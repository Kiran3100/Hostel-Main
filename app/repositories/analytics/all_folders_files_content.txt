### Combined Content from Folder: C:\Hostel-Main\app\repositories\analytics ###



# ===== Folder: C:\Hostel-Main\app\repositories\analytics =====

# --- File: C:\Hostel-Main\app\repositories\analytics\analytics_aggregate_repository.py ---
"""
Analytics Aggregate Repository for cross-module data aggregation.

Provides unified access to analytics data across all modules with:
- Cross-module metric aggregation
- Unified reporting capabilities
- Performance optimization for complex queries
- Cache coordination across repositories
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case
from sqlalchemy.orm import Session, joinedload, selectinload
from uuid import UUID

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.repositories.base.caching_repository import CachingRepository
from app.models.analytics import (
    BookingKPI,
    ComplaintKPI,
    OccupancyKPI,
    FinancialReport,
    SupervisorKPI,
    PlatformMetrics,
    DashboardKPI,
    QuickStats,
)


class AnalyticsAggregateRepository(BaseRepository):
    """
    Aggregate repository for cross-module analytics operations.
    
    Coordinates data retrieval and aggregation across all analytics
    modules for unified reporting and insights.
    """
    
    def __init__(self, db: Session):
        """Initialize with database session and caching."""
        super().__init__(db)
        self.cache = CachingRepository(db)
        self._cache_ttl = 300  # 5 minutes default cache
    
    # ==================== Unified Dashboard Data ====================
    
    def get_unified_dashboard_metrics(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Get unified dashboard metrics across all modules.
        
        Args:
            hostel_id: Hostel ID (None for platform-wide)
            period_start: Period start date
            period_end: Period end date
            use_cache: Whether to use cached results
            
        Returns:
            Dictionary with aggregated metrics from all modules
        """
        cache_key = f"unified_dashboard:{hostel_id}:{period_start}:{period_end}"
        
        if use_cache:
            cached = self.cache.get(cache_key)
            if cached:
                return cached
        
        # Aggregate from all modules
        metrics = {
            'booking_metrics': self._get_booking_summary(hostel_id, period_start, period_end),
            'financial_metrics': self._get_financial_summary(hostel_id, period_start, period_end),
            'occupancy_metrics': self._get_occupancy_summary(hostel_id, period_start, period_end),
            'complaint_metrics': self._get_complaint_summary(hostel_id, period_start, period_end),
            'supervisor_metrics': self._get_supervisor_summary(hostel_id, period_start, period_end),
            'quick_stats': self._get_quick_stats_summary(hostel_id, period_end),
            'alerts': self._get_critical_alerts(hostel_id),
            'trends': self._calculate_period_trends(hostel_id, period_start, period_end),
        }
        
        # Calculate composite scores
        metrics['health_score'] = self._calculate_overall_health_score(metrics)
        metrics['performance_grade'] = self._calculate_performance_grade(metrics)
        
        # Cache results
        if use_cache:
            self.cache.set(cache_key, metrics, ttl=self._cache_ttl)
        
        return metrics
    
    def _get_booking_summary(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Get booking metrics summary."""
        query = QueryBuilder(BookingKPI, self.db)
        
        if hostel_id:
            query = query.where(BookingKPI.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                BookingKPI.period_start >= period_start,
                BookingKPI.period_end <= period_end
            )
        )
        
        kpi = query.first()
        
        if not kpi:
            return self._empty_booking_summary()
        
        return {
            'total_bookings': kpi.total_bookings,
            'confirmed_bookings': kpi.confirmed_bookings,
            'conversion_rate': float(kpi.booking_conversion_rate),
            'cancellation_rate': float(kpi.cancellation_rate),
            'average_lead_time': float(kpi.average_lead_time_days),
            'approval_rate': float(kpi.approval_rate) if kpi.approval_rate else 0,
        }
    
    def _get_financial_summary(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Get financial metrics summary."""
        query = QueryBuilder(FinancialReport, self.db)
        
        if hostel_id:
            query = query.where(FinancialReport.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                FinancialReport.period_start >= period_start,
                FinancialReport.period_end <= period_end
            )
        )
        
        report = query.first()
        
        if not report:
            return self._empty_financial_summary()
        
        return {
            'total_revenue': float(report.pnl.revenue_breakdown.total_revenue) if report.pnl else 0,
            'net_profit': float(report.pnl.net_profit) if report.pnl else 0,
            'net_profit_margin': float(report.pnl.net_profit_margin) if report.pnl else 0,
            'collection_rate': float(report.collection_rate),
            'overdue_ratio': float(report.overdue_ratio),
            'financial_health_score': float(report.financial_health_score) if report.financial_health_score else 0,
            'performance_grade': report.performance_grade,
        }
    
    def _get_occupancy_summary(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Get occupancy metrics summary."""
        query = QueryBuilder(OccupancyKPI, self.db)
        
        if hostel_id:
            query = query.where(OccupancyKPI.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                OccupancyKPI.period_start >= period_start,
                OccupancyKPI.period_end <= period_end
            )
        )
        
        kpi = query.first()
        
        if not kpi:
            return self._empty_occupancy_summary()
        
        return {
            'current_occupancy': float(kpi.current_occupancy_percentage),
            'average_occupancy': float(kpi.average_occupancy_percentage),
            'total_beds': kpi.total_beds,
            'occupied_beds': kpi.occupied_beds,
            'available_beds': kpi.available_beds,
            'utilization_rate': float(kpi.utilization_rate),
            'occupancy_status': kpi.occupancy_status,
        }
    
    def _get_complaint_summary(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Get complaint metrics summary."""
        query = QueryBuilder(ComplaintKPI, self.db)
        
        if hostel_id:
            query = query.where(ComplaintKPI.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                ComplaintKPI.period_start >= period_start,
                ComplaintKPI.period_end <= period_end
            )
        )
        
        kpi = query.first()
        
        if not kpi:
            return self._empty_complaint_summary()
        
        return {
            'total_complaints': kpi.total_complaints,
            'open_complaints': kpi.open_complaints,
            'resolved_complaints': kpi.resolved_complaints,
            'average_resolution_time': float(kpi.average_resolution_time_hours),
            'sla_compliance_rate': float(kpi.sla_compliance_rate),
            'escalation_rate': float(kpi.escalation_rate),
            'efficiency_score': float(kpi.efficiency_score) if kpi.efficiency_score else 0,
        }
    
    def _get_supervisor_summary(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Get supervisor metrics summary."""
        query = QueryBuilder(SupervisorKPI, self.db)
        
        if hostel_id:
            query = query.where(SupervisorKPI.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                SupervisorKPI.period_start >= period_start,
                SupervisorKPI.period_end <= period_end
            )
        )
        
        # Aggregate across all supervisors
        supervisors = query.all()
        
        if not supervisors:
            return self._empty_supervisor_summary()
        
        return {
            'total_supervisors': len(supervisors),
            'average_performance_score': float(
                sum(s.overall_performance_score for s in supervisors) / len(supervisors)
            ),
            'total_complaints_resolved': sum(s.complaints_resolved for s in supervisors),
            'average_sla_compliance': float(
                sum(s.complaint_sla_compliance_rate for s in supervisors) / len(supervisors)
            ),
            'total_tasks_completed': sum(
                s.complaints_resolved + s.maintenance_requests_completed 
                for s in supervisors
            ),
        }
    
    def _get_quick_stats_summary(
        self,
        hostel_id: Optional[UUID],
        snapshot_date: date
    ) -> Dict[str, Any]:
        """Get quick stats for immediate dashboard visibility."""
        query = QueryBuilder(QuickStats, self.db)
        
        if hostel_id:
            query = query.where(QuickStats.hostel_id == hostel_id)
        
        query = query.where(QuickStats.snapshot_date == snapshot_date)
        
        stats = query.first()
        
        if not stats:
            return self._empty_quick_stats()
        
        return {
            'total_students': stats.total_students,
            'active_students': stats.active_students,
            'todays_check_ins': stats.todays_check_ins,
            'todays_check_outs': stats.todays_check_outs,
            'open_complaints': stats.open_complaints,
            'urgent_complaints': stats.urgent_complaints,
            'pending_maintenance': stats.pending_maintenance,
            'todays_revenue': float(stats.todays_revenue),
            'monthly_revenue': float(stats.monthly_revenue),
            'outstanding_payments': float(stats.outstanding_payments),
            'occupancy_rate': float(stats.occupancy_rate) if stats.occupancy_rate else 0,
        }
    
    def _get_critical_alerts(self, hostel_id: Optional[UUID]) -> List[Dict[str, Any]]:
        """Get critical alerts requiring immediate attention."""
        alerts = []
        
        # Check for critical metrics from quick stats
        query = QueryBuilder(QuickStats, self.db)
        if hostel_id:
            query = query.where(QuickStats.hostel_id == hostel_id)
        
        query = query.order_by(QuickStats.snapshot_date.desc())
        stats = query.first()
        
        if not stats:
            return alerts
        
        # Critical complaint alerts
        if stats.urgent_complaints > 0:
            alerts.append({
                'severity': 'critical',
                'type': 'complaints',
                'message': f'{stats.urgent_complaints} urgent complaints require attention',
                'value': stats.urgent_complaints,
            })
        
        # Overdue maintenance alerts
        if stats.overdue_maintenance > 0:
            alerts.append({
                'severity': 'error',
                'type': 'maintenance',
                'message': f'{stats.overdue_maintenance} overdue maintenance requests',
                'value': stats.overdue_maintenance,
            })
        
        # Overdue payment alerts
        if stats.overdue_payments > 1000:  # Threshold
            alerts.append({
                'severity': 'warning',
                'type': 'payments',
                'message': f'₹{float(stats.overdue_payments):,.2f} in overdue payments',
                'value': float(stats.overdue_payments),
            })
        
        # Low occupancy alerts
        if stats.occupancy_rate and stats.occupancy_rate < 50:
            alerts.append({
                'severity': 'warning',
                'type': 'occupancy',
                'message': f'Low occupancy rate: {float(stats.occupancy_rate)}%',
                'value': float(stats.occupancy_rate),
            })
        
        return alerts
    
    def _calculate_period_trends(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Calculate trends over the period."""
        # Calculate previous period for comparison
        period_length = (period_end - period_start).days
        prev_period_start = period_start - timedelta(days=period_length)
        prev_period_end = period_start - timedelta(days=1)
        
        current = self.get_unified_dashboard_metrics(
            hostel_id, period_start, period_end, use_cache=False
        )
        previous = self.get_unified_dashboard_metrics(
            hostel_id, prev_period_start, prev_period_end, use_cache=False
        )
        
        return {
            'booking_trend': self._calculate_trend_percentage(
                current['booking_metrics']['total_bookings'],
                previous['booking_metrics']['total_bookings']
            ),
            'revenue_trend': self._calculate_trend_percentage(
                current['financial_metrics']['total_revenue'],
                previous['financial_metrics']['total_revenue']
            ),
            'occupancy_trend': self._calculate_trend_percentage(
                current['occupancy_metrics']['average_occupancy'],
                previous['occupancy_metrics']['average_occupancy']
            ),
            'complaint_resolution_trend': self._calculate_trend_percentage(
                current['complaint_metrics']['resolved_complaints'],
                previous['complaint_metrics']['resolved_complaints']
            ),
        }
    
    def _calculate_trend_percentage(
        self,
        current: float,
        previous: float
    ) -> Dict[str, Any]:
        """Calculate trend percentage and direction."""
        if previous == 0:
            return {
                'percentage': 0,
                'direction': 'stable',
                'is_improvement': True,
            }
        
        percentage = ((current - previous) / previous) * 100
        
        return {
            'percentage': round(percentage, 2),
            'direction': 'up' if percentage > 0 else 'down' if percentage < 0 else 'stable',
            'is_improvement': percentage > 0,  # Context-dependent
        }
    
    def _calculate_overall_health_score(self, metrics: Dict[str, Any]) -> float:
        """
        Calculate overall health score (0-100) based on all metrics.
        
        Weighted average of:
        - Financial health: 30%
        - Occupancy: 25%
        - Complaint resolution: 20%
        - Booking performance: 15%
        - Supervisor performance: 10%
        """
        weights = {
            'financial': 0.30,
            'occupancy': 0.25,
            'complaint': 0.20,
            'booking': 0.15,
            'supervisor': 0.10,
        }
        
        scores = {
            'financial': metrics['financial_metrics']['financial_health_score'],
            'occupancy': metrics['occupancy_metrics']['average_occupancy'],
            'complaint': metrics['complaint_metrics']['efficiency_score'],
            'booking': metrics['booking_metrics']['conversion_rate'],
            'supervisor': metrics['supervisor_metrics']['average_performance_score'],
        }
        
        weighted_score = sum(
            scores[key] * weights[key] 
            for key in weights.keys()
        )
        
        return round(weighted_score, 2)
    
    def _calculate_performance_grade(self, metrics: Dict[str, Any]) -> str:
        """Calculate letter grade based on health score."""
        health_score = metrics.get('health_score', 0)
        
        if health_score >= 90:
            return 'A+'
        elif health_score >= 85:
            return 'A'
        elif health_score >= 80:
            return 'A-'
        elif health_score >= 75:
            return 'B+'
        elif health_score >= 70:
            return 'B'
        elif health_score >= 65:
            return 'B-'
        elif health_score >= 60:
            return 'C+'
        elif health_score >= 55:
            return 'C'
        elif health_score >= 50:
            return 'C-'
        else:
            return 'D'
    
    # ==================== Empty Summary Helpers ====================
    
    def _empty_booking_summary(self) -> Dict[str, Any]:
        """Return empty booking summary."""
        return {
            'total_bookings': 0,
            'confirmed_bookings': 0,
            'conversion_rate': 0,
            'cancellation_rate': 0,
            'average_lead_time': 0,
            'approval_rate': 0,
        }
    
    def _empty_financial_summary(self) -> Dict[str, Any]:
        """Return empty financial summary."""
        return {
            'total_revenue': 0,
            'net_profit': 0,
            'net_profit_margin': 0,
            'collection_rate': 0,
            'overdue_ratio': 0,
            'financial_health_score': 0,
            'performance_grade': 'N/A',
        }
    
    def _empty_occupancy_summary(self) -> Dict[str, Any]:
        """Return empty occupancy summary."""
        return {
            'current_occupancy': 0,
            'average_occupancy': 0,
            'total_beds': 0,
            'occupied_beds': 0,
            'available_beds': 0,
            'utilization_rate': 0,
            'occupancy_status': 'unknown',
        }
    
    def _empty_complaint_summary(self) -> Dict[str, Any]:
        """Return empty complaint summary."""
        return {
            'total_complaints': 0,
            'open_complaints': 0,
            'resolved_complaints': 0,
            'average_resolution_time': 0,
            'sla_compliance_rate': 0,
            'escalation_rate': 0,
            'efficiency_score': 0,
        }
    
    def _empty_supervisor_summary(self) -> Dict[str, Any]:
        """Return empty supervisor summary."""
        return {
            'total_supervisors': 0,
            'average_performance_score': 0,
            'total_complaints_resolved': 0,
            'average_sla_compliance': 0,
            'total_tasks_completed': 0,
        }
    
    def _empty_quick_stats(self) -> Dict[str, Any]:
        """Return empty quick stats."""
        return {
            'total_students': 0,
            'active_students': 0,
            'todays_check_ins': 0,
            'todays_check_outs': 0,
            'open_complaints': 0,
            'urgent_complaints': 0,
            'pending_maintenance': 0,
            'todays_revenue': 0,
            'monthly_revenue': 0,
            'outstanding_payments': 0,
            'occupancy_rate': 0,
        }
    
    # ==================== Platform-Wide Aggregation ====================
    
    def get_platform_wide_metrics(
        self,
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """
        Get platform-wide aggregated metrics across all hostels.
        
        Args:
            period_start: Period start date
            period_end: Period end date
            
        Returns:
            Dictionary with platform-wide aggregated metrics
        """
        query = QueryBuilder(PlatformMetrics, self.db)
        query = query.where(
            and_(
                PlatformMetrics.period_start >= period_start,
                PlatformMetrics.period_end <= period_end
            )
        )
        
        metrics = query.first()
        
        if not metrics:
            return self._empty_platform_metrics()
        
        return {
            'total_hostels': metrics.total_hostels,
            'active_hostels': metrics.active_hostels,
            'total_users': metrics.total_users,
            'total_students': metrics.total_students,
            'total_beds': metrics.total_beds_platform,
            'platform_occupancy': float(metrics.platform_occupancy_rate),
            'activation_rate': float(metrics.activation_rate) if metrics.activation_rate else 0,
            'avg_daily_active_users': metrics.avg_daily_active_users,
            'peak_concurrent_sessions': metrics.peak_concurrent_sessions,
        }
    
    def _empty_platform_metrics(self) -> Dict[str, Any]:
        """Return empty platform metrics."""
        return {
            'total_hostels': 0,
            'active_hostels': 0,
            'total_users': 0,
            'total_students': 0,
            'total_beds': 0,
            'platform_occupancy': 0,
            'activation_rate': 0,
            'avg_daily_active_users': 0,
            'peak_concurrent_sessions': 0,
        }
    
    # ==================== Comparative Analysis ====================
    
    def compare_hostels_performance(
        self,
        hostel_ids: List[UUID],
        period_start: date,
        period_end: date,
        metrics: Optional[List[str]] = None
    ) -> Dict[UUID, Dict[str, Any]]:
        """
        Compare performance across multiple hostels.
        
        Args:
            hostel_ids: List of hostel IDs to compare
            period_start: Period start date
            period_end: Period end date
            metrics: Specific metrics to compare (None for all)
            
        Returns:
            Dictionary mapping hostel IDs to their metrics
        """
        comparison = {}
        
        for hostel_id in hostel_ids:
            comparison[hostel_id] = self.get_unified_dashboard_metrics(
                hostel_id, period_start, period_end
            )
        
        # Add rankings
        comparison = self._add_hostel_rankings(comparison, metrics)
        
        return comparison
    
    def _add_hostel_rankings(
        self,
        comparison: Dict[UUID, Dict[str, Any]],
        metrics: Optional[List[str]] = None
    ) -> Dict[UUID, Dict[str, Any]]:
        """Add ranking information to comparison data."""
        # Extract values for ranking
        hostel_scores = {
            hostel_id: data['health_score']
            for hostel_id, data in comparison.items()
        }
        
        # Sort by score
        ranked = sorted(
            hostel_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # Add rankings
        for rank, (hostel_id, score) in enumerate(ranked, start=1):
            comparison[hostel_id]['overall_rank'] = rank
            comparison[hostel_id]['total_hostels'] = len(ranked)
        
        return comparison
    
    # ==================== Time Series Analysis ====================
    
    def get_time_series_metrics(
        self,
        hostel_id: Optional[UUID],
        metric_keys: List[str],
        start_date: date,
        end_date: date,
        granularity: str = 'daily'
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        Get time series data for specified metrics.
        
        Args:
            hostel_id: Hostel ID (None for platform-wide)
            metric_keys: List of metric keys to retrieve
            start_date: Start date
            end_date: End date
            granularity: Time granularity (daily, weekly, monthly)
            
        Returns:
            Dictionary mapping metric keys to time series data
        """
        # Implementation would aggregate from various trend tables
        # For now, return structure
        return {
            metric_key: []
            for metric_key in metric_keys
        }
    
    # ==================== Export and Reporting ====================
    
    def export_analytics_report(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        format: str = 'json'
    ) -> Dict[str, Any]:
        """
        Export comprehensive analytics report.
        
        Args:
            hostel_id: Hostel ID (None for platform-wide)
            period_start: Period start date
            period_end: Period end date
            format: Export format (json, csv, excel)
            
        Returns:
            Formatted report data
        """
        report = {
            'metadata': {
                'hostel_id': str(hostel_id) if hostel_id else 'platform',
                'period_start': period_start.isoformat(),
                'period_end': period_end.isoformat(),
                'generated_at': datetime.utcnow().isoformat(),
                'format': format,
            },
            'metrics': self.get_unified_dashboard_metrics(
                hostel_id, period_start, period_end
            ),
        }
        
        return report

# --- File: C:\Hostel-Main\app\repositories\analytics\booking_analytics_repository.py ---
"""
Booking Analytics Repository for booking performance tracking.

Provides comprehensive booking analytics with:
- Conversion funnel analysis
- Cancellation pattern tracking
- Source performance metrics
- Revenue optimization insights
- Predictive demand forecasting
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, extract
from sqlalchemy.orm import Session, joinedload
from uuid import UUID

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.repositories.base.pagination import PaginationManager
from app.models.analytics.booking_analytics import (
    BookingKPI,
    BookingTrendPoint,
    BookingFunnelAnalytics,
    CancellationAnalytics,
    BookingSourceMetrics,
    BookingAnalyticsSummary,
)


class BookingAnalyticsRepository(BaseRepository):
    """Repository for booking analytics operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
        self.pagination = PaginationManager()
    
    # ==================== KPI Operations ====================
    
    def create_booking_kpi(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        kpi_data: Dict[str, Any]
    ) -> BookingKPI:
        """
        Create or update booking KPI record.
        
        Args:
            hostel_id: Hostel ID (None for platform-wide)
            period_start: Period start date
            period_end: Period end date
            kpi_data: KPI metrics data
            
        Returns:
            Created or updated BookingKPI instance
        """
        # Check if exists
        existing = self.get_booking_kpi(hostel_id, period_start, period_end)
        
        if existing:
            # Update existing
            for key, value in kpi_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        # Create new
        kpi = BookingKPI(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **kpi_data
        )
        
        self.db.add(kpi)
        self.db.commit()
        self.db.refresh(kpi)
        
        return kpi
    
    def get_booking_kpi(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[BookingKPI]:
        """Get booking KPI for specific period."""
        query = QueryBuilder(BookingKPI, self.db)
        
        if hostel_id:
            query = query.where(BookingKPI.hostel_id == hostel_id)
        else:
            query = query.where(BookingKPI.hostel_id.is_(None))
        
        query = query.where(
            and_(
                BookingKPI.period_start == period_start,
                BookingKPI.period_end == period_end
            )
        )
        
        return query.first()
    
    def get_booking_kpis_by_date_range(
        self,
        hostel_id: Optional[UUID],
        start_date: date,
        end_date: date
    ) -> List[BookingKPI]:
        """Get all booking KPIs within date range."""
        query = QueryBuilder(BookingKPI, self.db)
        
        if hostel_id:
            query = query.where(BookingKPI.hostel_id == hostel_id)
        
        query = query.where(
            or_(
                and_(
                    BookingKPI.period_start >= start_date,
                    BookingKPI.period_start <= end_date
                ),
                and_(
                    BookingKPI.period_end >= start_date,
                    BookingKPI.period_end <= end_date
                )
            )
        ).order_by(BookingKPI.period_start.desc())
        
        return query.all()
    
    # ==================== Trend Analysis ====================
    
    def add_trend_points(
        self,
        kpi_id: UUID,
        trend_points: List[Dict[str, Any]]
    ) -> List[BookingTrendPoint]:
        """
        Add multiple trend points for a KPI.
        
        Args:
            kpi_id: Parent KPI ID
            trend_points: List of trend point data
            
        Returns:
            List of created BookingTrendPoint instances
        """
        created_points = []
        
        for point_data in trend_points:
            # Check if point exists
            existing = self.db.query(BookingTrendPoint).filter(
                and_(
                    BookingTrendPoint.kpi_id == kpi_id,
                    BookingTrendPoint.trend_date == point_data['trend_date']
                )
            ).first()
            
            if existing:
                # Update existing
                for key, value in point_data.items():
                    if key != 'trend_date':
                        setattr(existing, key, value)
                created_points.append(existing)
            else:
                # Create new
                point = BookingTrendPoint(
                    kpi_id=kpi_id,
                    **point_data
                )
                self.db.add(point)
                created_points.append(point)
        
        self.db.commit()
        for point in created_points:
            self.db.refresh(point)
        
        return created_points
    
    def get_trend_points(
        self,
        kpi_id: UUID,
        start_date: Optional[date] = None,
        end_date: Optional[date] = None
    ) -> List[BookingTrendPoint]:
        """Get trend points for a KPI."""
        query = QueryBuilder(BookingTrendPoint, self.db)
        query = query.where(BookingTrendPoint.kpi_id == kpi_id)
        
        if start_date:
            query = query.where(BookingTrendPoint.trend_date >= start_date)
        if end_date:
            query = query.where(BookingTrendPoint.trend_date <= end_date)
        
        query = query.order_by(BookingTrendPoint.trend_date.asc())
        
        return query.all()
    
    def calculate_trend_direction(
        self,
        kpi_id: UUID,
        metric: str = 'total_bookings'
    ) -> Dict[str, Any]:
        """
        Calculate trend direction and percentage for a metric.
        
        Args:
            kpi_id: KPI ID
            metric: Metric name to analyze
            
        Returns:
            Dictionary with trend analysis
        """
        points = self.get_trend_points(kpi_id)
        
        if len(points) < 2:
            return {
                'direction': 'stable',
                'percentage': 0,
                'confidence': 0,
            }
        
        # Get values
        values = [getattr(point, metric) for point in points]
        
        # Calculate linear regression
        n = len(values)
        x = list(range(n))
        
        sum_x = sum(x)
        sum_y = sum(values)
        sum_xy = sum(xi * yi for xi, yi in zip(x, values))
        sum_x2 = sum(xi * xi for xi in x)
        
        # Calculate slope
        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)
        
        # Calculate percentage change
        if values[0] != 0:
            percentage = ((values[-1] - values[0]) / values[0]) * 100
        else:
            percentage = 0
        
        # Determine direction
        if slope > 0.1:
            direction = 'up'
        elif slope < -0.1:
            direction = 'down'
        else:
            direction = 'stable'
        
        # Calculate R-squared for confidence
        y_mean = sum_y / n
        ss_tot = sum((yi - y_mean) ** 2 for yi in values)
        
        if ss_tot > 0:
            intercept = (sum_y - slope * sum_x) / n
            y_pred = [slope * xi + intercept for xi in x]
            ss_res = sum((yi - ypi) ** 2 for yi, ypi in zip(values, y_pred))
            r_squared = 1 - (ss_res / ss_tot)
        else:
            r_squared = 0
        
        return {
            'direction': direction,
            'percentage': round(percentage, 2),
            'confidence': round(r_squared, 4),
            'slope': round(slope, 4),
        }
    
    # ==================== Conversion Funnel ====================
    
    def create_funnel_analytics(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        funnel_data: Dict[str, Any]
    ) -> BookingFunnelAnalytics:
        """Create or update booking funnel analytics."""
        # Check if exists
        existing = self.db.query(BookingFunnelAnalytics).filter(
            and_(
                BookingFunnelAnalytics.hostel_id == hostel_id if hostel_id else BookingFunnelAnalytics.hostel_id.is_(None),
                BookingFunnelAnalytics.period_start == period_start,
                BookingFunnelAnalytics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in funnel_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        funnel = BookingFunnelAnalytics(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **funnel_data
        )
        
        self.db.add(funnel)
        self.db.commit()
        self.db.refresh(funnel)
        
        return funnel
    
    def calculate_conversion_rates(
        self,
        funnel: BookingFunnelAnalytics
    ) -> Dict[str, float]:
        """Calculate all conversion rates for a funnel."""
        rates = {}
        
        # View to start
        if funnel.hostel_page_views > 0:
            rates['view_to_start'] = (
                funnel.booking_form_starts / funnel.hostel_page_views
            ) * 100
        else:
            rates['view_to_start'] = 0
        
        # Start to submit
        if funnel.booking_form_starts > 0:
            rates['start_to_submit'] = (
                funnel.booking_submissions / funnel.booking_form_starts
            ) * 100
        else:
            rates['start_to_submit'] = 0
        
        # Submit to confirm
        if funnel.booking_submissions > 0:
            rates['submit_to_confirm'] = (
                funnel.bookings_confirmed / funnel.booking_submissions
            ) * 100
        else:
            rates['submit_to_confirm'] = 0
        
        # Overall
        if funnel.hostel_page_views > 0:
            rates['overall'] = (
                funnel.bookings_confirmed / funnel.hostel_page_views
            ) * 100
        else:
            rates['overall'] = 0
        
        return rates
    
    def identify_funnel_bottleneck(
        self,
        funnel: BookingFunnelAnalytics
    ) -> Dict[str, Any]:
        """Identify the largest drop-off stage in funnel."""
        stages = {
            'view_to_start': {
                'stage': 'View to Form Start',
                'drop_off': funnel.hostel_page_views - funnel.booking_form_starts,
                'rate': funnel.view_to_start_rate,
            },
            'start_to_submit': {
                'stage': 'Form Start to Submit',
                'drop_off': funnel.booking_form_starts - funnel.booking_submissions,
                'rate': funnel.start_to_submit_rate,
            },
            'submit_to_confirm': {
                'stage': 'Submit to Confirm',
                'drop_off': funnel.booking_submissions - funnel.bookings_confirmed,
                'rate': funnel.submit_to_confirm_rate,
            },
        }
        
        # Find largest drop-off
        bottleneck = max(
            stages.values(),
            key=lambda x: x['drop_off']
        )
        
        return bottleneck
    
    # ==================== Cancellation Analysis ====================
    
    def create_cancellation_analytics(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        cancellation_data: Dict[str, Any]
    ) -> CancellationAnalytics:
        """Create or update cancellation analytics."""
        existing = self.db.query(CancellationAnalytics).filter(
            and_(
                CancellationAnalytics.hostel_id == hostel_id if hostel_id else CancellationAnalytics.hostel_id.is_(None),
                CancellationAnalytics.period_start == period_start,
                CancellationAnalytics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in cancellation_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        analytics = CancellationAnalytics(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **cancellation_data
        )
        
        self.db.add(analytics)
        self.db.commit()
        self.db.refresh(analytics)
        
        return analytics
    
    def analyze_cancellation_patterns(
        self,
        hostel_id: Optional[UUID],
        start_date: date,
        end_date: date
    ) -> Dict[str, Any]:
        """Analyze cancellation patterns over time."""
        analytics_records = self.db.query(CancellationAnalytics).filter(
            and_(
                CancellationAnalytics.hostel_id == hostel_id if hostel_id else CancellationAnalytics.hostel_id.is_(None),
                CancellationAnalytics.period_start >= start_date,
                CancellationAnalytics.period_end <= end_date
            )
        ).all()
        
        if not analytics_records:
            return self._empty_cancellation_pattern()
        
        # Aggregate data
        total_cancellations = sum(a.total_cancellations for a in analytics_records)
        avg_cancellation_rate = sum(
            float(a.cancellation_rate) for a in analytics_records
        ) / len(analytics_records)
        
        # Collect all reasons
        all_reasons = {}
        for record in analytics_records:
            if record.cancellations_by_reason:
                for reason, count in record.cancellations_by_reason.items():
                    all_reasons[reason] = all_reasons.get(reason, 0) + count
        
        # Top reason
        top_reason = max(
            all_reasons.items(),
            key=lambda x: x[1]
        )[0] if all_reasons else None
        
        # Timing analysis
        avg_time_before_checkin = sum(
            float(a.average_time_before_checkin_days) for a in analytics_records
        ) / len(analytics_records)
        
        total_within_24h = sum(a.cancellations_within_24h for a in analytics_records)
        late_cancellation_rate = (
            total_within_24h / total_cancellations * 100
        ) if total_cancellations > 0 else 0
        
        return {
            'total_cancellations': total_cancellations,
            'average_cancellation_rate': round(avg_cancellation_rate, 2),
            'top_cancellation_reason': top_reason,
            'cancellations_by_reason': all_reasons,
            'average_time_before_checkin': round(avg_time_before_checkin, 2),
            'late_cancellation_rate': round(late_cancellation_rate, 2),
            'trend': self._calculate_cancellation_trend(analytics_records),
        }
    
    def _calculate_cancellation_trend(
        self,
        records: List[CancellationAnalytics]
    ) -> str:
        """Calculate cancellation trend direction."""
        if len(records) < 2:
            return 'stable'
        
        # Sort by period start
        sorted_records = sorted(records, key=lambda x: x.period_start)
        
        first_half = sorted_records[:len(sorted_records)//2]
        second_half = sorted_records[len(sorted_records)//2:]
        
        avg_first = sum(r.total_cancellations for r in first_half) / len(first_half)
        avg_second = sum(r.total_cancellations for r in second_half) / len(second_half)
        
        if avg_second > avg_first * 1.1:
            return 'increasing'
        elif avg_second < avg_first * 0.9:
            return 'decreasing'
        else:
            return 'stable'
    
    def _empty_cancellation_pattern(self) -> Dict[str, Any]:
        """Return empty cancellation pattern."""
        return {
            'total_cancellations': 0,
            'average_cancellation_rate': 0,
            'top_cancellation_reason': None,
            'cancellations_by_reason': {},
            'average_time_before_checkin': 0,
            'late_cancellation_rate': 0,
            'trend': 'stable',
        }
    
    # ==================== Source Performance ====================
    
    def create_source_metrics(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        source: str,
        metrics_data: Dict[str, Any]
    ) -> BookingSourceMetrics:
        """Create or update booking source metrics."""
        existing = self.db.query(BookingSourceMetrics).filter(
            and_(
                BookingSourceMetrics.hostel_id == hostel_id if hostel_id else BookingSourceMetrics.hostel_id.is_(None),
                BookingSourceMetrics.period_start == period_start,
                BookingSourceMetrics.period_end == period_end,
                BookingSourceMetrics.source == source
            )
        ).first()
        
        if existing:
            for key, value in metrics_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = BookingSourceMetrics(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            source=source,
            **metrics_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def get_source_performance_comparison(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[Dict[str, Any]]:
        """Compare performance across all booking sources."""
        metrics = self.db.query(BookingSourceMetrics).filter(
            and_(
                BookingSourceMetrics.hostel_id == hostel_id if hostel_id else BookingSourceMetrics.hostel_id.is_(None),
                BookingSourceMetrics.period_start == period_start,
                BookingSourceMetrics.period_end == period_end
            )
        ).all()
        
        comparison = []
        for metric in metrics:
            comparison.append({
                'source': metric.source,
                'total_bookings': metric.total_bookings,
                'confirmed_bookings': metric.confirmed_bookings,
                'conversion_rate': float(metric.conversion_rate),
                'total_revenue': float(metric.total_revenue),
                'average_booking_value': float(metric.average_booking_value),
                'roi': float(metric.roi) if metric.roi else None,
                'cost_per_booking': float(
                    metric.marketing_cost / metric.confirmed_bookings
                ) if metric.marketing_cost and metric.confirmed_bookings > 0 else None,
            })
        
        # Sort by total revenue
        comparison.sort(key=lambda x: x['total_revenue'], reverse=True)
        
        return comparison
    
    def get_best_performing_source(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        metric: str = 'conversion_rate'
    ) -> Optional[BookingSourceMetrics]:
        """Get the best performing source for a given metric."""
        query = QueryBuilder(BookingSourceMetrics, self.db)
        
        if hostel_id:
            query = query.where(BookingSourceMetrics.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                BookingSourceMetrics.period_start == period_start,
                BookingSourceMetrics.period_end == period_end
            )
        )
        
        # Order by specified metric
        if metric == 'conversion_rate':
            query = query.order_by(BookingSourceMetrics.conversion_rate.desc())
        elif metric == 'total_revenue':
            query = query.order_by(BookingSourceMetrics.total_revenue.desc())
        elif metric == 'roi':
            query = query.order_by(BookingSourceMetrics.roi.desc())
        else:
            query = query.order_by(BookingSourceMetrics.total_bookings.desc())
        
        return query.first()
    
    # ==================== Predictive Analytics ====================
    
    def forecast_booking_demand(
        self,
        hostel_id: Optional[UUID],
        forecast_days: int = 30,
        historical_days: int = 90
    ) -> List[Dict[str, Any]]:
        """
        Forecast booking demand using historical data.
        
        Args:
            hostel_id: Hostel ID
            forecast_days: Days to forecast
            historical_days: Historical data days to use
            
        Returns:
            List of forecasted data points
        """
        # Get historical trend points
        end_date = date.today()
        start_date = end_date - timedelta(days=historical_days)
        
        # Get KPIs for the period
        kpis = self.get_booking_kpis_by_date_range(
            hostel_id, start_date, end_date
        )
        
        if not kpis:
            return []
        
        # Get all trend points
        all_points = []
        for kpi in kpis:
            points = self.get_trend_points(kpi.id)
            all_points.extend(points)
        
        # Sort by date
        all_points.sort(key=lambda x: x.trend_date)
        
        if len(all_points) < 7:  # Need minimum data
            return []
        
        # Simple moving average forecast
        window_size = 7
        values = [p.total_bookings for p in all_points[-window_size:]]
        moving_avg = sum(values) / len(values)
        
        # Calculate trend
        recent_avg = sum(values[-3:]) / 3
        older_avg = sum(values[:3]) / 3
        trend = (recent_avg - older_avg) / 3  # Daily trend
        
        # Generate forecast
        forecast = []
        current_date = end_date + timedelta(days=1)
        
        for i in range(forecast_days):
            forecasted_value = moving_avg + (trend * i)
            forecasted_value = max(0, forecasted_value)  # No negative bookings
            
            # Add some uncertainty bounds (±20%)
            lower_bound = forecasted_value * 0.8
            upper_bound = forecasted_value * 1.2
            
            forecast.append({
                'date': current_date + timedelta(days=i),
                'forecasted_bookings': round(forecasted_value),
                'lower_bound': round(lower_bound),
                'upper_bound': round(upper_bound),
                'confidence': 0.80,  # 80% confidence interval
            })
        
        return forecast
    
    # ==================== Summary and Aggregation ====================
    
    def create_booking_summary(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> BookingAnalyticsSummary:
        """
        Create comprehensive booking analytics summary.
        
        Aggregates data from KPIs, funnel, cancellations, and sources.
        """
        # Get related analytics
        kpi = self.get_booking_kpi(hostel_id, period_start, period_end)
        
        funnel = self.db.query(BookingFunnelAnalytics).filter(
            and_(
                BookingFunnelAnalytics.hostel_id == hostel_id if hostel_id else BookingFunnelAnalytics.hostel_id.is_(None),
                BookingFunnelAnalytics.period_start == period_start,
                BookingFunnelAnalytics.period_end == period_end
            )
        ).first()
        
        cancellation = self.db.query(CancellationAnalytics).filter(
            and_(
                CancellationAnalytics.hostel_id == hostel_id if hostel_id else CancellationAnalytics.hostel_id.is_(None),
                CancellationAnalytics.period_start == period_start,
                CancellationAnalytics.period_end == period_end
            )
        ).first()
        
        sources = self.db.query(BookingSourceMetrics).filter(
            and_(
                BookingSourceMetrics.hostel_id == hostel_id if hostel_id else BookingSourceMetrics.hostel_id.is_(None),
                BookingSourceMetrics.period_start == period_start,
                BookingSourceMetrics.period_end == period_end
            )
        ).all()
        
        # Calculate aggregates
        total_revenue = sum(float(s.total_revenue) for s in sources)
        
        bookings_by_source = {
            s.source: s.total_bookings for s in sources
        }
        
        revenue_by_source = {
            s.source: float(s.total_revenue) for s in sources
        }
        
        # Find best performers
        best_conversion = max(
            sources,
            key=lambda s: s.conversion_rate
        ) if sources else None
        
        best_revenue = max(
            sources,
            key=lambda s: s.total_revenue
        ) if sources else None
        
        # Create or update summary
        existing = self.db.query(BookingAnalyticsSummary).filter(
            and_(
                BookingAnalyticsSummary.hostel_id == hostel_id if hostel_id else BookingAnalyticsSummary.hostel_id.is_(None),
                BookingAnalyticsSummary.period_start == period_start,
                BookingAnalyticsSummary.period_end == period_end
            )
        ).first()
        
        summary_data = {
            'kpi_id': kpi.id if kpi else None,
            'funnel_id': funnel.id if funnel else None,
            'cancellation_id': cancellation.id if cancellation else None,
            'total_bookings': kpi.total_bookings if kpi else 0,
            'total_revenue': total_revenue,
            'overall_conversion_rate': float(kpi.booking_conversion_rate) if kpi else 0,
            'bookings_by_source': bookings_by_source,
            'revenue_by_source': revenue_by_source,
            'best_performing_source': best_conversion.source if best_conversion else None,
            'highest_revenue_source': best_revenue.source if best_revenue else None,
            'trend_summary': self._generate_trend_summary(kpi) if kpi else {},
            'is_cached': True,
            'cache_expires_at': datetime.utcnow() + timedelta(hours=1),
            'calculated_at': datetime.utcnow(),
        }
        
        if existing:
            for key, value in summary_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        summary = BookingAnalyticsSummary(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **summary_data
        )
        
        self.db.add(summary)
        self.db.commit()
        self.db.refresh(summary)
        
        return summary
    
    def _generate_trend_summary(self, kpi: BookingKPI) -> Dict[str, Any]:
        """Generate trend summary for KPI."""
        trend_analysis = self.calculate_trend_direction(kpi.id, 'total_bookings')
        
        return {
            'booking_trend': trend_analysis['direction'],
            'booking_change_percentage': trend_analysis['percentage'],
            'trend_confidence': trend_analysis['confidence'],
        }
    
    # ==================== Performance Optimization ====================
    
    def get_conversion_optimization_insights(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Generate actionable insights for conversion optimization."""
        funnel = self.db.query(BookingFunnelAnalytics).filter(
            and_(
                BookingFunnelAnalytics.hostel_id == hostel_id if hostel_id else BookingFunnelAnalytics.hostel_id.is_(None),
                BookingFunnelAnalytics.period_start == period_start,
                BookingFunnelAnalytics.period_end == period_end
            )
        ).first()
        
        if not funnel:
            return {'insights': [], 'recommendations': []}
        
        insights = []
        recommendations = []
        
        # Analyze view to form start
        if float(funnel.view_to_start_rate) < 10:  # Low threshold
            insights.append({
                'metric': 'view_to_start_rate',
                'value': float(funnel.view_to_start_rate),
                'status': 'needs_improvement',
                'priority': 'high',
            })
            recommendations.append(
                'Improve call-to-action visibility and value proposition on hostel pages'
            )
        
        # Analyze form completion
        if float(funnel.start_to_submit_rate) < 50:
            insights.append({
                'metric': 'start_to_submit_rate',
                'value': float(funnel.start_to_submit_rate),
                'status': 'needs_improvement',
                'priority': 'high',
            })
            recommendations.append(
                'Simplify booking form and reduce friction in form completion'
            )
        
        # Analyze confirmation rate
        if float(funnel.submit_to_confirm_rate) < 70:
            insights.append({
                'metric': 'submit_to_confirm_rate',
                'value': float(funnel.submit_to_confirm_rate),
                'status': 'needs_improvement',
                'priority': 'medium',
            })
            recommendations.append(
                'Streamline confirmation process and improve payment success rates'
            )
        
        # Overall conversion
        if float(funnel.view_to_confirm_rate) < 5:
            insights.append({
                'metric': 'overall_conversion',
                'value': float(funnel.view_to_confirm_rate),
                'status': 'critical',
                'priority': 'critical',
            })
            recommendations.append(
                'Comprehensive funnel optimization required - consider A/B testing'
            )
        
        return {
            'insights': insights,
            'recommendations': recommendations,
            'bottleneck': self.identify_funnel_bottleneck(funnel),
        }

# --- File: C:\Hostel-Main\app\repositories\analytics\complaint_analytics_repository.py ---
"""
Complaint Analytics Repository for service quality tracking.

Provides comprehensive complaint analytics with:
- SLA compliance monitoring
- Resolution time tracking
- Category and priority analysis
- Supervisor performance metrics
- Trend analysis and forecasting
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, distinct
from sqlalchemy.orm import Session, joinedload
from uuid import UUID

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.models.analytics.complaint_analytics import (
    ComplaintKPI,
    SLAMetrics,
    ComplaintTrendPoint,
    CategoryBreakdown,
    PriorityBreakdown,
    ComplaintDashboard,
)


class ComplaintAnalyticsRepository(BaseRepository):
    """Repository for complaint analytics operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
    
    # ==================== KPI Operations ====================
    
    def create_complaint_kpi(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        kpi_data: Dict[str, Any]
    ) -> ComplaintKPI:
        """
        Create or update complaint KPI record.
        
        Args:
            hostel_id: Hostel ID (None for platform-wide)
            period_start: Period start date
            period_end: Period end date
            kpi_data: KPI metrics data
            
        Returns:
            Created or updated ComplaintKPI instance
        """
        existing = self.db.query(ComplaintKPI).filter(
            and_(
                ComplaintKPI.hostel_id == hostel_id if hostel_id else ComplaintKPI.hostel_id.is_(None),
                ComplaintKPI.period_start == period_start,
                ComplaintKPI.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in kpi_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        kpi = ComplaintKPI(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **kpi_data
        )
        
        self.db.add(kpi)
        self.db.commit()
        self.db.refresh(kpi)
        
        return kpi
    
    def get_complaint_kpi(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[ComplaintKPI]:
        """Get complaint KPI for specific period."""
        query = QueryBuilder(ComplaintKPI, self.db)
        
        if hostel_id:
            query = query.where(ComplaintKPI.hostel_id == hostel_id)
        else:
            query = query.where(ComplaintKPI.hostel_id.is_(None))
        
        query = query.where(
            and_(
                ComplaintKPI.period_start == period_start,
                ComplaintKPI.period_end == period_end
            )
        )
        
        return query.first()
    
    def get_complaint_kpis_by_date_range(
        self,
        hostel_id: Optional[UUID],
        start_date: date,
        end_date: date
    ) -> List[ComplaintKPI]:
        """Get all complaint KPIs within date range."""
        query = QueryBuilder(ComplaintKPI, self.db)
        
        if hostel_id:
            query = query.where(ComplaintKPI.hostel_id == hostel_id)
        
        query = query.where(
            or_(
                and_(
                    ComplaintKPI.period_start >= start_date,
                    ComplaintKPI.period_start <= end_date
                ),
                and_(
                    ComplaintKPI.period_end >= start_date,
                    ComplaintKPI.period_end <= end_date
                )
            )
        ).order_by(ComplaintKPI.period_start.desc())
        
        return query.all()
    
    # ==================== SLA Metrics ====================
    
    def create_sla_metrics(
        self,
        complaint_kpi_id: UUID,
        sla_data: Dict[str, Any]
    ) -> SLAMetrics:
        """Create or update SLA metrics for a complaint KPI."""
        existing = self.db.query(SLAMetrics).filter(
            SLAMetrics.complaint_kpi_id == complaint_kpi_id
        ).first()
        
        if existing:
            for key, value in sla_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = SLAMetrics(
            complaint_kpi_id=complaint_kpi_id,
            **sla_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def calculate_sla_compliance_rate(
        self,
        total_with_sla: int,
        met_sla: int
    ) -> Decimal:
        """Calculate SLA compliance rate percentage."""
        if total_with_sla == 0:
            return Decimal('0.00')
        
        rate = (met_sla / total_with_sla) * 100
        return Decimal(str(round(rate, 2)))
    
    def get_sla_breach_analysis(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Analyze SLA breaches for the period."""
        kpi = self.get_complaint_kpi(hostel_id, period_start, period_end)
        
        if not kpi or not kpi.sla_metrics:
            return self._empty_sla_analysis()
        
        sla = kpi.sla_metrics
        
        return {
            'total_with_sla': sla.total_with_sla,
            'met_sla': sla.met_sla,
            'breached_sla': sla.breached_sla,
            'compliance_rate': float(sla.sla_compliance_rate),
            'average_buffer_hours': float(sla.average_sla_buffer_hours),
            'at_risk_count': sla.at_risk_count,
            'breach_rate': (
                float(sla.breached_sla / sla.total_with_sla * 100)
                if sla.total_with_sla > 0 else 0
            ),
            'risk_percentage': (
                float(sla.at_risk_count / kpi.open_complaints * 100)
                if kpi.open_complaints > 0 else 0
            ),
        }
    
    def _empty_sla_analysis(self) -> Dict[str, Any]:
        """Return empty SLA analysis."""
        return {
            'total_with_sla': 0,
            'met_sla': 0,
            'breached_sla': 0,
            'compliance_rate': 0,
            'average_buffer_hours': 0,
            'at_risk_count': 0,
            'breach_rate': 0,
            'risk_percentage': 0,
        }
    
    def identify_sla_risk_complaints(
        self,
        hostel_id: Optional[UUID],
        hours_threshold: int = 24
    ) -> List[Dict[str, Any]]:
        """
        Identify complaints at risk of SLA breach.
        
        Args:
            hostel_id: Hostel ID
            hours_threshold: Hours before SLA breach to flag
            
        Returns:
            List of at-risk complaint summaries
        """
        # This would query actual Complaint model (not analytics)
        # Placeholder for structure
        return []
    
    # ==================== Trend Analysis ====================
    
    def add_complaint_trend_points(
        self,
        kpi_id: UUID,
        trend_points: List[Dict[str, Any]]
    ) -> List[ComplaintTrendPoint]:
        """Add multiple complaint trend points."""
        created_points = []
        
        for point_data in trend_points:
            existing = self.db.query(ComplaintTrendPoint).filter(
                and_(
                    ComplaintTrendPoint.kpi_id == kpi_id,
                    ComplaintTrendPoint.trend_date == point_data['trend_date']
                )
            ).first()
            
            if existing:
                for key, value in point_data.items():
                    if key != 'trend_date':
                        setattr(existing, key, value)
                created_points.append(existing)
            else:
                point = ComplaintTrendPoint(
                    kpi_id=kpi_id,
                    **point_data
                )
                self.db.add(point)
                created_points.append(point)
        
        self.db.commit()
        for point in created_points:
            self.db.refresh(point)
        
        return created_points
    
    def get_complaint_trend_points(
        self,
        kpi_id: UUID,
        start_date: Optional[date] = None,
        end_date: Optional[date] = None
    ) -> List[ComplaintTrendPoint]:
        """Get complaint trend points for a KPI."""
        query = QueryBuilder(ComplaintTrendPoint, self.db)
        query = query.where(ComplaintTrendPoint.kpi_id == kpi_id)
        
        if start_date:
            query = query.where(ComplaintTrendPoint.trend_date >= start_date)
        if end_date:
            query = query.where(ComplaintTrendPoint.trend_date <= end_date)
        
        query = query.order_by(ComplaintTrendPoint.trend_date.asc())
        
        return query.all()
    
    def analyze_complaint_trends(
        self,
        kpi_id: UUID
    ) -> Dict[str, Any]:
        """Analyze trends in complaint metrics."""
        points = self.get_complaint_trend_points(kpi_id)
        
        if len(points) < 2:
            return {
                'direction': 'stable',
                'volume_trend': 'stable',
                'resolution_trend': 'stable',
                'escalation_trend': 'stable',
            }
        
        # Volume trend
        first_half_volume = sum(
            p.total_complaints for p in points[:len(points)//2]
        ) / (len(points)//2)
        
        second_half_volume = sum(
            p.total_complaints for p in points[len(points)//2:]
        ) / (len(points) - len(points)//2)
        
        volume_trend = self._determine_trend_direction(
            first_half_volume, second_half_volume
        )
        
        # Resolution trend
        first_half_resolution = sum(
            p.resolved_complaints for p in points[:len(points)//2]
        ) / (len(points)//2)
        
        second_half_resolution = sum(
            p.resolved_complaints for p in points[len(points)//2:]
        ) / (len(points) - len(points)//2)
        
        resolution_trend = self._determine_trend_direction(
            first_half_resolution, second_half_resolution
        )
        
        # Escalation trend
        first_half_escalation = sum(
            p.escalated for p in points[:len(points)//2]
        ) / (len(points)//2)
        
        second_half_escalation = sum(
            p.escalated for p in points[len(points)//2:]
        ) / (len(points) - len(points)//2)
        
        escalation_trend = self._determine_trend_direction(
            first_half_escalation, second_half_escalation
        )
        
        # Overall direction
        if volume_trend == 'increasing' and resolution_trend != 'increasing':
            overall = 'worsening'
        elif volume_trend == 'decreasing' and resolution_trend == 'increasing':
            overall = 'improving'
        else:
            overall = 'stable'
        
        return {
            'direction': overall,
            'volume_trend': volume_trend,
            'resolution_trend': resolution_trend,
            'escalation_trend': escalation_trend,
            'data_points': len(points),
        }
    
    def _determine_trend_direction(
        self,
        first_value: float,
        second_value: float,
        threshold: float = 0.1
    ) -> str:
        """Determine trend direction based on values."""
        if first_value == 0:
            return 'stable'
        
        change = (second_value - first_value) / first_value
        
        if change > threshold:
            return 'increasing'
        elif change < -threshold:
            return 'decreasing'
        else:
            return 'stable'
    
    # ==================== Category Analysis ====================
    
    def create_category_breakdown(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        category: str,
        breakdown_data: Dict[str, Any]
    ) -> CategoryBreakdown:
        """Create or update category breakdown."""
        existing = self.db.query(CategoryBreakdown).filter(
            and_(
                CategoryBreakdown.hostel_id == hostel_id if hostel_id else CategoryBreakdown.hostel_id.is_(None),
                CategoryBreakdown.period_start == period_start,
                CategoryBreakdown.period_end == period_end,
                CategoryBreakdown.category == category
            )
        ).first()
        
        if existing:
            for key, value in breakdown_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        breakdown = CategoryBreakdown(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            category=category,
            **breakdown_data
        )
        
        self.db.add(breakdown)
        self.db.commit()
        self.db.refresh(breakdown)
        
        return breakdown
    
    def get_category_breakdowns(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[CategoryBreakdown]:
        """Get all category breakdowns for period."""
        query = QueryBuilder(CategoryBreakdown, self.db)
        
        if hostel_id:
            query = query.where(CategoryBreakdown.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                CategoryBreakdown.period_start == period_start,
                CategoryBreakdown.period_end == period_end
            )
        ).order_by(CategoryBreakdown.count.desc())
        
        return query.all()
    
    def get_top_complaint_categories(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """Get top complaint categories by volume."""
        breakdowns = self.get_category_breakdowns(
            hostel_id, period_start, period_end
        )
        
        top_categories = breakdowns[:limit]
        
        return [
            {
                'category': b.category,
                'count': b.count,
                'percentage': float(b.percentage_of_total),
                'resolution_rate': float(b.resolution_rate) if b.resolution_rate else 0,
                'avg_resolution_time': float(b.average_resolution_time_hours),
            }
            for b in top_categories
        ]
    
    def identify_problem_categories(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[Dict[str, Any]]:
        """Identify categories with poor performance."""
        breakdowns = self.get_category_breakdowns(
            hostel_id, period_start, period_end
        )
        
        problem_categories = []
        
        for breakdown in breakdowns:
            issues = []
            
            # High volume
            if float(breakdown.percentage_of_total) > 20:
                issues.append('high_volume')
            
            # Low resolution rate
            if breakdown.resolution_rate and float(breakdown.resolution_rate) < 70:
                issues.append('low_resolution_rate')
            
            # High resolution time
            if float(breakdown.average_resolution_time_hours) > 48:
                issues.append('slow_resolution')
            
            # High open count
            if breakdown.open_count > breakdown.count * 0.3:
                issues.append('high_backlog')
            
            if issues:
                problem_categories.append({
                    'category': breakdown.category,
                    'issues': issues,
                    'count': breakdown.count,
                    'percentage': float(breakdown.percentage_of_total),
                    'open_count': breakdown.open_count,
                    'resolution_rate': float(breakdown.resolution_rate) if breakdown.resolution_rate else 0,
                    'avg_resolution_time': float(breakdown.average_resolution_time_hours),
                })
        
        # Sort by number of issues
        problem_categories.sort(key=lambda x: len(x['issues']), reverse=True)
        
        return problem_categories
    
    # ==================== Priority Analysis ====================
    
    def create_priority_breakdown(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        priority: str,
        breakdown_data: Dict[str, Any]
    ) -> PriorityBreakdown:
        """Create or update priority breakdown."""
        existing = self.db.query(PriorityBreakdown).filter(
            and_(
                PriorityBreakdown.hostel_id == hostel_id if hostel_id else PriorityBreakdown.hostel_id.is_(None),
                PriorityBreakdown.period_start == period_start,
                PriorityBreakdown.period_end == period_end,
                PriorityBreakdown.priority == priority
            )
        ).first()
        
        if existing:
            for key, value in breakdown_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        breakdown = PriorityBreakdown(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            priority=priority,
            **breakdown_data
        )
        
        self.db.add(breakdown)
        self.db.commit()
        self.db.refresh(breakdown)
        
        return breakdown
    
    def get_priority_breakdowns(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[PriorityBreakdown]:
        """Get all priority breakdowns for period."""
        query = QueryBuilder(PriorityBreakdown, self.db)
        
        if hostel_id:
            query = query.where(PriorityBreakdown.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                PriorityBreakdown.period_start == period_start,
                PriorityBreakdown.period_end == period_end
            )
        ).order_by(PriorityBreakdown.priority_score.desc())
        
        return query.all()
    
    def analyze_priority_distribution(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[str, Any]:
        """Analyze complaint distribution by priority."""
        breakdowns = self.get_priority_breakdowns(
            hostel_id, period_start, period_end
        )
        
        total = sum(b.count for b in breakdowns)
        
        distribution = {
            b.priority: {
                'count': b.count,
                'percentage': float(b.percentage_of_total),
                'avg_resolution_time': float(b.average_resolution_time_hours),
                'sla_compliance': float(b.sla_compliance_rate),
            }
            for b in breakdowns
        }
        
        # Identify concerns
        concerns = []
        
        for breakdown in breakdowns:
            # High priority with low SLA compliance
            if breakdown.priority.lower() in ['urgent', 'critical', 'high']:
                if float(breakdown.sla_compliance_rate) < 80:
                    concerns.append({
                        'priority': breakdown.priority,
                        'issue': 'low_sla_compliance',
                        'value': float(breakdown.sla_compliance_rate),
                    })
        
        return {
            'total_complaints': total,
            'distribution': distribution,
            'concerns': concerns,
        }
    
    # ==================== Dashboard Creation ====================
    
    def create_complaint_dashboard(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> ComplaintDashboard:
        """Create comprehensive complaint dashboard."""
        # Get related data
        kpi = self.get_complaint_kpi(hostel_id, period_start, period_end)
        
        categories = self.get_category_breakdowns(
            hostel_id, period_start, period_end
        )
        
        priorities = self.get_priority_breakdowns(
            hostel_id, period_start, period_end
        )
        
        # Calculate aggregates
        total_complaints = kpi.total_complaints if kpi else 0
        open_complaints = kpi.open_complaints if kpi else 0
        
        # Count urgent (high priority)
        urgent_complaints = sum(
            p.count for p in priorities
            if p.priority.lower() in ['urgent', 'critical']
        )
        
        # Most common category
        most_common_category = categories[0].category if categories else None
        
        # Slowest category
        slowest_category = max(
            categories,
            key=lambda c: c.average_resolution_time_hours
        ).category if categories else None
        
        # High priority percentage
        high_priority_count = sum(
            p.count for p in priorities
            if p.priority.lower() in ['high', 'urgent', 'critical']
        )
        high_priority_percentage = (
            Decimal(str(high_priority_count / total_complaints * 100))
            if total_complaints > 0 else Decimal('0')
        )
        
        # Build JSON breakdowns
        category_breakdown_json = [
            {
                'category': c.category,
                'count': c.count,
                'percentage': float(c.percentage_of_total),
                'resolution_rate': float(c.resolution_rate) if c.resolution_rate else 0,
            }
            for c in categories
        ]
        
        priority_breakdown_json = [
            {
                'priority': p.priority,
                'count': p.count,
                'percentage': float(p.percentage_of_total),
                'sla_compliance': float(p.sla_compliance_rate),
            }
            for p in priorities
        ]
        
        # Generate insights
        problem_categories = self.identify_problem_categories(
            hostel_id, period_start, period_end
        )
        
        priority_analysis = self.analyze_priority_distribution(
            hostel_id, period_start, period_end
        )
        
        actionable_insights = {
            'problem_categories': problem_categories,
            'priority_concerns': priority_analysis.get('concerns', []),
            'recommendations': self._generate_complaint_recommendations(
                kpi, categories, priorities
            ),
        }
        
        # Create or update dashboard
        existing = self.db.query(ComplaintDashboard).filter(
            and_(
                ComplaintDashboard.hostel_id == hostel_id if hostel_id else ComplaintDashboard.hostel_id.is_(None),
                ComplaintDashboard.period_start == period_start,
                ComplaintDashboard.period_end == period_end
            )
        ).first()
        
        dashboard_data = {
            'kpi_id': kpi.id if kpi else None,
            'total_complaints': total_complaints,
            'open_complaints': open_complaints,
            'urgent_complaints': urgent_complaints,
            'most_common_category': most_common_category,
            'slowest_category': slowest_category,
            'high_priority_percentage': high_priority_percentage,
            'category_breakdown_json': category_breakdown_json,
            'priority_breakdown_json': priority_breakdown_json,
            'actionable_insights': actionable_insights,
            'is_cached': True,
            'cache_expires_at': datetime.utcnow() + timedelta(hours=1),
            'calculated_at': datetime.utcnow(),
        }
        
        if existing:
            for key, value in dashboard_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        dashboard = ComplaintDashboard(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **dashboard_data
        )
        
        self.db.add(dashboard)
        self.db.commit()
        self.db.refresh(dashboard)
        
        return dashboard
    
    def _generate_complaint_recommendations(
        self,
        kpi: Optional[ComplaintKPI],
        categories: List[CategoryBreakdown],
        priorities: List[PriorityBreakdown]
    ) -> List[str]:
        """Generate actionable recommendations."""
        recommendations = []
        
        if not kpi:
            return recommendations
        
        # SLA compliance
        if float(kpi.sla_compliance_rate) < 80:
            recommendations.append(
                'Improve SLA compliance - currently below target at '
                f'{float(kpi.sla_compliance_rate):.1f}%'
            )
        
        # Resolution time
        if float(kpi.average_resolution_time_hours) > 48:
            recommendations.append(
                'Reduce average resolution time - currently at '
                f'{float(kpi.average_resolution_time_hours):.1f} hours'
            )
        
        # Escalation rate
        if float(kpi.escalation_rate) > 15:
            recommendations.append(
                'High escalation rate detected - review first-level resolution capabilities'
            )
        
        # Reopen rate
        if float(kpi.reopen_rate) > 10:
            recommendations.append(
                'High reopen rate - improve quality of initial resolutions'
            )
        
        # Category concentration
        if categories:
            top_category = categories[0]
            if float(top_category.percentage_of_total) > 30:
                recommendations.append(
                    f'Address high volume of {top_category.category} complaints '
                    f'({float(top_category.percentage_of_total):.1f}% of total)'
                )
        
        return recommendations
    
    # ==================== Performance Metrics ====================
    
    def calculate_efficiency_score(
        self,
        kpi: ComplaintKPI
    ) -> Decimal:
        """
        Calculate overall complaint handling efficiency score (0-100).
        
        Based on:
        - Resolution rate (30%)
        - SLA compliance (30%)
        - Average resolution time (20%)
        - Escalation rate (10%)
        - Reopen rate (10%)
        """
        # Resolution rate score
        resolution_rate = (
            kpi.resolved_complaints / kpi.total_complaints * 100
        ) if kpi.total_complaints > 0 else 0
        resolution_score = min(resolution_rate, 100)
        
        # SLA compliance score
        sla_score = float(kpi.sla_compliance_rate)
        
        # Resolution time score (inverse - faster is better)
        # Assume 24 hours is excellent, 72+ hours is poor
        time_hours = float(kpi.average_resolution_time_hours)
        if time_hours <= 24:
            time_score = 100
        elif time_hours >= 72:
            time_score = 0
        else:
            time_score = 100 - ((time_hours - 24) / 48 * 100)
        
        # Escalation score (inverse - lower is better)
        escalation_rate = float(kpi.escalation_rate)
        escalation_score = max(0, 100 - (escalation_rate * 5))
        
        # Reopen score (inverse - lower is better)
        reopen_rate = float(kpi.reopen_rate)
        reopen_score = max(0, 100 - (reopen_rate * 5))
        
        # Weighted average
        efficiency = (
            resolution_score * 0.30 +
            sla_score * 0.30 +
            time_score * 0.20 +
            escalation_score * 0.10 +
            reopen_score * 0.10
        )
        
        return Decimal(str(round(efficiency, 2)))
    
    def get_performance_comparison(
        self,
        hostel_ids: List[UUID],
        period_start: date,
        period_end: date
    ) -> Dict[UUID, Dict[str, Any]]:
        """Compare complaint performance across hostels."""
        comparison = {}
        
        for hostel_id in hostel_ids:
            kpi = self.get_complaint_kpi(hostel_id, period_start, period_end)
            
            if kpi:
                efficiency = self.calculate_efficiency_score(kpi)
                
                comparison[hostel_id] = {
                    'total_complaints': kpi.total_complaints,
                    'resolution_rate': float(
                        kpi.resolved_complaints / kpi.total_complaints * 100
                    ) if kpi.total_complaints > 0 else 0,
                    'sla_compliance': float(kpi.sla_compliance_rate),
                    'avg_resolution_time': float(kpi.average_resolution_time_hours),
                    'efficiency_score': float(efficiency),
                }
            else:
                comparison[hostel_id] = {
                    'total_complaints': 0,
                    'resolution_rate': 0,
                    'sla_compliance': 0,
                    'avg_resolution_time': 0,
                    'efficiency_score': 0,
                }
        
        # Add rankings
        sorted_by_efficiency = sorted(
            comparison.items(),
            key=lambda x: x[1]['efficiency_score'],
            reverse=True
        )
        
        for rank, (hostel_id, data) in enumerate(sorted_by_efficiency, start=1):
            comparison[hostel_id]['rank'] = rank
        
        return comparison
    
    # ==================== Predictive Analytics ====================
    
    def forecast_complaint_volume(
        self,
        hostel_id: Optional[UUID],
        forecast_days: int = 30
    ) -> List[Dict[str, Any]]:
        """Forecast complaint volume using historical trends."""
        # Get historical data (last 90 days)
        end_date = date.today()
        start_date = end_date - timedelta(days=90)
        
        kpis = self.get_complaint_kpis_by_date_range(
            hostel_id, start_date, end_date
        )
        
        if not kpis:
            return []
        
        # Get all trend points
        all_points = []
        for kpi in kpis:
            points = self.get_complaint_trend_points(kpi.id)
            all_points.extend(points)
        
        # Sort by date
        all_points.sort(key=lambda x: x.trend_date)
        
        if len(all_points) < 7:
            return []
        
        # Calculate moving average
        window_size = 7
        recent_values = [p.total_complaints for p in all_points[-window_size:]]
        moving_avg = sum(recent_values) / len(recent_values)
        
        # Calculate trend
        recent_avg = sum(recent_values[-3:]) / 3
        older_avg = sum(recent_values[:3]) / 3
        daily_trend = (recent_avg - older_avg) / 3
        
        # Generate forecast
        forecast = []
        current_date = end_date + timedelta(days=1)
        
        for i in range(forecast_days):
            forecasted_value = moving_avg + (daily_trend * i)
            forecasted_value = max(0, forecasted_value)
            
            # Confidence bounds
            lower_bound = forecasted_value * 0.7
            upper_bound = forecasted_value * 1.3
            
            forecast.append({
                'date': current_date + timedelta(days=i),
                'forecasted_complaints': round(forecasted_value),
                'lower_bound': round(lower_bound),
                'upper_bound': round(upper_bound),
                'confidence': 0.75,
            })
        
        return forecast

# --- File: C:\Hostel-Main\app\repositories\analytics\custom_reports_repository.py ---
"""
Custom Reports Repository for flexible report generation.

Provides comprehensive report management with:
- Report definition and template management
- Scheduled report execution
- Report result caching
- Execution history tracking
- Multi-format export capabilities
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta, time
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, desc
from sqlalchemy.orm import Session, joinedload
from uuid import UUID
import hashlib
import json

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.repositories.base.pagination import PaginationManager
from app.models.analytics.custom_reports import (
    CustomReportDefinition,
    ReportSchedule,
    ReportExecutionHistory,
    CachedReportResult,
)


class CustomReportsRepository(BaseRepository):
    """Repository for custom report operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
        self.pagination = PaginationManager()
    
    # ==================== Report Definition Operations ====================
    
    def create_report_definition(
        self,
        owner_id: UUID,
        report_data: Dict[str, Any]
    ) -> CustomReportDefinition:
        """
        Create a new custom report definition.
        
        Args:
            owner_id: User ID creating the report
            report_data: Report configuration data
            
        Returns:
            Created CustomReportDefinition instance
        """
        # Calculate complexity score
        complexity = self._calculate_report_complexity(report_data)
        
        report = CustomReportDefinition(
            owner_id=owner_id,
            complexity_score=complexity,
            **report_data
        )
        
        self.db.add(report)
        self.db.commit()
        self.db.refresh(report)
        
        return report
    
    def update_report_definition(
        self,
        report_id: UUID,
        update_data: Dict[str, Any]
    ) -> Optional[CustomReportDefinition]:
        """Update an existing report definition."""
        report = self.db.query(CustomReportDefinition).filter(
            CustomReportDefinition.id == report_id
        ).first()
        
        if not report:
            return None
        
        # Recalculate complexity if fields/filters changed
        if 'fields' in update_data or 'filters' in update_data:
            complexity = self._calculate_report_complexity(update_data)
            update_data['complexity_score'] = complexity
        
        for key, value in update_data.items():
            setattr(report, key, value)
        
        self.db.commit()
        self.db.refresh(report)
        
        return report
    
    def get_report_definition(
        self,
        report_id: UUID
    ) -> Optional[CustomReportDefinition]:
        """Get a report definition by ID."""
        return self.db.query(CustomReportDefinition).filter(
            CustomReportDefinition.id == report_id
        ).first()
    
    def get_user_reports(
        self,
        user_id: UUID,
        include_shared: bool = True,
        page: int = 1,
        page_size: int = 20
    ) -> Tuple[List[CustomReportDefinition], int]:
        """
        Get all reports accessible to a user.
        
        Args:
            user_id: User ID
            include_shared: Whether to include reports shared with user
            page: Page number
            page_size: Items per page
            
        Returns:
            Tuple of (reports list, total count)
        """
        query = QueryBuilder(CustomReportDefinition, self.db)
        
        if include_shared:
            # Include owned reports and reports shared with user
            query = query.where(
                or_(
                    CustomReportDefinition.owner_id == user_id,
                    CustomReportDefinition.shared_with_user_ids.contains([user_id]),
                    CustomReportDefinition.is_public == True
                )
            )
        else:
            query = query.where(CustomReportDefinition.owner_id == user_id)
        
        query = query.order_by(CustomReportDefinition.created_at.desc())
        
        # Get total count
        total = query.count()
        
        # Apply pagination
        offset = (page - 1) * page_size
        query = query.limit(page_size).offset(offset)
        
        reports = query.all()
        
        return reports, total
    
    def get_public_templates(
        self,
        module: Optional[str] = None,
        page: int = 1,
        page_size: int = 20
    ) -> Tuple[List[CustomReportDefinition], int]:
        """Get public report templates."""
        query = QueryBuilder(CustomReportDefinition, self.db)
        
        query = query.where(CustomReportDefinition.is_template == True)
        query = query.where(CustomReportDefinition.is_public == True)
        
        if module:
            query = query.where(CustomReportDefinition.module == module)
        
        query = query.order_by(CustomReportDefinition.run_count.desc())
        
        total = query.count()
        
        offset = (page - 1) * page_size
        query = query.limit(page_size).offset(offset)
        
        templates = query.all()
        
        return templates, total
    
    def search_reports(
        self,
        user_id: UUID,
        search_term: str,
        module: Optional[str] = None,
        page: int = 1,
        page_size: int = 20
    ) -> Tuple[List[CustomReportDefinition], int]:
        """Search reports by name or description."""
        query = QueryBuilder(CustomReportDefinition, self.db)
        
        # Access filter
        query = query.where(
            or_(
                CustomReportDefinition.owner_id == user_id,
                CustomReportDefinition.shared_with_user_ids.contains([user_id]),
                CustomReportDefinition.is_public == True
            )
        )
        
        # Search filter
        search_filter = or_(
            CustomReportDefinition.report_name.ilike(f'%{search_term}%'),
            CustomReportDefinition.description.ilike(f'%{search_term}%')
        )
        query = query.where(search_filter)
        
        # Module filter
        if module:
            query = query.where(CustomReportDefinition.module == module)
        
        total = query.count()
        
        offset = (page - 1) * page_size
        query = query.limit(page_size).offset(offset)
        
        reports = query.all()
        
        return reports, total
    
    def share_report(
        self,
        report_id: UUID,
        user_ids: Optional[List[UUID]] = None,
        role: Optional[str] = None,
        is_public: bool = False
    ) -> Optional[CustomReportDefinition]:
        """Share a report with users or roles."""
        report = self.get_report_definition(report_id)
        
        if not report:
            return None
        
        if user_ids:
            # Add to existing shared users
            existing_users = report.shared_with_user_ids or []
            new_users = list(set(existing_users + user_ids))
            report.shared_with_user_ids = new_users
        
        if role:
            report.shared_with_role = role
        
        if is_public:
            report.is_public = True
        
        report.is_shared = True
        
        self.db.commit()
        self.db.refresh(report)
        
        return report
    
    def unshare_report(
        self,
        report_id: UUID,
        user_ids: Optional[List[UUID]] = None
    ) -> Optional[CustomReportDefinition]:
        """Remove sharing for specific users."""
        report = self.get_report_definition(report_id)
        
        if not report:
            return None
        
        if user_ids and report.shared_with_user_ids:
            remaining_users = [
                uid for uid in report.shared_with_user_ids
                if uid not in user_ids
            ]
            report.shared_with_user_ids = remaining_users if remaining_users else None
        
        # Update is_shared flag
        report.is_shared = bool(
            report.shared_with_user_ids or 
            report.shared_with_role or 
            report.is_public
        )
        
        self.db.commit()
        self.db.refresh(report)
        
        return report
    
    def delete_report_definition(
        self,
        report_id: UUID,
        user_id: UUID
    ) -> bool:
        """
        Delete a report definition (only owner can delete).
        
        Args:
            report_id: Report ID
            user_id: User requesting deletion
            
        Returns:
            True if deleted, False if not found or unauthorized
        """
        report = self.db.query(CustomReportDefinition).filter(
            and_(
                CustomReportDefinition.id == report_id,
                CustomReportDefinition.owner_id == user_id
            )
        ).first()
        
        if not report:
            return False
        
        self.db.delete(report)
        self.db.commit()
        
        return True
    
    def _calculate_report_complexity(
        self,
        report_data: Dict[str, Any]
    ) -> int:
        """
        Calculate report complexity score (0-100).
        
        Based on:
        - Number of fields
        - Number of filters
        - Presence of grouping
        - Join complexity
        """
        score = 0
        
        # Field count (max 30 points)
        fields = report_data.get('fields', [])
        field_count = len(fields) if isinstance(fields, list) else 0
        score += min(field_count * 3, 30)
        
        # Filter count (max 30 points)
        filters = report_data.get('filters', {})
        filter_count = len(filters) if isinstance(filters, dict) else 0
        score += min(filter_count * 5, 30)
        
        # Grouping (20 points)
        if report_data.get('group_by'):
            score += 20
        
        # Sorting (10 points)
        if report_data.get('sort_by'):
            score += 10
        
        # Complex filters (10 points)
        if filters and any(
            isinstance(v, dict) for v in filters.values()
        ):
            score += 10
        
        return min(score, 100)
    
    # ==================== Report Scheduling ====================
    
    def create_schedule(
        self,
        report_definition_id: UUID,
        schedule_data: Dict[str, Any]
    ) -> ReportSchedule:
        """Create a new report schedule."""
        # Calculate next run time
        next_run = self._calculate_next_run_time(
            schedule_data.get('frequency'),
            schedule_data.get('time_of_day'),
            schedule_data.get('day_of_week'),
            schedule_data.get('day_of_month'),
            schedule_data.get('timezone', 'UTC')
        )
        
        schedule = ReportSchedule(
            report_definition_id=report_definition_id,
            next_run_at=next_run,
            **schedule_data
        )
        
        self.db.add(schedule)
        self.db.commit()
        self.db.refresh(schedule)
        
        return schedule
    
    def update_schedule(
        self,
        schedule_id: UUID,
        update_data: Dict[str, Any]
    ) -> Optional[ReportSchedule]:
        """Update a report schedule."""
        schedule = self.db.query(ReportSchedule).filter(
            ReportSchedule.id == schedule_id
        ).first()
        
        if not schedule:
            return None
        
        # Recalculate next run if schedule changed
        if any(key in update_data for key in ['frequency', 'time_of_day', 'day_of_week', 'day_of_month']):
            next_run = self._calculate_next_run_time(
                update_data.get('frequency', schedule.frequency),
                update_data.get('time_of_day', schedule.time_of_day),
                update_data.get('day_of_week', schedule.day_of_week),
                update_data.get('day_of_month', schedule.day_of_month),
                update_data.get('timezone', schedule.timezone)
            )
            update_data['next_run_at'] = next_run
        
        for key, value in update_data.items():
            setattr(schedule, key, value)
        
        self.db.commit()
        self.db.refresh(schedule)
        
        return schedule
    
    def get_schedule(
        self,
        schedule_id: UUID
    ) -> Optional[ReportSchedule]:
        """Get a report schedule by ID."""
        return self.db.query(ReportSchedule).filter(
            ReportSchedule.id == schedule_id
        ).first()
    
    def get_schedules_for_report(
        self,
        report_definition_id: UUID
    ) -> List[ReportSchedule]:
        """Get all schedules for a report."""
        return self.db.query(ReportSchedule).filter(
            ReportSchedule.report_definition_id == report_definition_id
        ).all()
    
    def get_due_schedules(
        self,
        current_time: Optional[datetime] = None
    ) -> List[ReportSchedule]:
        """Get schedules that are due for execution."""
        if not current_time:
            current_time = datetime.utcnow()
        
        return self.db.query(ReportSchedule).filter(
            and_(
                ReportSchedule.is_active == True,
                ReportSchedule.next_run_at <= current_time
            )
        ).all()
    
    def update_schedule_after_execution(
        self,
        schedule_id: UUID,
        status: str,
        error_message: Optional[str] = None
    ) -> Optional[ReportSchedule]:
        """Update schedule after execution."""
        schedule = self.get_schedule(schedule_id)
        
        if not schedule:
            return None
        
        schedule.last_run_at = datetime.utcnow()
        schedule.last_run_status = status
        schedule.execution_count += 1
        
        if status == 'failed':
            schedule.failure_count += 1
            
            # Disable after 5 consecutive failures
            if schedule.failure_count >= 5:
                schedule.is_active = False
        else:
            schedule.failure_count = 0  # Reset on success
        
        # Calculate next run
        schedule.next_run_at = self._calculate_next_run_time(
            schedule.frequency,
            schedule.time_of_day,
            schedule.day_of_week,
            schedule.day_of_month,
            schedule.timezone
        )
        
        self.db.commit()
        self.db.refresh(schedule)
        
        return schedule
    
    def delete_schedule(
        self,
        schedule_id: UUID
    ) -> bool:
        """Delete a report schedule."""
        schedule = self.db.query(ReportSchedule).filter(
            ReportSchedule.id == schedule_id
        ).first()
        
        if not schedule:
            return False
        
        self.db.delete(schedule)
        self.db.commit()
        
        return True
    
    def _calculate_next_run_time(
        self,
        frequency: str,
        time_of_day: time,
        day_of_week: Optional[int],
        day_of_month: Optional[int],
        timezone: str
    ) -> datetime:
        """Calculate next scheduled run time."""
        # Simplified calculation (assumes UTC)
        now = datetime.utcnow()
        
        # Combine today's date with scheduled time
        next_run = datetime.combine(now.date(), time_of_day)
        
        if frequency == 'daily':
            # If time has passed today, schedule for tomorrow
            if next_run <= now:
                next_run += timedelta(days=1)
        
        elif frequency == 'weekly':
            # Find next occurrence of day_of_week
            current_weekday = now.weekday()
            days_ahead = (day_of_week - current_weekday) % 7
            
            if days_ahead == 0 and next_run <= now:
                days_ahead = 7
            
            next_run += timedelta(days=days_ahead)
        
        elif frequency == 'monthly':
            # Find next occurrence of day_of_month
            if day_of_month <= now.day and next_run <= now:
                # Next month
                if now.month == 12:
                    next_month = datetime(now.year + 1, 1, day_of_month)
                else:
                    next_month = datetime(now.year, now.month + 1, day_of_month)
                next_run = datetime.combine(next_month.date(), time_of_day)
            else:
                next_run = datetime.combine(
                    datetime(now.year, now.month, day_of_month).date(),
                    time_of_day
                )
        
        elif frequency == 'quarterly':
            # Next quarter
            quarter_months = [1, 4, 7, 10]
            current_quarter_month = min(
                [m for m in quarter_months if m >= now.month],
                default=1
            )
            
            if current_quarter_month == 1:
                next_year = now.year + 1
            else:
                next_year = now.year
            
            next_run = datetime.combine(
                datetime(next_year, current_quarter_month, day_of_month or 1).date(),
                time_of_day
            )
        
        return next_run
    
    # ==================== Execution History ====================
    
    def create_execution_history(
        self,
        report_definition_id: UUID,
        execution_data: Dict[str, Any]
    ) -> ReportExecutionHistory:
        """Create a new execution history record."""
        history = ReportExecutionHistory(
            report_definition_id=report_definition_id,
            started_at=datetime.utcnow(),
            **execution_data
        )
        
        self.db.add(history)
        self.db.commit()
        self.db.refresh(history)
        
        return history
    
    def update_execution_history(
        self,
        execution_id: UUID,
        update_data: Dict[str, Any]
    ) -> Optional[ReportExecutionHistory]:
        """Update execution history record."""
        history = self.db.query(ReportExecutionHistory).filter(
            ReportExecutionHistory.id == execution_id
        ).first()
        
        if not history:
            return None
        
        # Calculate execution time if completed
        if 'completed_at' in update_data and not history.completed_at:
            completed_at = update_data['completed_at']
            execution_time = int(
                (completed_at - history.started_at).total_seconds() * 1000
            )
            update_data['execution_time_ms'] = execution_time
        
        for key, value in update_data.items():
            setattr(history, key, value)
        
        self.db.commit()
        self.db.refresh(history)
        
        return history
    
    def get_execution_history(
        self,
        report_definition_id: UUID,
        limit: int = 10
    ) -> List[ReportExecutionHistory]:
        """Get execution history for a report."""
        return self.db.query(ReportExecutionHistory).filter(
            ReportExecutionHistory.report_definition_id == report_definition_id
        ).order_by(
            ReportExecutionHistory.started_at.desc()
        ).limit(limit).all()
    
    def get_execution_statistics(
        self,
        report_definition_id: UUID
    ) -> Dict[str, Any]:
        """Get execution statistics for a report."""
        history = self.db.query(ReportExecutionHistory).filter(
            ReportExecutionHistory.report_definition_id == report_definition_id
        ).all()
        
        if not history:
            return {
                'total_executions': 0,
                'successful_executions': 0,
                'failed_executions': 0,
                'success_rate': 0,
                'average_execution_time_ms': 0,
            }
        
        successful = [h for h in history if h.status == 'completed']
        failed = [h for h in history if h.status == 'failed']
        
        execution_times = [
            h.execution_time_ms for h in successful
            if h.execution_time_ms is not None
        ]
        
        avg_time = (
            sum(execution_times) / len(execution_times)
            if execution_times else 0
        )
        
        return {
            'total_executions': len(history),
            'successful_executions': len(successful),
            'failed_executions': len(failed),
            'success_rate': (len(successful) / len(history) * 100) if history else 0,
            'average_execution_time_ms': round(avg_time),
            'last_execution': history[0].started_at if history else None,
        }
    
    # ==================== Result Caching ====================
    
    def cache_report_result(
        self,
        report_definition_id: UUID,
        execution_history_id: Optional[UUID],
        result_data: Any,
        parameters: Dict[str, Any],
        cache_ttl_seconds: int = 3600
    ) -> CachedReportResult:
        """Cache report execution result."""
        # Generate parameter hash for cache key
        params_hash = self._generate_parameters_hash(parameters)
        
        # Calculate column definitions from result
        column_definitions = self._extract_column_definitions(result_data)
        
        # Calculate summary stats
        summary_stats = self._calculate_summary_statistics(result_data)
        
        # Count rows
        row_count = len(result_data) if isinstance(result_data, list) else 0
        
        # Calculate data size
        data_json = json.dumps(result_data)
        data_size = len(data_json.encode('utf-8'))
        
        # Set expiration
        cache_expires_at = datetime.utcnow() + timedelta(seconds=cache_ttl_seconds)
        
        # Check for existing cache
        existing = self.db.query(CachedReportResult).filter(
            and_(
                CachedReportResult.report_definition_id == report_definition_id,
                CachedReportResult.parameters_hash == params_hash
            )
        ).first()
        
        if existing:
            # Update existing cache
            existing.result_data = result_data
            existing.row_count = row_count
            existing.column_definitions = column_definitions
            existing.summary_stats = summary_stats
            existing.data_size_bytes = data_size
            existing.generated_at = datetime.utcnow()
            existing.cache_expires_at = cache_expires_at
            existing.execution_history_id = execution_history_id
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        # Create new cache
        cached_result = CachedReportResult(
            report_definition_id=report_definition_id,
            execution_history_id=execution_history_id,
            result_data=result_data,
            row_count=row_count,
            column_definitions=column_definitions,
            summary_stats=summary_stats,
            parameters_hash=params_hash,
            data_size_bytes=data_size,
            cache_expires_at=cache_expires_at,
            is_cached=True
        )
        
        self.db.add(cached_result)
        self.db.commit()
        self.db.refresh(cached_result)
        
        return cached_result
    
    def get_cached_result(
        self,
        report_definition_id: UUID,
        parameters: Dict[str, Any]
    ) -> Optional[CachedReportResult]:
        """Get cached result if available and valid."""
        params_hash = self._generate_parameters_hash(parameters)
        
        cached = self.db.query(CachedReportResult).filter(
            and_(
                CachedReportResult.report_definition_id == report_definition_id,
                CachedReportResult.parameters_hash == params_hash,
                CachedReportResult.cache_expires_at > datetime.utcnow()
            )
        ).first()
        
        if cached:
            # Increment hit count
            cached.cache_hit_count += 1
            self.db.commit()
        
        return cached
    
    def invalidate_report_cache(
        self,
        report_definition_id: UUID
    ) -> int:
        """Invalidate all cached results for a report."""
        count = self.db.query(CachedReportResult).filter(
            CachedReportResult.report_definition_id == report_definition_id
        ).update({
            'cache_expires_at': datetime.utcnow()
        })
        
        self.db.commit()
        
        return count
    
    def cleanup_expired_cache(
        self,
        before_date: Optional[datetime] = None
    ) -> int:
        """Delete expired cache entries."""
        if not before_date:
            before_date = datetime.utcnow()
        
        count = self.db.query(CachedReportResult).filter(
            CachedReportResult.cache_expires_at < before_date
        ).delete()
        
        self.db.commit()
        
        return count
    
    def _generate_parameters_hash(
        self,
        parameters: Dict[str, Any]
    ) -> str:
        """Generate hash from parameters for caching."""
        # Sort parameters for consistent hashing
        sorted_params = json.dumps(parameters, sort_keys=True)
        
        # Generate SHA256 hash
        hash_object = hashlib.sha256(sorted_params.encode())
        
        return hash_object.hexdigest()
    
    def _extract_column_definitions(
        self,
        result_data: Any
    ) -> Dict[str, Any]:
        """Extract column definitions from result data."""
        if not result_data or not isinstance(result_data, list):
            return {}
        
        if not result_data[0]:
            return {}
        
        first_row = result_data[0]
        
        columns = {}
        for key, value in first_row.items():
            columns[key] = {
                'type': type(value).__name__,
                'nullable': value is None,
            }
        
        return columns
    
    def _calculate_summary_statistics(
        self,
        result_data: Any
    ) -> Dict[str, Any]:
        """Calculate summary statistics for numeric columns."""
        if not result_data or not isinstance(result_data, list):
            return {}
        
        summary = {
            'row_count': len(result_data),
        }
        
        # Find numeric columns
        if result_data:
            first_row = result_data[0]
            numeric_columns = [
                key for key, value in first_row.items()
                if isinstance(value, (int, float, Decimal))
            ]
            
            # Calculate stats for each numeric column
            for col in numeric_columns:
                values = [
                    row[col] for row in result_data
                    if row.get(col) is not None
                ]
                
                if values:
                    summary[col] = {
                        'min': min(values),
                        'max': max(values),
                        'sum': sum(values),
                        'avg': sum(values) / len(values),
                        'count': len(values),
                    }
        
        return summary
    
    # ==================== Report Execution ====================
    
    def increment_run_count(
        self,
        report_definition_id: UUID
    ) -> Optional[CustomReportDefinition]:
        """Increment run count for a report."""
        report = self.get_report_definition(report_definition_id)
        
        if not report:
            return None
        
        report.run_count += 1
        report.last_run_at = datetime.utcnow()
        
        self.db.commit()
        self.db.refresh(report)
        
        return report

# --- File: C:\Hostel-Main\app\repositories\analytics\dashboard_analytics_repository.py ---
"""
Dashboard Analytics Repository for unified metrics display.

Provides comprehensive dashboard data management with:
- Generic KPI tracking and storage
- Widget configuration and management
- Time-series metric collection
- Alert notification handling
- Quick stats aggregation
- Role-specific dashboard customization
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, desc
from sqlalchemy.orm import Session, joinedload
from uuid import UUID

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.models.analytics.dashboard_analytics import (
    DashboardKPI,
    TimeseriesMetric,
    DashboardWidget,
    AlertNotification,
    QuickStats,
    RoleSpecificDashboard,
)


class DashboardAnalyticsRepository(BaseRepository):
    """Repository for dashboard analytics operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
    
    # ==================== Dashboard KPI Operations ====================
    
    def create_or_update_kpi(
        self,
        hostel_id: Optional[UUID],
        kpi_key: str,
        period_start: date,
        period_end: date,
        kpi_data: Dict[str, Any]
    ) -> DashboardKPI:
        """
        Create or update a dashboard KPI.
        
        Args:
            hostel_id: Hostel ID (None for platform-wide)
            kpi_key: Unique KPI identifier
            period_start: Period start date
            period_end: Period end date
            kpi_data: KPI data including value, target, etc.
            
        Returns:
            Created or updated DashboardKPI instance
        """
        existing = self.db.query(DashboardKPI).filter(
            and_(
                DashboardKPI.hostel_id == hostel_id if hostel_id else DashboardKPI.hostel_id.is_(None),
                DashboardKPI.kpi_key == kpi_key,
                DashboardKPI.period_start == period_start,
                DashboardKPI.period_end == period_end
            )
        ).first()
        
        # Calculate performance status
        performance_status = self._calculate_kpi_performance_status(kpi_data)
        kpi_data['performance_status'] = performance_status
        
        # Determine if on target
        is_on_target = self._is_kpi_on_target(kpi_data)
        kpi_data['is_on_target'] = is_on_target
        
        if existing:
            for key, value in kpi_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        kpi = DashboardKPI(
            hostel_id=hostel_id,
            kpi_key=kpi_key,
            period_start=period_start,
            period_end=period_end,
            **kpi_data
        )
        
        self.db.add(kpi)
        self.db.commit()
        self.db.refresh(kpi)
        
        return kpi
    
    def get_kpi(
        self,
        hostel_id: Optional[UUID],
        kpi_key: str,
        period_start: date,
        period_end: date
    ) -> Optional[DashboardKPI]:
        """Get a specific KPI."""
        return self.db.query(DashboardKPI).filter(
            and_(
                DashboardKPI.hostel_id == hostel_id if hostel_id else DashboardKPI.hostel_id.is_(None),
                DashboardKPI.kpi_key == kpi_key,
                DashboardKPI.period_start == period_start,
                DashboardKPI.period_end == period_end
            )
        ).first()
    
    def get_kpis_by_category(
        self,
        hostel_id: Optional[UUID],
        category: str,
        period_start: date,
        period_end: date
    ) -> List[DashboardKPI]:
        """Get all KPIs in a category."""
        query = QueryBuilder(DashboardKPI, self.db)
        
        if hostel_id:
            query = query.where(DashboardKPI.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                DashboardKPI.kpi_category == category,
                DashboardKPI.period_start == period_start,
                DashboardKPI.period_end == period_end
            )
        )
        
        return query.all()
    
    def get_all_kpis_for_period(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[DashboardKPI]:
        """Get all KPIs for a period."""
        query = QueryBuilder(DashboardKPI, self.db)
        
        if hostel_id:
            query = query.where(DashboardKPI.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                DashboardKPI.period_start == period_start,
                DashboardKPI.period_end == period_end
            )
        )
        
        return query.all()
    
    def _calculate_kpi_performance_status(
        self,
        kpi_data: Dict[str, Any]
    ) -> str:
        """Calculate performance status based on value and target."""
        value = kpi_data.get('metric_value')
        target = kpi_data.get('target_value')
        good_when = kpi_data.get('good_when')
        
        if value is None or target is None:
            return 'unknown'
        
        value = float(value)
        target = float(target)
        
        # Calculate percentage of target
        if target == 0:
            return 'unknown'
        
        percentage = (value / target) * 100
        
        if good_when == 'higher_is_better':
            if percentage >= 100:
                return 'excellent'
            elif percentage >= 90:
                return 'good'
            elif percentage >= 70:
                return 'warning'
            else:
                return 'critical'
        
        elif good_when == 'lower_is_better':
            if percentage <= 100:
                return 'excellent'
            elif percentage <= 110:
                return 'good'
            elif percentage <= 130:
                return 'warning'
            else:
                return 'critical'
        
        else:  # closer_to_target
            diff_percentage = abs(100 - percentage)
            if diff_percentage <= 5:
                return 'excellent'
            elif diff_percentage <= 10:
                return 'good'
            elif diff_percentage <= 20:
                return 'warning'
            else:
                return 'critical'
    
    def _is_kpi_on_target(
        self,
        kpi_data: Dict[str, Any]
    ) -> bool:
        """Determine if KPI is on target."""
        status = kpi_data.get('performance_status', 'unknown')
        return status in ['excellent', 'good']
    
    # ==================== Time Series Metrics ====================
    
    def add_timeseries_metric(
        self,
        metric_key: str,
        hostel_id: Optional[UUID],
        data_date: date,
        value: Decimal,
        label: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> TimeseriesMetric:
        """Add a time series data point."""
        existing = self.db.query(TimeseriesMetric).filter(
            and_(
                TimeseriesMetric.metric_key == metric_key,
                TimeseriesMetric.hostel_id == hostel_id if hostel_id else TimeseriesMetric.hostel_id.is_(None),
                TimeseriesMetric.data_date == data_date
            )
        ).first()
        
        if existing:
            existing.value = value
            if label:
                existing.label = label
            if metadata:
                existing.metadata = metadata
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metric = TimeseriesMetric(
            metric_key=metric_key,
            hostel_id=hostel_id,
            data_date=data_date,
            value=value,
            label=label,
            metadata=metadata
        )
        
        self.db.add(metric)
        self.db.commit()
        self.db.refresh(metric)
        
        return metric
    
    def get_timeseries_metrics(
        self,
        metric_key: str,
        hostel_id: Optional[UUID],
        start_date: date,
        end_date: date
    ) -> List[TimeseriesMetric]:
        """Get time series metrics for a date range."""
        query = QueryBuilder(TimeseriesMetric, self.db)
        
        query = query.where(TimeseriesMetric.metric_key == metric_key)
        
        if hostel_id:
            query = query.where(TimeseriesMetric.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                TimeseriesMetric.data_date >= start_date,
                TimeseriesMetric.data_date <= end_date
            )
        ).order_by(TimeseriesMetric.data_date.asc())
        
        return query.all()
    
    def get_latest_metric_value(
        self,
        metric_key: str,
        hostel_id: Optional[UUID]
    ) -> Optional[TimeseriesMetric]:
        """Get the latest value for a metric."""
        query = QueryBuilder(TimeseriesMetric, self.db)
        
        query = query.where(TimeseriesMetric.metric_key == metric_key)
        
        if hostel_id:
            query = query.where(TimeseriesMetric.hostel_id == hostel_id)
        
        query = query.order_by(TimeseriesMetric.data_date.desc())
        
        return query.first()
    
    def calculate_metric_trend(
        self,
        metric_key: str,
        hostel_id: Optional[UUID],
        days: int = 30
    ) -> Dict[str, Any]:
        """Calculate trend for a metric over recent days."""
        end_date = date.today()
        start_date = end_date - timedelta(days=days)
        
        metrics = self.get_timeseries_metrics(
            metric_key, hostel_id, start_date, end_date
        )
        
        if len(metrics) < 2:
            return {
                'direction': 'stable',
                'percentage_change': 0,
                'data_points': len(metrics),
            }
        
        values = [float(m.value) for m in metrics]
        
        # Compare first half to second half
        mid_point = len(values) // 2
        first_half_avg = sum(values[:mid_point]) / mid_point
        second_half_avg = sum(values[mid_point:]) / (len(values) - mid_point)
        
        if first_half_avg == 0:
            percentage_change = 0
        else:
            percentage_change = ((second_half_avg - first_half_avg) / first_half_avg) * 100
        
        if percentage_change > 5:
            direction = 'up'
        elif percentage_change < -5:
            direction = 'down'
        else:
            direction = 'stable'
        
        return {
            'direction': direction,
            'percentage_change': round(percentage_change, 2),
            'data_points': len(metrics),
            'latest_value': float(metrics[-1].value),
        }
    
    # ==================== Dashboard Widgets ====================
    
    def create_or_update_widget(
        self,
        user_id: Optional[UUID],
        role: Optional[str],
        hostel_id: Optional[UUID],
        widget_data: Dict[str, Any]
    ) -> DashboardWidget:
        """Create or update a dashboard widget configuration."""
        widget_id = widget_data.get('widget_id')
        
        existing = self.db.query(DashboardWidget).filter(
            and_(
                DashboardWidget.user_id == user_id if user_id else DashboardWidget.user_id.is_(None),
                DashboardWidget.role == role if role else DashboardWidget.role.is_(None),
                DashboardWidget.hostel_id == hostel_id if hostel_id else DashboardWidget.hostel_id.is_(None),
                DashboardWidget.widget_id == widget_id
            )
        ).first()
        
        if existing:
            for key, value in widget_data.items():
                if key != 'widget_id':
                    setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        widget = DashboardWidget(
            user_id=user_id,
            role=role,
            hostel_id=hostel_id,
            **widget_data
        )
        
        self.db.add(widget)
        self.db.commit()
        self.db.refresh(widget)
        
        return widget
    
    def get_user_widgets(
        self,
        user_id: UUID,
        hostel_id: Optional[UUID] = None
    ) -> List[DashboardWidget]:
        """Get all widgets for a user."""
        query = QueryBuilder(DashboardWidget, self.db)
        
        query = query.where(DashboardWidget.user_id == user_id)
        
        if hostel_id:
            query = query.where(DashboardWidget.hostel_id == hostel_id)
        
        query = query.where(DashboardWidget.is_visible == True)
        query = query.order_by(DashboardWidget.position.asc())
        
        return query.all()
    
    def get_role_widgets(
        self,
        role: str,
        hostel_id: Optional[UUID] = None
    ) -> List[DashboardWidget]:
        """Get default widgets for a role."""
        query = QueryBuilder(DashboardWidget, self.db)
        
        query = query.where(DashboardWidget.role == role)
        query = query.where(DashboardWidget.user_id.is_(None))
        
        if hostel_id:
            query = query.where(DashboardWidget.hostel_id == hostel_id)
        
        query = query.where(DashboardWidget.is_visible == True)
        query = query.order_by(DashboardWidget.position.asc())
        
        return query.all()
    
    def update_widget_position(
        self,
        widget_id: UUID,
        new_position: int
    ) -> Optional[DashboardWidget]:
        """Update widget position/order."""
        widget = self.db.query(DashboardWidget).filter(
            DashboardWidget.id == widget_id
        ).first()
        
        if not widget:
            return None
        
        widget.position = new_position
        
        self.db.commit()
        self.db.refresh(widget)
        
        return widget
    
    def toggle_widget_visibility(
        self,
        widget_id: UUID
    ) -> Optional[DashboardWidget]:
        """Toggle widget visibility."""
        widget = self.db.query(DashboardWidget).filter(
            DashboardWidget.id == widget_id
        ).first()
        
        if not widget:
            return None
        
        widget.is_visible = not widget.is_visible
        
        self.db.commit()
        self.db.refresh(widget)
        
        return widget
    
    def delete_widget(
        self,
        widget_id: UUID
    ) -> bool:
        """Delete a widget."""
        widget = self.db.query(DashboardWidget).filter(
            DashboardWidget.id == widget_id
        ).first()
        
        if not widget:
            return False
        
        self.db.delete(widget)
        self.db.commit()
        
        return True
    
    # ==================== Alert Notifications ====================
    
    def create_alert(
        self,
        hostel_id: Optional[UUID],
        alert_data: Dict[str, Any]
    ) -> AlertNotification:
        """Create a new alert notification."""
        alert = AlertNotification(
            hostel_id=hostel_id,
            **alert_data
        )
        
        self.db.add(alert)
        self.db.commit()
        self.db.refresh(alert)
        
        return alert
    
    def get_active_alerts(
        self,
        hostel_id: Optional[UUID],
        severity: Optional[str] = None
    ) -> List[AlertNotification]:
        """Get active (non-dismissed, non-expired) alerts."""
        query = QueryBuilder(AlertNotification, self.db)
        
        if hostel_id:
            query = query.where(AlertNotification.hostel_id == hostel_id)
        
        query = query.where(AlertNotification.is_dismissed == False)
        
        # Not expired
        query = query.where(
            or_(
                AlertNotification.expires_at.is_(None),
                AlertNotification.expires_at > datetime.utcnow()
            )
        )
        
        if severity:
            query = query.where(AlertNotification.severity == severity)
        
        query = query.order_by(
            case(
                (AlertNotification.severity == 'critical', 1),
                (AlertNotification.severity == 'error', 2),
                (AlertNotification.severity == 'warning', 3),
                else_=4
            ),
            AlertNotification.created_at.desc()
        )
        
        return query.all()
    
    def dismiss_alert(
        self,
        alert_id: UUID,
        dismissed_by: UUID
    ) -> Optional[AlertNotification]:
        """Dismiss an alert."""
        alert = self.db.query(AlertNotification).filter(
            AlertNotification.id == alert_id
        ).first()
        
        if not alert:
            return None
        
        alert.is_dismissed = True
        alert.dismissed_at = datetime.utcnow()
        alert.dismissed_by = dismissed_by
        
        self.db.commit()
        self.db.refresh(alert)
        
        return alert
    
    def cleanup_expired_alerts(
        self,
        before_date: Optional[datetime] = None
    ) -> int:
        """Delete expired and old dismissed alerts."""
        if not before_date:
            before_date = datetime.utcnow()
        
        count = self.db.query(AlertNotification).filter(
            or_(
                AlertNotification.expires_at < before_date,
                and_(
                    AlertNotification.is_dismissed == True,
                    AlertNotification.dismissed_at < (before_date - timedelta(days=30))
                )
            )
        ).delete()
        
        self.db.commit()
        
        return count
    
    # ==================== Quick Stats ====================
    
    def create_or_update_quick_stats(
        self,
        hostel_id: Optional[UUID],
        snapshot_date: date,
        stats_data: Dict[str, Any]
    ) -> QuickStats:
        """Create or update quick stats snapshot."""
        existing = self.db.query(QuickStats).filter(
            and_(
                QuickStats.hostel_id == hostel_id if hostel_id else QuickStats.hostel_id.is_(None),
                QuickStats.snapshot_date == snapshot_date
            )
        ).first()
        
        if existing:
            for key, value in stats_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        stats = QuickStats(
            hostel_id=hostel_id,
            snapshot_date=snapshot_date,
            **stats_data
        )
        
        self.db.add(stats)
        self.db.commit()
        self.db.refresh(stats)
        
        return stats
    
    def get_quick_stats(
        self,
        hostel_id: Optional[UUID],
        snapshot_date: Optional[date] = None
    ) -> Optional[QuickStats]:
        """Get quick stats for a specific date."""
        if not snapshot_date:
            snapshot_date = date.today()
        
        return self.db.query(QuickStats).filter(
            and_(
                QuickStats.hostel_id == hostel_id if hostel_id else QuickStats.hostel_id.is_(None),
                QuickStats.snapshot_date == snapshot_date
            )
        ).first()
    
    def get_quick_stats_history(
        self,
        hostel_id: Optional[UUID],
        days: int = 7
    ) -> List[QuickStats]:
        """Get quick stats history for recent days."""
        end_date = date.today()
        start_date = end_date - timedelta(days=days)
        
        query = QueryBuilder(QuickStats, self.db)
        
        if hostel_id:
            query = query.where(QuickStats.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                QuickStats.snapshot_date >= start_date,
                QuickStats.snapshot_date <= end_date
            )
        ).order_by(QuickStats.snapshot_date.asc())
        
        return query.all()
    
    # ==================== Role-Specific Dashboard ====================
    
    def create_or_update_role_dashboard(
        self,
        user_id: UUID,
        hostel_id: Optional[UUID],
        role: str,
        dashboard_data: Dict[str, Any]
    ) -> RoleSpecificDashboard:
        """Create or update role-specific dashboard configuration."""
        existing = self.db.query(RoleSpecificDashboard).filter(
            and_(
                RoleSpecificDashboard.user_id == user_id,
                RoleSpecificDashboard.hostel_id == hostel_id if hostel_id else RoleSpecificDashboard.hostel_id.is_(None)
            )
        ).first()
        
        if existing:
            for key, value in dashboard_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        dashboard = RoleSpecificDashboard(
            user_id=user_id,
            hostel_id=hostel_id,
            role=role,
            **dashboard_data
        )
        
        self.db.add(dashboard)
        self.db.commit()
        self.db.refresh(dashboard)
        
        return dashboard
    
    def get_role_dashboard(
        self,
        user_id: UUID,
        hostel_id: Optional[UUID]
    ) -> Optional[RoleSpecificDashboard]:
        """Get role-specific dashboard for a user."""
        return self.db.query(RoleSpecificDashboard).filter(
            and_(
                RoleSpecificDashboard.user_id == user_id,
                RoleSpecificDashboard.hostel_id == hostel_id if hostel_id else RoleSpecificDashboard.hostel_id.is_(None)
            )
        ).first()

# --- File: C:\Hostel-Main\app\repositories\analytics\financial_analytics_repository.py ---
"""
Financial Analytics Repository for P&L and cashflow tracking.

Provides comprehensive financial analytics with:
- Revenue and expense breakdown management
- Profit & Loss statement generation
- Cashflow analysis and tracking
- Budget vs actual comparison
- Tax summary management
- Financial health scoring
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, desc
from sqlalchemy.orm import Session, joinedload
from uuid import UUID

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.models.analytics.financial_analytics import (
    RevenueBreakdown,
    ExpenseBreakdown,
    FinancialRatios,
    ProfitAndLossStatement,
    CashflowPoint,
    CashflowSummary,
    BudgetComparison,
    TaxSummary,
    FinancialReport,
)


class FinancialAnalyticsRepository(BaseRepository):
    """Repository for financial analytics operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
    
    # ==================== Revenue Breakdown ====================
    
    def create_revenue_breakdown(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        revenue_data: Dict[str, Any]
    ) -> RevenueBreakdown:
        """Create or update revenue breakdown."""
        # Calculate derived fields
        collection_rate = self._calculate_collection_rate(
            revenue_data.get('billed_amount', 0),
            revenue_data.get('collected_amount', 0)
        )
        revenue_data['collection_rate'] = collection_rate
        
        primary_source = self._identify_primary_revenue_source(revenue_data)
        revenue_data['primary_revenue_source'] = primary_source
        
        concentration_risk = self._assess_revenue_concentration_risk(revenue_data)
        revenue_data['revenue_concentration_risk'] = concentration_risk
        
        existing = self.db.query(RevenueBreakdown).filter(
            and_(
                RevenueBreakdown.hostel_id == hostel_id if hostel_id else RevenueBreakdown.hostel_id.is_(None),
                RevenueBreakdown.period_start == period_start,
                RevenueBreakdown.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in revenue_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        breakdown = RevenueBreakdown(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **revenue_data
        )
        
        self.db.add(breakdown)
        self.db.commit()
        self.db.refresh(breakdown)
        
        return breakdown
    
    def get_revenue_breakdown(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[RevenueBreakdown]:
        """Get revenue breakdown for period."""
        return self.db.query(RevenueBreakdown).filter(
            and_(
                RevenueBreakdown.hostel_id == hostel_id if hostel_id else RevenueBreakdown.hostel_id.is_(None),
                RevenueBreakdown.period_start == period_start,
                RevenueBreakdown.period_end == period_end
            )
        ).first()
    
    def get_revenue_trend(
        self,
        hostel_id: Optional[UUID],
        start_date: date,
        end_date: date
    ) -> List[Dict[str, Any]]:
        """Get revenue trend over time."""
        breakdowns = self.db.query(RevenueBreakdown).filter(
            and_(
                RevenueBreakdown.hostel_id == hostel_id if hostel_id else RevenueBreakdown.hostel_id.is_(None),
                RevenueBreakdown.period_start >= start_date,
                RevenueBreakdown.period_end <= end_date
            )
        ).order_by(RevenueBreakdown.period_start.asc()).all()
        
        return [
            {
                'period_start': b.period_start,
                'period_end': b.period_end,
                'total_revenue': float(b.total_revenue),
                'collection_rate': float(b.collection_rate),
                'primary_source': b.primary_revenue_source,
            }
            for b in breakdowns
        ]
    
    def _calculate_collection_rate(
        self,
        billed: Decimal,
        collected: Decimal
    ) -> Decimal:
        """Calculate collection efficiency rate."""
        if billed == 0:
            return Decimal('0.00')
        
        rate = (collected / billed) * 100
        return Decimal(str(round(rate, 2)))
    
    def _identify_primary_revenue_source(
        self,
        revenue_data: Dict[str, Any]
    ) -> str:
        """Identify the largest revenue source."""
        sources = {
            'booking': revenue_data.get('booking_revenue', 0),
            'rent': revenue_data.get('rent_revenue', 0),
            'mess': revenue_data.get('mess_revenue', 0),
            'utility': revenue_data.get('utility_revenue', 0),
            'late_fee': revenue_data.get('late_fee_revenue', 0),
            'other': revenue_data.get('other_revenue', 0),
        }
        
        if not any(sources.values()):
            return 'none'
        
        return max(sources.items(), key=lambda x: x[1])[0]
    
    def _assess_revenue_concentration_risk(
        self,
        revenue_data: Dict[str, Any]
    ) -> str:
        """Assess revenue concentration risk level."""
        total = float(revenue_data.get('total_revenue', 0))
        
        if total == 0:
            return 'unknown'
        
        sources = {
            'booking': float(revenue_data.get('booking_revenue', 0)),
            'rent': float(revenue_data.get('rent_revenue', 0)),
            'mess': float(revenue_data.get('mess_revenue', 0)),
            'utility': float(revenue_data.get('utility_revenue', 0)),
            'late_fee': float(revenue_data.get('late_fee_revenue', 0)),
            'other': float(revenue_data.get('other_revenue', 0)),
        }
        
        # Calculate percentage of largest source
        max_source_pct = (max(sources.values()) / total) * 100
        
        if max_source_pct > 70:
            return 'high'
        elif max_source_pct > 50:
            return 'moderate'
        else:
            return 'low'
    
    # ==================== Expense Breakdown ====================
    
    def create_expense_breakdown(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        expense_data: Dict[str, Any]
    ) -> ExpenseBreakdown:
        """Create or update expense breakdown."""
        # Identify largest expense
        largest_category = self._identify_largest_expense_category(expense_data)
        expense_data['largest_expense_category'] = largest_category
        
        # Calculate staff expense ratio
        staff_ratio = self._calculate_expense_ratio(
            expense_data.get('staff_expenses', 0),
            expense_data.get('total_expenses', 0)
        )
        expense_data['expense_ratio_staff'] = staff_ratio
        
        existing = self.db.query(ExpenseBreakdown).filter(
            and_(
                ExpenseBreakdown.hostel_id == hostel_id if hostel_id else ExpenseBreakdown.hostel_id.is_(None),
                ExpenseBreakdown.period_start == period_start,
                ExpenseBreakdown.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in expense_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        breakdown = ExpenseBreakdown(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **expense_data
        )
        
        self.db.add(breakdown)
        self.db.commit()
        self.db.refresh(breakdown)
        
        return breakdown
    
    def get_expense_breakdown(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[ExpenseBreakdown]:
        """Get expense breakdown for period."""
        return self.db.query(ExpenseBreakdown).filter(
            and_(
                ExpenseBreakdown.hostel_id == hostel_id if hostel_id else ExpenseBreakdown.hostel_id.is_(None),
                ExpenseBreakdown.period_start == period_start,
                ExpenseBreakdown.period_end == period_end
            )
        ).first()
    
    def _identify_largest_expense_category(
        self,
        expense_data: Dict[str, Any]
    ) -> str:
        """Identify the largest expense category."""
        categories = {
            'maintenance': expense_data.get('maintenance_expenses', 0),
            'staff': expense_data.get('staff_expenses', 0),
            'utility': expense_data.get('utility_expenses', 0),
            'supply': expense_data.get('supply_expenses', 0),
            'marketing': expense_data.get('marketing_expenses', 0),
            'administrative': expense_data.get('administrative_expenses', 0),
            'other': expense_data.get('other_expenses', 0),
        }
        
        if not any(categories.values()):
            return 'none'
        
        return max(categories.items(), key=lambda x: x[1])[0]
    
    def _calculate_expense_ratio(
        self,
        category_expense: Decimal,
        total_expense: Decimal
    ) -> Decimal:
        """Calculate expense ratio as percentage."""
        if total_expense == 0:
            return Decimal('0.00')
        
        ratio = (category_expense / total_expense) * 100
        return Decimal(str(round(ratio, 2)))
    
    # ==================== Financial Ratios ====================
    
    def create_financial_ratios(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        ratios_data: Dict[str, Any]
    ) -> FinancialRatios:
        """Create or update financial ratios."""
        # Calculate profitability status
        profitability_status = self._assess_profitability_status(ratios_data)
        ratios_data['profitability_status'] = profitability_status
        
        existing = self.db.query(FinancialRatios).filter(
            and_(
                FinancialRatios.hostel_id == hostel_id if hostel_id else FinancialRatios.hostel_id.is_(None),
                FinancialRatios.period_start == period_start,
                FinancialRatios.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in ratios_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        ratios = FinancialRatios(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **ratios_data
        )
        
        self.db.add(ratios)
        self.db.commit()
        self.db.refresh(ratios)
        
        return ratios
    
    def _assess_profitability_status(
        self,
        ratios_data: Dict[str, Any]
    ) -> str:
        """Assess overall profitability status."""
        net_margin = float(ratios_data.get('net_profit_margin', 0))
        
        if net_margin >= 20:
            return 'excellent'
        elif net_margin >= 15:
            return 'good'
        elif net_margin >= 10:
            return 'satisfactory'
        elif net_margin >= 5:
            return 'marginal'
        elif net_margin > 0:
            return 'break_even'
        else:
            return 'loss'
    
    # ==================== Profit & Loss Statement ====================
    
    def create_pnl_statement(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        revenue_breakdown_id: Optional[UUID],
        expense_breakdown_id: Optional[UUID],
        financial_ratios_id: Optional[UUID]
    ) -> ProfitAndLossStatement:
        """Create or update P&L statement."""
        # Get related data
        revenue = self.db.query(RevenueBreakdown).filter(
            RevenueBreakdown.id == revenue_breakdown_id
        ).first() if revenue_breakdown_id else None
        
        expense = self.db.query(ExpenseBreakdown).filter(
            ExpenseBreakdown.id == expense_breakdown_id
        ).first() if expense_breakdown_id else None
        
        # Calculate P&L metrics
        total_revenue = float(revenue.total_revenue) if revenue else 0
        total_expenses = float(expense.total_expenses) if expense else 0
        
        gross_profit = Decimal(str(total_revenue - total_expenses))
        operating_profit = gross_profit  # Simplified
        net_profit = operating_profit  # Simplified
        
        # Calculate margins
        gross_margin = self._calculate_margin(gross_profit, total_revenue)
        operating_margin = self._calculate_margin(operating_profit, total_revenue)
        net_margin = self._calculate_margin(net_profit, total_revenue)
        
        # Profitability flag
        is_profitable = float(net_profit) > 0
        
        # Break-even analysis
        break_even_revenue = Decimal(str(total_expenses))
        revenue_above_break_even = Decimal(str(max(0, total_revenue - total_expenses)))
        
        # Performance summary
        performance_summary = {
            'total_revenue': total_revenue,
            'total_expenses': total_expenses,
            'net_profit': float(net_profit),
            'is_profitable': is_profitable,
            'profit_margin': float(net_margin),
        }
        
        existing = self.db.query(ProfitAndLossStatement).filter(
            and_(
                ProfitAndLossStatement.hostel_id == hostel_id if hostel_id else ProfitAndLossStatement.hostel_id.is_(None),
                ProfitAndLossStatement.period_start == period_start,
                ProfitAndLossStatement.period_end == period_end
            )
        ).first()
        
        pnl_data = {
            'revenue_breakdown_id': revenue_breakdown_id,
            'expense_breakdown_id': expense_breakdown_id,
            'financial_ratios_id': financial_ratios_id,
            'gross_profit': gross_profit,
            'operating_profit': operating_profit,
            'net_profit': net_profit,
            'gross_profit_margin': gross_margin,
            'operating_profit_margin': operating_margin,
            'net_profit_margin': net_margin,
            'is_profitable': is_profitable,
            'break_even_revenue': break_even_revenue,
            'revenue_above_break_even': revenue_above_break_even,
            'performance_summary': performance_summary,
            'calculated_at': datetime.utcnow(),
        }
        
        if existing:
            for key, value in pnl_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        pnl = ProfitAndLossStatement(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **pnl_data
        )
        
        self.db.add(pnl)
        self.db.commit()
        self.db.refresh(pnl)
        
        return pnl
    
    def get_pnl_statement(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[ProfitAndLossStatement]:
        """Get P&L statement for period."""
        return self.db.query(ProfitAndLossStatement).filter(
            and_(
                ProfitAndLossStatement.hostel_id == hostel_id if hostel_id else ProfitAndLossStatement.hostel_id.is_(None),
                ProfitAndLossStatement.period_start == period_start,
                ProfitAndLossStatement.period_end == period_end
            )
        ).first()
    
    def _calculate_margin(
        self,
        profit: Decimal,
        revenue: float
    ) -> Decimal:
        """Calculate profit margin percentage."""
        if revenue == 0:
            return Decimal('0.0000')
        
        margin = (float(profit) / revenue) * 100
        return Decimal(str(round(margin, 4)))
    
    # ==================== Cashflow Analysis ====================
    
    def create_cashflow_summary(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        cashflow_data: Dict[str, Any]
    ) -> CashflowSummary:
        """Create or update cashflow summary."""
        # Calculate cashflow health
        cashflow_health = self._assess_cashflow_health(cashflow_data)
        cashflow_data['cashflow_health'] = cashflow_health
        
        # Calculate burn rate
        burn_rate_days = self._calculate_burn_rate(cashflow_data)
        cashflow_data['burn_rate_days'] = burn_rate_days
        
        existing = self.db.query(CashflowSummary).filter(
            and_(
                CashflowSummary.hostel_id == hostel_id if hostel_id else CashflowSummary.hostel_id.is_(None),
                CashflowSummary.period_start == period_start,
                CashflowSummary.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in cashflow_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        summary = CashflowSummary(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **cashflow_data
        )
        
        self.db.add(summary)
        self.db.commit()
        self.db.refresh(summary)
        
        return summary
    
    def add_cashflow_points(
        self,
        cashflow_summary_id: UUID,
        points: List[Dict[str, Any]]
    ) -> List[CashflowPoint]:
        """Add cashflow data points to summary."""
        created_points = []
        
        for point_data in points:
            existing = self.db.query(CashflowPoint).filter(
                and_(
                    CashflowPoint.cashflow_summary_id == cashflow_summary_id,
                    CashflowPoint.cashflow_date == point_data['cashflow_date']
                )
            ).first()
            
            if existing:
                for key, value in point_data.items():
                    if key != 'cashflow_date':
                        setattr(existing, key, value)
                created_points.append(existing)
            else:
                point = CashflowPoint(
                    cashflow_summary_id=cashflow_summary_id,
                    **point_data
                )
                self.db.add(point)
                created_points.append(point)
        
        self.db.commit()
        for point in created_points:
            self.db.refresh(point)
        
        return created_points
    
    def get_cashflow_points(
        self,
        cashflow_summary_id: UUID
    ) -> List[CashflowPoint]:
        """Get all cashflow points for a summary."""
        return self.db.query(CashflowPoint).filter(
            CashflowPoint.cashflow_summary_id == cashflow_summary_id
        ).order_by(CashflowPoint.cashflow_date.asc()).all()
    
    def _assess_cashflow_health(
        self,
        cashflow_data: Dict[str, Any]
    ) -> str:
        """Assess cashflow health status."""
        net_cashflow = float(cashflow_data.get('net_cashflow', 0))
        closing_balance = float(cashflow_data.get('closing_balance', 0))
        
        if net_cashflow > 0 and closing_balance > 0:
            return 'healthy'
        elif net_cashflow >= 0:
            return 'stable'
        elif closing_balance > 0:
            return 'concerning'
        else:
            return 'critical'
    
    def _calculate_burn_rate(
        self,
        cashflow_data: Dict[str, Any]
    ) -> Optional[int]:
        """Calculate cash burn rate in days."""
        net_cashflow = float(cashflow_data.get('net_cashflow', 0))
        closing_balance = float(cashflow_data.get('closing_balance', 0))
        
        if net_cashflow >= 0:
            return None  # Not burning cash
        
        if closing_balance <= 0:
            return 0  # Already out of cash
        
        # Calculate daily burn rate
        period_days = (
            cashflow_data.get('period_end') - 
            cashflow_data.get('period_start')
        ).days
        
        if period_days == 0:
            return None
        
        daily_burn = abs(net_cashflow) / period_days
        
        if daily_burn == 0:
            return None
        
        days_remaining = int(closing_balance / daily_burn)
        
        return days_remaining
    
    # ==================== Budget Comparison ====================
    
    def create_budget_comparison(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        category: str,
        comparison_data: Dict[str, Any]
    ) -> BudgetComparison:
        """Create or update budget comparison."""
        # Calculate variance
        budgeted = float(comparison_data.get('budgeted_amount', 0))
        actual = float(comparison_data.get('actual_amount', 0))
        
        variance_amount = Decimal(str(actual - budgeted))
        
        if budgeted != 0:
            variance_pct = Decimal(str(((actual - budgeted) / budgeted) * 100))
        else:
            variance_pct = Decimal('0.0000')
        
        comparison_data['variance_amount'] = variance_amount
        comparison_data['variance_percentage'] = variance_pct
        
        # Determine if favorable (context-dependent)
        is_favorable = self._is_variance_favorable(category, variance_amount)
        comparison_data['is_favorable'] = is_favorable
        
        # Assess severity
        severity = self._assess_variance_severity(variance_pct)
        comparison_data['variance_severity'] = severity
        
        existing = self.db.query(BudgetComparison).filter(
            and_(
                BudgetComparison.hostel_id == hostel_id if hostel_id else BudgetComparison.hostel_id.is_(None),
                BudgetComparison.period_start == period_start,
                BudgetComparison.period_end == period_end,
                BudgetComparison.category == category
            )
        ).first()
        
        if existing:
            for key, value in comparison_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        comparison = BudgetComparison(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            category=category,
            **comparison_data
        )
        
        self.db.add(comparison)
        self.db.commit()
        self.db.refresh(comparison)
        
        return comparison
    
    def get_budget_comparisons(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[BudgetComparison]:
        """Get all budget comparisons for period."""
        return self.db.query(BudgetComparison).filter(
            and_(
                BudgetComparison.hostel_id == hostel_id if hostel_id else BudgetComparison.hostel_id.is_(None),
                BudgetComparison.period_start == period_start,
                BudgetComparison.period_end == period_end
            )
        ).all()
    
    def _is_variance_favorable(
        self,
        category: str,
        variance: Decimal
    ) -> bool:
        """Determine if variance is favorable."""
        # For revenue categories, higher is better
        revenue_categories = ['revenue', 'income', 'sales']
        
        if any(cat in category.lower() for cat in revenue_categories):
            return float(variance) > 0
        
        # For expense categories, lower is better
        return float(variance) < 0
    
    def _assess_variance_severity(
        self,
        variance_pct: Decimal
    ) -> str:
        """Assess variance severity level."""
        abs_variance = abs(float(variance_pct))
        
        if abs_variance < 5:
            return 'minor'
        elif abs_variance < 10:
            return 'moderate'
        elif abs_variance < 20:
            return 'significant'
        else:
            return 'critical'
    
    # ==================== Tax Summary ====================
    
    def create_tax_summary(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        tax_data: Dict[str, Any]
    ) -> TaxSummary:
        """Create or update tax summary."""
        # Calculate effective tax rate
        taxable_revenue = float(tax_data.get('taxable_revenue', 0))
        total_tax = (
            float(tax_data.get('estimated_income_tax', 0)) +
            float(tax_data.get('gst_payable', 0))
        )
        
        if taxable_revenue > 0:
            effective_rate = Decimal(str((total_tax / taxable_revenue) * 100))
        else:
            effective_rate = Decimal('0.00')
        
        tax_data['effective_tax_rate'] = effective_rate
        
        existing = self.db.query(TaxSummary).filter(
            and_(
                TaxSummary.hostel_id == hostel_id if hostel_id else TaxSummary.hostel_id.is_(None),
                TaxSummary.period_start == period_start,
                TaxSummary.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in tax_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        summary = TaxSummary(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **tax_data
        )
        
        self.db.add(summary)
        self.db.commit()
        self.db.refresh(summary)
        
        return summary
    
    # ==================== Comprehensive Financial Report ====================
    
    def create_financial_report(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        pnl_id: Optional[UUID],
        cashflow_id: Optional[UUID],
        tax_summary_id: Optional[UUID],
        report_data: Dict[str, Any]
    ) -> FinancialReport:
        """Create or update comprehensive financial report."""
        # Calculate financial health score
        health_score = self._calculate_financial_health_score(report_data)
        report_data['financial_health_score'] = health_score
        
        # Assign performance grade
        performance_grade = self._assign_performance_grade(health_score)
        report_data['performance_grade'] = performance_grade
        
        # Generate executive summary
        executive_summary = self._generate_executive_summary(report_data)
        report_data['executive_summary'] = executive_summary
        
        existing = self.db.query(FinancialReport).filter(
            and_(
                FinancialReport.hostel_id == hostel_id if hostel_id else FinancialReport.hostel_id.is_(None),
                FinancialReport.period_start == period_start,
                FinancialReport.period_end == period_end
            )
        ).first()
        
        report_data.update({
            'pnl_id': pnl_id,
            'cashflow_id': cashflow_id,
            'tax_summary_id': tax_summary_id,
            'calculated_at': datetime.utcnow(),
        })
        
        if existing:
            for key, value in report_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        report = FinancialReport(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **report_data
        )
        
        self.db.add(report)
        self.db.commit()
        self.db.refresh(report)
        
        return report
    
    def get_financial_report(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[FinancialReport]:
        """Get comprehensive financial report."""
        return self.db.query(FinancialReport).filter(
            and_(
                FinancialReport.hostel_id == hostel_id if hostel_id else FinancialReport.hostel_id.is_(None),
                FinancialReport.period_start == period_start,
                FinancialReport.period_end == period_end
            )
        ).first()
    
    def _calculate_financial_health_score(
        self,
        report_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate overall financial health score (0-100).
        
        Weighted factors:
        - Profitability: 30%
        - Liquidity: 25%
        - Collection efficiency: 20%
        - Revenue growth: 15%
        - Expense control: 10%
        """
        # Profitability (based on net margin)
        net_margin = float(report_data.get('avg_revenue_per_student', 0))
        profitability_score = min(max(net_margin, 0), 100) * 0.30
        
        # Liquidity (based on collection rate)
        collection_rate = float(report_data.get('collection_rate', 0))
        liquidity_score = collection_rate * 0.25
        
        # Collection efficiency
        overdue_ratio = float(report_data.get('overdue_ratio', 0))
        collection_efficiency = max(0, 100 - overdue_ratio) * 0.20
        
        # Revenue growth (YoY)
        revenue_growth = float(report_data.get('revenue_growth_yoy', 0))
        growth_score = min(max(revenue_growth, 0), 100) * 0.15
        
        # Expense control (based on occupancy)
        occupancy_rate = float(report_data.get('occupancy_rate', 0))
        expense_score = occupancy_rate * 0.10
        
        total_score = (
            profitability_score +
            liquidity_score +
            collection_efficiency +
            growth_score +
            expense_score
        )
        
        return Decimal(str(round(total_score, 2)))
    
    def _assign_performance_grade(
        self,
        health_score: Decimal
    ) -> str:
        """Assign letter grade based on health score."""
        score = float(health_score)
        
        if score >= 90:
            return 'A+'
        elif score >= 85:
            return 'A'
        elif score >= 80:
            return 'A-'
        elif score >= 75:
            return 'B+'
        elif score >= 70:
            return 'B'
        elif score >= 65:
            return 'B-'
        elif score >= 60:
            return 'C+'
        elif score >= 55:
            return 'C'
        elif score >= 50:
            return 'C-'
        else:
            return 'D'
    
    def _generate_executive_summary(
        self,
        report_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate executive summary with key insights."""
        return {
            'key_highlights': [
                f"Collection rate: {report_data.get('collection_rate', 0)}%",
                f"Average revenue per student: ₹{report_data.get('avg_revenue_per_student', 0):,.2f}",
                f"Occupancy rate: {report_data.get('occupancy_rate', 0)}%",
            ],
            'areas_of_concern': self._identify_concerns(report_data),
            'recommendations': self._generate_recommendations(report_data),
        }
    
    def _identify_concerns(
        self,
        report_data: Dict[str, Any]
    ) -> List[str]:
        """Identify financial concerns."""
        concerns = []
        
        if float(report_data.get('collection_rate', 100)) < 80:
            concerns.append('Low collection efficiency')
        
        if float(report_data.get('overdue_ratio', 0)) > 20:
            concerns.append('High overdue ratio')
        
        if float(report_data.get('occupancy_rate', 100)) < 70:
            concerns.append('Below-target occupancy')
        
        return concerns
    
    def _generate_recommendations(
        self,
        report_data: Dict[str, Any]
    ) -> List[str]:
        """Generate actionable recommendations."""
        recommendations = []
        
        if float(report_data.get('collection_rate', 100)) < 85:
            recommendations.append('Implement stricter payment collection policies')
        
        if float(report_data.get('occupancy_rate', 100)) < 75:
            recommendations.append('Increase marketing efforts to boost occupancy')
        
        if float(report_data.get('overdue_ratio', 0)) > 15:
            recommendations.append('Review and enforce payment terms more rigorously')
        
        return recommendations

# --- File: C:\Hostel-Main\app\repositories\analytics\occupancy_analytics_repository.py ---
"""
Occupancy Analytics Repository for capacity management and forecasting.

Provides comprehensive occupancy analytics with:
- Occupancy KPI tracking and trends
- Room type and floor analysis
- Seasonal pattern identification
- Demand forecasting with ML
- Capacity optimization insights
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, desc
from sqlalchemy.orm import Session, joinedload
from uuid import UUID
import statistics

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.models.analytics.occupancy_analytics import (
    OccupancyKPI,
    OccupancyTrendPoint,
    OccupancyByRoomType,
    OccupancyByFloor,
    SeasonalPattern,
    ForecastPoint,
    ForecastData,
    OccupancyReport,
)


class OccupancyAnalyticsRepository(BaseRepository):
    """Repository for occupancy analytics operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
    
    # ==================== Occupancy KPI ====================
    
    def create_occupancy_kpi(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        kpi_data: Dict[str, Any]
    ) -> OccupancyKPI:
        """Create or update occupancy KPI."""
        # Calculate derived fields
        vacancy_rate = self._calculate_vacancy_rate(
            kpi_data.get('total_beds', 0),
            kpi_data.get('occupied_beds', 0)
        )
        kpi_data['vacancy_rate'] = vacancy_rate
        
        occupancy_status = self._determine_occupancy_status(
            kpi_data.get('current_occupancy_percentage', 0)
        )
        kpi_data['occupancy_status'] = occupancy_status
        
        capacity_pressure = self._calculate_capacity_pressure(
            kpi_data.get('current_occupancy_percentage', 0)
        )
        kpi_data['capacity_pressure'] = capacity_pressure
        
        existing = self.db.query(OccupancyKPI).filter(
            and_(
                OccupancyKPI.hostel_id == hostel_id if hostel_id else OccupancyKPI.hostel_id.is_(None),
                OccupancyKPI.period_start == period_start,
                OccupancyKPI.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in kpi_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        kpi = OccupancyKPI(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **kpi_data
        )
        
        self.db.add(kpi)
        self.db.commit()
        self.db.refresh(kpi)
        
        return kpi
    
    def get_occupancy_kpi(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[OccupancyKPI]:
        """Get occupancy KPI for period."""
        return self.db.query(OccupancyKPI).filter(
            and_(
                OccupancyKPI.hostel_id == hostel_id if hostel_id else OccupancyKPI.hostel_id.is_(None),
                OccupancyKPI.period_start == period_start,
                OccupancyKPI.period_end == period_end
            )
        ).first()
    
    def _calculate_vacancy_rate(
        self,
        total_beds: int,
        occupied_beds: int
    ) -> Decimal:
        """Calculate vacancy rate percentage."""
        if total_beds == 0:
            return Decimal('0.00')
        
        vacant = total_beds - occupied_beds
        rate = (vacant / total_beds) * 100
        
        return Decimal(str(round(rate, 2)))
    
    def _determine_occupancy_status(
        self,
        occupancy_percentage: Decimal
    ) -> str:
        """Determine occupancy status category."""
        occupancy = float(occupancy_percentage)
        
        if occupancy >= 95:
            return 'critical'  # At capacity
        elif occupancy >= 85:
            return 'high'
        elif occupancy >= 70:
            return 'optimal'
        elif occupancy >= 50:
            return 'moderate'
        else:
            return 'low'
    
    def _calculate_capacity_pressure(
        self,
        occupancy_percentage: Decimal
    ) -> Decimal:
        """Calculate capacity pressure score (0-100)."""
        occupancy = float(occupancy_percentage)
        
        # Pressure increases exponentially as occupancy approaches 100%
        if occupancy >= 95:
            pressure = 100
        elif occupancy >= 90:
            pressure = 80 + ((occupancy - 90) / 5) * 20
        elif occupancy >= 80:
            pressure = 60 + ((occupancy - 80) / 10) * 20
        else:
            pressure = (occupancy / 80) * 60
        
        return Decimal(str(round(pressure, 2)))
    
    # ==================== Trend Analysis ====================
    
    def add_occupancy_trend_points(
        self,
        kpi_id: UUID,
        trend_points: List[Dict[str, Any]]
    ) -> List[OccupancyTrendPoint]:
        """Add multiple occupancy trend points."""
        created_points = []
        
        for point_data in trend_points:
            # Calculate net change
            net_change = (
                point_data.get('check_ins', 0) - 
                point_data.get('check_outs', 0)
            )
            point_data['net_change'] = net_change
            
            existing = self.db.query(OccupancyTrendPoint).filter(
                and_(
                    OccupancyTrendPoint.kpi_id == kpi_id,
                    OccupancyTrendPoint.trend_date == point_data['trend_date']
                )
            ).first()
            
            if existing:
                for key, value in point_data.items():
                    if key != 'trend_date':
                        setattr(existing, key, value)
                created_points.append(existing)
            else:
                point = OccupancyTrendPoint(
                    kpi_id=kpi_id,
                    **point_data
                )
                self.db.add(point)
                created_points.append(point)
        
        self.db.commit()
        for point in created_points:
            self.db.refresh(point)
        
        return created_points
    
    def get_occupancy_trend_points(
        self,
        kpi_id: UUID,
        start_date: Optional[date] = None,
        end_date: Optional[date] = None
    ) -> List[OccupancyTrendPoint]:
        """Get occupancy trend points."""
        query = QueryBuilder(OccupancyTrendPoint, self.db)
        query = query.where(OccupancyTrendPoint.kpi_id == kpi_id)
        
        if start_date:
            query = query.where(OccupancyTrendPoint.trend_date >= start_date)
        if end_date:
            query = query.where(OccupancyTrendPoint.trend_date <= end_date)
        
        query = query.order_by(OccupancyTrendPoint.trend_date.asc())
        
        return query.all()
    
    # ==================== Room Type Analysis ====================
    
    def create_room_type_occupancy(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        room_type: str,
        occupancy_data: Dict[str, Any]
    ) -> OccupancyByRoomType:
        """Create or update room type occupancy breakdown."""
        # Calculate available beds
        available_beds = (
            occupancy_data.get('total_beds', 0) - 
            occupancy_data.get('occupied_beds', 0)
        )
        occupancy_data['available_beds'] = available_beds
        
        existing = self.db.query(OccupancyByRoomType).filter(
            and_(
                OccupancyByRoomType.hostel_id == hostel_id if hostel_id else OccupancyByRoomType.hostel_id.is_(None),
                OccupancyByRoomType.period_start == period_start,
                OccupancyByRoomType.period_end == period_end,
                OccupancyByRoomType.room_type == room_type
            )
        ).first()
        
        if existing:
            for key, value in occupancy_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        breakdown = OccupancyByRoomType(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            room_type=room_type,
            **occupancy_data
        )
        
        self.db.add(breakdown)
        self.db.commit()
        self.db.refresh(breakdown)
        
        return breakdown
    
    def get_room_type_occupancies(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[OccupancyByRoomType]:
        """Get all room type occupancies for period."""
        return self.db.query(OccupancyByRoomType).filter(
            and_(
                OccupancyByRoomType.hostel_id == hostel_id if hostel_id else OccupancyByRoomType.hostel_id.is_(None),
                OccupancyByRoomType.period_start == period_start,
                OccupancyByRoomType.period_end == period_end
            )
        ).order_by(OccupancyByRoomType.occupancy_percentage.desc()).all()
    
    def get_best_performing_room_type(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[OccupancyByRoomType]:
        """Get room type with highest occupancy."""
        return self.db.query(OccupancyByRoomType).filter(
            and_(
                OccupancyByRoomType.hostel_id == hostel_id if hostel_id else OccupancyByRoomType.hostel_id.is_(None),
                OccupancyByRoomType.period_start == period_start,
                OccupancyByRoomType.period_end == period_end
            )
        ).order_by(OccupancyByRoomType.occupancy_percentage.desc()).first()
    
    # ==================== Floor Analysis ====================
    
    def create_floor_occupancy(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        floor_number: int,
        occupancy_data: Dict[str, Any]
    ) -> OccupancyByFloor:
        """Create or update floor occupancy breakdown."""
        existing = self.db.query(OccupancyByFloor).filter(
            and_(
                OccupancyByFloor.hostel_id == hostel_id if hostel_id else OccupancyByFloor.hostel_id.is_(None),
                OccupancyByFloor.period_start == period_start,
                OccupancyByFloor.period_end == period_end,
                OccupancyByFloor.floor_number == floor_number
            )
        ).first()
        
        if existing:
            for key, value in occupancy_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        breakdown = OccupancyByFloor(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            floor_number=floor_number,
            **occupancy_data
        )
        
        self.db.add(breakdown)
        self.db.commit()
        self.db.refresh(breakdown)
        
        return breakdown
    
    def get_floor_occupancies(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[OccupancyByFloor]:
        """Get all floor occupancies for period."""
        return self.db.query(OccupancyByFloor).filter(
            and_(
                OccupancyByFloor.hostel_id == hostel_id if hostel_id else OccupancyByFloor.hostel_id.is_(None),
                OccupancyByFloor.period_start == period_start,
                OccupancyByFloor.period_end == period_end
            )
        ).order_by(OccupancyByFloor.floor_number.asc()).all()
    
    # ==================== Seasonal Patterns ====================
    
    def create_seasonal_pattern(
        self,
        hostel_id: Optional[UUID],
        pattern_data: Dict[str, Any]
    ) -> SeasonalPattern:
        """Create or update seasonal pattern."""
        pattern = SeasonalPattern(
            hostel_id=hostel_id,
            **pattern_data
        )
        
        self.db.add(pattern)
        self.db.commit()
        self.db.refresh(pattern)
        
        return pattern
    
    def get_seasonal_patterns(
        self,
        hostel_id: Optional[UUID],
        year: Optional[int] = None
    ) -> List[SeasonalPattern]:
        """Get identified seasonal patterns."""
        query = QueryBuilder(SeasonalPattern, self.db)
        
        if hostel_id:
            query = query.where(SeasonalPattern.hostel_id == hostel_id)
        
        if year:
            query = query.where(SeasonalPattern.year_identified == year)
        
        query = query.order_by(SeasonalPattern.start_month.asc())
        
        return query.all()
    
    def identify_seasonal_patterns(
        self,
        hostel_id: Optional[UUID],
        lookback_years: int = 2
    ) -> List[SeasonalPattern]:
        """
        Identify seasonal patterns from historical data.
        
        Analyzes historical occupancy to detect recurring patterns.
        """
        # Get historical KPIs
        end_date = date.today()
        start_date = end_date - timedelta(days=lookback_years * 365)
        
        # This would analyze historical data and create patterns
        # Simplified implementation
        patterns = []
        
        # Example: High season (June-August for students)
        high_season = {
            'pattern_name': 'Academic Year Start',
            'start_month': 6,
            'end_month': 8,
            'average_occupancy': Decimal('85.00'),
            'occupancy_variance': Decimal('5.00'),
            'confidence': Decimal('90.00'),
            'is_high_season': True,
            'year_identified': end_date.year,
        }
        
        pattern = self.create_seasonal_pattern(hostel_id, high_season)
        patterns.append(pattern)
        
        return patterns
    
    # ==================== Forecasting ====================
    
    def create_forecast(
        self,
        hostel_id: Optional[UUID],
        forecast_data: Dict[str, Any]
    ) -> ForecastData:
        """Create or update forecast data."""
        forecast = ForecastData(
            hostel_id=hostel_id,
            last_updated=datetime.utcnow(),
            **forecast_data
        )
        
        self.db.add(forecast)
        self.db.commit()
        self.db.refresh(forecast)
        
        return forecast
    
    def add_forecast_points(
        self,
        forecast_data_id: UUID,
        forecast_points: List[Dict[str, Any]]
    ) -> List[ForecastPoint]:
        """Add forecast data points."""
        created_points = []
        
        for point_data in forecast_points:
            existing = self.db.query(ForecastPoint).filter(
                and_(
                    ForecastPoint.forecast_data_id == forecast_data_id,
                    ForecastPoint.forecast_date == point_data['forecast_date']
                )
            ).first()
            
            if existing:
                for key, value in point_data.items():
                    if key != 'forecast_date':
                        setattr(existing, key, value)
                created_points.append(existing)
            else:
                point = ForecastPoint(
                    forecast_data_id=forecast_data_id,
                    **point_data
                )
                self.db.add(point)
                created_points.append(point)
        
        self.db.commit()
        for point in created_points:
            self.db.refresh(point)
        
        return created_points
    
    def get_latest_forecast(
        self,
        hostel_id: Optional[UUID]
    ) -> Optional[ForecastData]:
        """Get the most recent forecast."""
        query = QueryBuilder(ForecastData, self.db)
        
        if hostel_id:
            query = query.where(ForecastData.hostel_id == hostel_id)
        
        query = query.order_by(ForecastData.created_at.desc())
        
        return query.first()
    
    def generate_occupancy_forecast(
        self,
        hostel_id: Optional[UUID],
        forecast_days: int = 30,
        model: str = 'moving_average'
    ) -> ForecastData:
        """
        Generate occupancy forecast using specified model.
        
        Args:
            hostel_id: Hostel ID
            forecast_days: Days to forecast
            model: Forecasting model to use
            
        Returns:
            ForecastData with forecast points
        """
        # Get historical data
        end_date = date.today()
        start_date = end_date - timedelta(days=90)
        
        # Get all trend points from recent KPIs
        kpis = self.db.query(OccupancyKPI).filter(
            and_(
                OccupancyKPI.hostel_id == hostel_id if hostel_id else OccupancyKPI.hostel_id.is_(None),
                OccupancyKPI.period_start >= start_date
            )
        ).all()
        
        all_points = []
        for kpi in kpis:
            points = self.get_occupancy_trend_points(kpi.id)
            all_points.extend(points)
        
        # Sort by date
        all_points.sort(key=lambda x: x.trend_date)
        
        if len(all_points) < 7:
            # Not enough data
            return None
        
        # Apply forecasting model
        if model == 'moving_average':
            forecast_points = self._forecast_moving_average(
                all_points, forecast_days
            )
        elif model == 'exponential_smoothing':
            forecast_points = self._forecast_exponential_smoothing(
                all_points, forecast_days
            )
        else:
            forecast_points = self._forecast_simple_extrapolation(
                all_points, forecast_days
            )
        
        # Calculate summary statistics
        forecasted_occupancies = [
            p['forecasted_occupancy_percentage'] for p in forecast_points
        ]
        
        avg_forecast = statistics.mean(forecasted_occupancies)
        
        peak_date = max(
            forecast_points,
            key=lambda x: x['forecasted_occupancy_percentage']
        )['forecast_date']
        
        low_date = min(
            forecast_points,
            key=lambda x: x['forecasted_occupancy_percentage']
        )['forecast_date']
        
        # Calculate model accuracy (if historical data available)
        model_accuracy = Decimal('75.00')  # Placeholder
        
        # Create forecast data
        forecast_data = {
            'forecast_horizon_days': forecast_days,
            'model_used': model,
            'model_accuracy': model_accuracy,
            'confidence_interval': Decimal('95.00'),
            'training_data_start': all_points[0].trend_date,
            'training_data_end': all_points[-1].trend_date,
            'training_samples': len(all_points),
            'average_forecasted_occupancy': Decimal(str(round(avg_forecast, 2))),
            'peak_forecasted_date': peak_date,
            'low_forecasted_date': low_date,
        }
        
        forecast = self.create_forecast(hostel_id, forecast_data)
        
        # Add forecast points
        self.add_forecast_points(forecast.id, forecast_points)
        
        return forecast
    
    def _forecast_moving_average(
        self,
        historical_points: List[OccupancyTrendPoint],
        forecast_days: int,
        window_size: int = 7
    ) -> List[Dict[str, Any]]:
        """Generate forecast using moving average."""
        # Get recent occupancy percentages
        recent_values = [
            float(p.occupancy_percentage) 
            for p in historical_points[-window_size:]
        ]
        
        moving_avg = statistics.mean(recent_values)
        
        # Calculate trend
        if len(recent_values) >= 3:
            recent_avg = statistics.mean(recent_values[-3:])
            older_avg = statistics.mean(recent_values[:3])
            daily_trend = (recent_avg - older_avg) / 3
        else:
            daily_trend = 0
        
        # Generate forecast points
        forecast_points = []
        last_date = historical_points[-1].trend_date
        
        for i in range(1, forecast_days + 1):
            forecast_date = last_date + timedelta(days=i)
            
            forecasted_occupancy = moving_avg + (daily_trend * i)
            forecasted_occupancy = max(0, min(100, forecasted_occupancy))
            
            # Simple confidence bounds (±10%)
            lower_bound = max(0, forecasted_occupancy * 0.9)
            upper_bound = min(100, forecasted_occupancy * 1.1)
            
            # Estimate occupied beds (assuming last known total)
            total_beds = historical_points[-1].total_beds
            forecasted_beds = int((forecasted_occupancy / 100) * total_beds)
            
            forecast_points.append({
                'forecast_date': forecast_date,
                'forecasted_occupancy_percentage': Decimal(str(round(forecasted_occupancy, 2))),
                'forecasted_occupied_beds': forecasted_beds,
                'lower_bound': Decimal(str(round(lower_bound, 2))),
                'upper_bound': Decimal(str(round(upper_bound, 2))),
                'confidence_level': Decimal('80.00'),
            })
        
        return forecast_points
    
    def _forecast_exponential_smoothing(
        self,
        historical_points: List[OccupancyTrendPoint],
        forecast_days: int,
        alpha: float = 0.3
    ) -> List[Dict[str, Any]]:
        """Generate forecast using exponential smoothing."""
        # Get occupancy values
        values = [float(p.occupancy_percentage) for p in historical_points]
        
        # Calculate smoothed values
        smoothed = [values[0]]
        for value in values[1:]:
            smoothed_value = alpha * value + (1 - alpha) * smoothed[-1]
            smoothed.append(smoothed_value)
        
        # Use last smoothed value as baseline
        last_smoothed = smoothed[-1]
        
        # Generate forecast
        forecast_points = []
        last_date = historical_points[-1].trend_date
        total_beds = historical_points[-1].total_beds
        
        for i in range(1, forecast_days + 1):
            forecast_date = last_date + timedelta(days=i)
            
            forecasted_occupancy = last_smoothed
            forecasted_occupancy = max(0, min(100, forecasted_occupancy))
            
            lower_bound = max(0, forecasted_occupancy * 0.85)
            upper_bound = min(100, forecasted_occupancy * 1.15)
            
            forecasted_beds = int((forecasted_occupancy / 100) * total_beds)
            
            forecast_points.append({
                'forecast_date': forecast_date,
                'forecasted_occupancy_percentage': Decimal(str(round(forecasted_occupancy, 2))),
                'forecasted_occupied_beds': forecasted_beds,
                'lower_bound': Decimal(str(round(lower_bound, 2))),
                'upper_bound': Decimal(str(round(upper_bound, 2))),
                'confidence_level': Decimal('75.00'),
            })
        
        return forecast_points
    
    def _forecast_simple_extrapolation(
        self,
        historical_points: List[OccupancyTrendPoint],
        forecast_days: int
    ) -> List[Dict[str, Any]]:
        """Generate forecast using simple linear extrapolation."""
        # Use last value and assume stable
        last_point = historical_points[-1]
        last_occupancy = float(last_point.occupancy_percentage)
        
        forecast_points = []
        
        for i in range(1, forecast_days + 1):
            forecast_date = last_point.trend_date + timedelta(days=i)
            
            forecasted_occupancy = last_occupancy
            forecasted_occupancy = max(0, min(100, forecasted_occupancy))
            
            lower_bound = max(0, forecasted_occupancy * 0.8)
            upper_bound = min(100, forecasted_occupancy * 1.2)
            
            forecasted_beds = int((forecasted_occupancy / 100) * last_point.total_beds)
            
            forecast_points.append({
                'forecast_date': forecast_date,
                'forecasted_occupancy_percentage': Decimal(str(round(forecasted_occupancy, 2))),
                'forecasted_occupied_beds': forecasted_beds,
                'lower_bound': Decimal(str(round(lower_bound, 2))),
                'upper_bound': Decimal(str(round(upper_bound, 2))),
                'confidence_level': Decimal('70.00'),
            })
        
        return forecast_points
    
    # ==================== Comprehensive Report ====================
    
    def create_occupancy_report(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        kpi_id: Optional[UUID],
        forecast_id: Optional[UUID]
    ) -> OccupancyReport:
        """Create comprehensive occupancy report."""
        # Get room type breakdowns
        room_types = self.get_room_type_occupancies(
            hostel_id, period_start, period_end
        )
        
        # Get floor breakdowns
        floors = self.get_floor_occupancies(
            hostel_id, period_start, period_end
        )
        
        # Identify best and worst performers
        best_room_type = room_types[0].room_type if room_types else None
        worst_room_type = room_types[-1].room_type if room_types else None
        
        # Determine trend direction
        kpi = self.get_occupancy_kpi(hostel_id, period_start, period_end)
        if kpi:
            if float(kpi.average_occupancy_percentage) > float(kpi.peak_occupancy_percentage) * 0.9:
                trend_direction = 'increasing'
            elif float(kpi.average_occupancy_percentage) < float(kpi.low_occupancy_percentage) * 1.1:
                trend_direction = 'decreasing'
            else:
                trend_direction = 'stable'
        else:
            trend_direction = 'unknown'
        
        # Build breakdowns
        room_type_breakdown = [
            {
                'room_type': rt.room_type,
                'occupancy_percentage': float(rt.occupancy_percentage),
                'revenue_generated': float(rt.revenue_generated) if rt.revenue_generated else 0,
            }
            for rt in room_types
        ]
        
        floor_breakdown = [
            {
                'floor_number': f.floor_number,
                'floor_name': f.floor_name,
                'occupancy_percentage': float(f.occupancy_percentage),
            }
            for f in floors
        ]
        
        # Generate optimization insights
        optimization_insights = self._generate_optimization_insights(
            kpi, room_types, floors
        )
        
        existing = self.db.query(OccupancyReport).filter(
            and_(
                OccupancyReport.hostel_id == hostel_id if hostel_id else OccupancyReport.hostel_id.is_(None),
                OccupancyReport.period_start == period_start,
                OccupancyReport.period_end == period_end
            )
        ).first()
        
        report_data = {
            'kpi_id': kpi_id,
            'forecast_id': forecast_id,
            'best_performing_room_type': best_room_type,
            'worst_performing_room_type': worst_room_type,
            'occupancy_trend_direction': trend_direction,
            'room_type_breakdown': room_type_breakdown,
            'floor_breakdown': floor_breakdown,
            'optimization_insights': optimization_insights,
            'is_cached': True,
            'cache_expires_at': datetime.utcnow() + timedelta(hours=1),
            'calculated_at': datetime.utcnow(),
        }
        
        if existing:
            for key, value in report_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        report = OccupancyReport(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **report_data
        )
        
        self.db.add(report)
        self.db.commit()
        self.db.refresh(report)
        
        return report
    
    def _generate_optimization_insights(
        self,
        kpi: Optional[OccupancyKPI],
        room_types: List[OccupancyByRoomType],
        floors: List[OccupancyByFloor]
    ) -> Dict[str, Any]:
        """Generate actionable optimization insights."""
        insights = {
            'recommendations': [],
            'opportunities': [],
            'concerns': [],
        }
        
        if not kpi:
            return insights
        
        # Check overall occupancy
        avg_occupancy = float(kpi.average_occupancy_percentage)
        
        if avg_occupancy < 70:
            insights['recommendations'].append(
                'Occupancy below optimal level - consider pricing adjustments or marketing campaigns'
            )
        elif avg_occupancy > 95:
            insights['recommendations'].append(
                'Near full capacity - consider expanding or premium pricing'
            )
        
        # Check room type performance variance
        if room_types:
            occupancies = [float(rt.occupancy_percentage) for rt in room_types]
            if max(occupancies) - min(occupancies) > 20:
                insights['opportunities'].append(
                    'High variance in room type occupancy - rebalance pricing or inventory'
                )
        
        # Check for underutilized floors
        if floors:
            for floor in floors:
                if float(floor.occupancy_percentage) < 60:
                    insights['concerns'].append(
                        f'Floor {floor.floor_number} underutilized at {float(floor.occupancy_percentage)}%'
                    )
        
        return insights

# --- File: C:\Hostel-Main\app\repositories\analytics\platform_analytics_repository.py ---
"""
Platform Analytics Repository for multi-tenant oversight.

Provides comprehensive platform-wide analytics with:
- Tenant performance tracking
- Growth metrics and trends
- Churn analysis and prediction
- System health monitoring
- Platform usage analytics
- Revenue aggregation
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, desc
from sqlalchemy.orm import Session, joinedload
from uuid import UUID

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.models.analytics.platform_analytics import (
    TenantMetrics,
    PlatformMetrics,
    MonthlyMetric,
    GrowthMetrics,
    ChurnAnalysis,
    SystemHealthMetrics,
    PlatformUsageAnalytics,
    RevenueMetrics,
)


class PlatformAnalyticsRepository(BaseRepository):
    """Repository for platform-wide analytics operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
    
    # ==================== Tenant Metrics ====================
    
    def create_tenant_metrics(
        self,
        tenant_id: UUID,
        period_start: date,
        period_end: date,
        metrics_data: Dict[str, Any]
    ) -> TenantMetrics:
        """Create or update tenant performance metrics."""
        # Calculate health score
        health_score = self._calculate_tenant_health_score(metrics_data)
        metrics_data['health_score'] = health_score
        
        # Calculate churn risk
        churn_risk = self._calculate_churn_risk_score(metrics_data)
        metrics_data['churn_risk_score'] = churn_risk
        
        # Determine if at risk
        metrics_data['is_at_risk'] = float(churn_risk) > 70
        
        # Calculate revenue per bed
        if metrics_data.get('total_beds', 0) > 0:
            revenue_per_bed = (
                metrics_data.get('subscription_mrr', 0) / 
                metrics_data['total_beds']
            )
            metrics_data['revenue_per_bed'] = Decimal(str(round(revenue_per_bed, 2)))
        else:
            metrics_data['revenue_per_bed'] = Decimal('0.00')
        
        # Determine engagement status
        engagement_status = self._determine_engagement_status(metrics_data)
        metrics_data['engagement_status'] = engagement_status
        
        existing = self.db.query(TenantMetrics).filter(
            and_(
                TenantMetrics.tenant_id == tenant_id,
                TenantMetrics.period_start == period_start,
                TenantMetrics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in metrics_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = TenantMetrics(
            tenant_id=tenant_id,
            period_start=period_start,
            period_end=period_end,
            **metrics_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def get_tenant_metrics(
        self,
        tenant_id: UUID,
        period_start: date,
        period_end: date
    ) -> Optional[TenantMetrics]:
        """Get tenant metrics for period."""
        return self.db.query(TenantMetrics).filter(
            and_(
                TenantMetrics.tenant_id == tenant_id,
                TenantMetrics.period_start == period_start,
                TenantMetrics.period_end == period_end
            )
        ).first()
    
    def get_all_tenant_metrics(
        self,
        period_start: date,
        period_end: date
    ) -> List[TenantMetrics]:
        """Get metrics for all tenants in period."""
        return self.db.query(TenantMetrics).filter(
            and_(
                TenantMetrics.period_start == period_start,
                TenantMetrics.period_end == period_end
            )
        ).all()
    
    def get_at_risk_tenants(
        self,
        period_start: date,
        period_end: date,
        risk_threshold: float = 70.0
    ) -> List[TenantMetrics]:
        """Get tenants at risk of churning."""
        return self.db.query(TenantMetrics).filter(
            and_(
                TenantMetrics.period_start == period_start,
                TenantMetrics.period_end == period_end,
                TenantMetrics.churn_risk_score >= risk_threshold
            )
        ).order_by(TenantMetrics.churn_risk_score.desc()).all()
    
    def _calculate_tenant_health_score(
        self,
        metrics_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate tenant health score (0-100).
        
        Factors:
        - Occupancy rate: 30%
        - Active users ratio: 25%
        - Payment status: 25%
        - Engagement (DAU/MAU): 20%
        """
        score = 0.0
        
        # Occupancy rate
        occupancy = float(metrics_data.get('occupancy_rate', 0))
        score += (occupancy / 100) * 30
        
        # Active users ratio
        total_students = metrics_data.get('total_students', 0)
        active_students = metrics_data.get('active_students', 0)
        if total_students > 0:
            active_ratio = (active_students / total_students) * 100
            score += (active_ratio / 100) * 25
        
        # Payment status
        payment_status = metrics_data.get('payment_status', 'overdue')
        if payment_status == 'current':
            score += 25
        elif payment_status == 'overdue':
            score += 10
        else:  # suspended
            score += 0
        
        # Engagement (DAU/MAU ratio)
        dau = metrics_data.get('daily_active_users', 0)
        mau = metrics_data.get('monthly_active_users', 0)
        if mau > 0:
            engagement_ratio = (dau / mau) * 100
            score += min(engagement_ratio, 100) * 0.20
        
        return Decimal(str(round(score, 2)))
    
    def _calculate_churn_risk_score(
        self,
        metrics_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate churn risk score (0-100, higher = more risk).
        
        Risk factors:
        - Payment issues: 30%
        - Low engagement: 25%
        - Low occupancy: 20%
        - Declining usage: 15%
        - Support tickets: 10%
        """
        risk_score = 0.0
        
        # Payment issues
        payment_status = metrics_data.get('payment_status', 'current')
        if payment_status == 'suspended':
            risk_score += 30
        elif payment_status == 'overdue':
            risk_score += 20
        
        # Low engagement
        engagement = metrics_data.get('engagement_status', 'low')
        if engagement == 'inactive':
            risk_score += 25
        elif engagement == 'low':
            risk_score += 20
        elif engagement == 'moderate':
            risk_score += 10
        
        # Low occupancy
        occupancy = float(metrics_data.get('occupancy_rate', 0))
        if occupancy < 50:
            risk_score += 20
        elif occupancy < 70:
            risk_score += 10
        
        # Declining usage (simplified - would compare to previous period)
        dau = metrics_data.get('daily_active_users', 0)
        if dau == 0:
            risk_score += 15
        elif dau < 5:
            risk_score += 10
        
        # Support load (placeholder)
        risk_score += 0  # Would factor in support ticket volume
        
        return Decimal(str(round(risk_score, 2)))
    
    def _determine_engagement_status(
        self,
        metrics_data: Dict[str, Any]
    ) -> str:
        """Determine tenant engagement status."""
        dau = metrics_data.get('daily_active_users', 0)
        mau = metrics_data.get('monthly_active_users', 0)
        
        if mau == 0:
            return 'inactive'
        
        engagement_ratio = (dau / mau) * 100
        
        if engagement_ratio >= 40:
            return 'highly_active'
        elif engagement_ratio >= 25:
            return 'active'
        elif engagement_ratio >= 15:
            return 'moderate'
        elif engagement_ratio >= 5:
            return 'low'
        else:
            return 'inactive'
    
    # ==================== Platform Metrics ====================
    
    def create_platform_metrics(
        self,
        period_start: date,
        period_end: date,
        metrics_data: Dict[str, Any]
    ) -> PlatformMetrics:
        """Create or update platform-wide metrics."""
        # Calculate activation rate
        total_hostels = metrics_data.get('total_hostels', 0)
        active_hostels = metrics_data.get('active_hostels', 0)
        
        if total_hostels > 0:
            activation_rate = Decimal(str((active_hostels / total_hostels) * 100))
        else:
            activation_rate = Decimal('0.00')
        
        metrics_data['activation_rate'] = activation_rate
        
        # Estimate trial conversion potential
        on_trial = metrics_data.get('hostels_on_trial', 0)
        # Assume 30% conversion rate
        trial_conversion_potential = int(on_trial * 0.3)
        metrics_data['trial_conversion_potential'] = trial_conversion_potential
        
        existing = self.db.query(PlatformMetrics).filter(
            and_(
                PlatformMetrics.period_start == period_start,
                PlatformMetrics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in metrics_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = PlatformMetrics(
            period_start=period_start,
            period_end=period_end,
            **metrics_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def get_platform_metrics(
        self,
        period_start: date,
        period_end: date
    ) -> Optional[PlatformMetrics]:
        """Get platform metrics for period."""
        return self.db.query(PlatformMetrics).filter(
            and_(
                PlatformMetrics.period_start == period_start,
                PlatformMetrics.period_end == period_end
            )
        ).first()
    
    def get_platform_metrics_trend(
        self,
        start_date: date,
        end_date: date
    ) -> List[PlatformMetrics]:
        """Get platform metrics trend over time."""
        return self.db.query(PlatformMetrics).filter(
            and_(
                PlatformMetrics.period_start >= start_date,
                PlatformMetrics.period_end <= end_date
            )
        ).order_by(PlatformMetrics.period_start.asc()).all()
    
    # ==================== Growth Metrics ====================
    
    def create_growth_metrics(
        self,
        period_start: date,
        period_end: date,
        growth_data: Dict[str, Any]
    ) -> GrowthMetrics:
        """Create or update growth metrics."""
        # Calculate is_growing flag
        net_hostel_growth = growth_data.get('net_hostel_growth', 0)
        revenue_growth_rate = float(growth_data.get('revenue_growth_rate', 0))
        
        is_growing = (
            net_hostel_growth > 0 and 
            revenue_growth_rate > 0
        )
        growth_data['is_growing'] = is_growing
        
        # Calculate growth health score
        health_score = self._calculate_growth_health_score(growth_data)
        growth_data['growth_health_score'] = health_score
        
        existing = self.db.query(GrowthMetrics).filter(
            and_(
                GrowthMetrics.period_start == period_start,
                GrowthMetrics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in growth_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = GrowthMetrics(
            period_start=period_start,
            period_end=period_end,
            **growth_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def get_growth_metrics(
        self,
        period_start: date,
        period_end: date
    ) -> Optional[GrowthMetrics]:
        """Get growth metrics for period."""
        return self.db.query(GrowthMetrics).filter(
            and_(
                GrowthMetrics.period_start == period_start,
                GrowthMetrics.period_end == period_end
            )
        ).first()
    
    def add_monthly_metrics(
        self,
        growth_metrics_id: UUID,
        monthly_data: List[Dict[str, Any]]
    ) -> List[MonthlyMetric]:
        """Add monthly metric data points."""
        created_metrics = []
        
        for data in monthly_data:
            existing = self.db.query(MonthlyMetric).filter(
                and_(
                    MonthlyMetric.growth_metrics_id == growth_metrics_id,
                    MonthlyMetric.metric_key == data['metric_key'],
                    MonthlyMetric.month == data['month']
                )
            ).first()
            
            if existing:
                existing.value = data['value']
                if 'label' in data:
                    existing.label = data['label']
                created_metrics.append(existing)
            else:
                metric = MonthlyMetric(
                    growth_metrics_id=growth_metrics_id,
                    **data
                )
                self.db.add(metric)
                created_metrics.append(metric)
        
        self.db.commit()
        for metric in created_metrics:
            self.db.refresh(metric)
        
        return created_metrics
    
    def _calculate_growth_health_score(
        self,
        growth_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate growth health score (0-100).
        
        Factors:
        - Hostel growth rate: 30%
        - Revenue growth rate: 30%
        - User growth rate: 20%
        - MRR growth rate: 20%
        """
        score = 0.0
        
        # Hostel growth (normalize to 0-100)
        hostel_growth = float(growth_data.get('hostel_growth_rate', 0))
        score += min(max(hostel_growth, 0), 100) * 0.30
        
        # Revenue growth
        revenue_growth = float(growth_data.get('revenue_growth_rate', 0))
        score += min(max(revenue_growth, 0), 100) * 0.30
        
        # User growth
        user_growth = float(growth_data.get('user_growth_rate', 0))
        score += min(max(user_growth, 0), 100) * 0.20
        
        # MRR growth
        mrr_growth = float(growth_data.get('mrr_growth_rate', 0))
        score += min(max(mrr_growth, 0), 100) * 0.20
        
        return Decimal(str(round(score, 2)))
    
    # ==================== Churn Analysis ====================
    
    def create_churn_analysis(
        self,
        period_start: date,
        period_end: date,
        churn_data: Dict[str, Any]
    ) -> ChurnAnalysis:
        """Create or update churn analysis."""
        # Determine churn risk status
        churn_rate = float(churn_data.get('churn_rate', 0))
        
        if churn_rate < 2:
            risk_status = 'low'
        elif churn_rate < 5:
            risk_status = 'moderate'
        elif churn_rate < 10:
            risk_status = 'high'
        else:
            risk_status = 'critical'
        
        churn_data['churn_risk_status'] = risk_status
        
        # Identify top churn reason
        if churn_data.get('churn_reasons'):
            reasons = churn_data['churn_reasons']
            top_reason = max(reasons.items(), key=lambda x: x[1])[0]
            churn_data['top_churn_reason'] = top_reason
        
        existing = self.db.query(ChurnAnalysis).filter(
            and_(
                ChurnAnalysis.period_start == period_start,
                ChurnAnalysis.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in churn_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        analysis = ChurnAnalysis(
            period_start=period_start,
            period_end=period_end,
            **churn_data
        )
        
        self.db.add(analysis)
        self.db.commit()
        self.db.refresh(analysis)
        
        return analysis
    
    def get_churn_analysis(
        self,
        period_start: date,
        period_end: date
    ) -> Optional[ChurnAnalysis]:
        """Get churn analysis for period."""
        return self.db.query(ChurnAnalysis).filter(
            and_(
                ChurnAnalysis.period_start == period_start,
                ChurnAnalysis.period_end == period_end
            )
        ).first()
    
    # ==================== System Health ====================
    
    def create_system_health_metrics(
        self,
        period_start: date,
        period_end: date,
        health_data: Dict[str, Any]
    ) -> SystemHealthMetrics:
        """Create or update system health metrics."""
        # Determine health status
        uptime = float(health_data.get('uptime_percentage', 0))
        error_rate = float(health_data.get('error_rate_percentage', 0))
        avg_response = float(health_data.get('average_response_time_ms', 0))
        
        health_status = self._determine_system_health_status(
            uptime, error_rate, avg_response
        )
        health_data['health_status'] = health_status
        
        # Assign performance grade
        performance_grade = self._assign_system_performance_grade(health_data)
        health_data['performance_grade'] = performance_grade
        
        existing = self.db.query(SystemHealthMetrics).filter(
            and_(
                SystemHealthMetrics.period_start == period_start,
                SystemHealthMetrics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in health_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = SystemHealthMetrics(
            period_start=period_start,
            period_end=period_end,
            **health_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def _determine_system_health_status(
        self,
        uptime: float,
        error_rate: float,
        avg_response_ms: float
    ) -> str:
        """Determine overall system health status."""
        if uptime >= 99.9 and error_rate < 0.1 and avg_response_ms < 200:
            return 'excellent'
        elif uptime >= 99.5 and error_rate < 0.5 and avg_response_ms < 500:
            return 'good'
        elif uptime >= 99.0 and error_rate < 1.0 and avg_response_ms < 1000:
            return 'fair'
        else:
            return 'poor'
    
    def _assign_system_performance_grade(
        self,
        health_data: Dict[str, Any]
    ) -> str:
        """Assign letter grade to system performance."""
        uptime = float(health_data.get('uptime_percentage', 0))
        
        if uptime >= 99.99:
            return 'A+'
        elif uptime >= 99.95:
            return 'A'
        elif uptime >= 99.9:
            return 'A-'
        elif uptime >= 99.5:
            return 'B+'
        elif uptime >= 99.0:
            return 'B'
        elif uptime >= 98.5:
            return 'B-'
        elif uptime >= 98.0:
            return 'C+'
        else:
            return 'C'
    
    # ==================== Platform Usage ====================
    
    def create_platform_usage_analytics(
        self,
        period_start: date,
        period_end: date,
        usage_data: Dict[str, Any]
    ) -> PlatformUsageAnalytics:
        """Create or update platform usage analytics."""
        # Identify most used module
        if usage_data.get('requests_by_module'):
            modules = usage_data['requests_by_module']
            most_used = max(modules.items(), key=lambda x: x[1])[0]
            usage_data['most_used_module'] = most_used
        
        # Determine platform health
        error_rate = float(usage_data.get('api_error_rate', 0))
        
        if error_rate < 0.1:
            health_indicator = 'healthy'
        elif error_rate < 0.5:
            health_indicator = 'stable'
        elif error_rate < 1.0:
            health_indicator = 'degraded'
        else:
            health_indicator = 'critical'
        
        usage_data['platform_health_indicator'] = health_indicator
        
        existing = self.db.query(PlatformUsageAnalytics).filter(
            and_(
                PlatformUsageAnalytics.period_start == period_start,
                PlatformUsageAnalytics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in usage_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        analytics = PlatformUsageAnalytics(
            period_start=period_start,
            period_end=period_end,
            **usage_data
        )
        
        self.db.add(analytics)
        self.db.commit()
        self.db.refresh(analytics)
        
        return analytics
    
    # ==================== Revenue Metrics ====================
    
    def create_revenue_metrics(
        self,
        period_start: date,
        period_end: date,
        revenue_data: Dict[str, Any]
    ) -> RevenueMetrics:
        """Create or update platform revenue metrics."""
        # Calculate revenue diversity score
        diversity_score = self._calculate_revenue_diversity(revenue_data)
        revenue_data['revenue_diversity_score'] = diversity_score
        
        # Calculate net new MRR
        new_customer_rev = float(revenue_data.get('new_customer_revenue', 0))
        expansion_rev = float(revenue_data.get('expansion_revenue', 0))
        churned_rev = float(revenue_data.get('churned_revenue', 0))
        
        net_new_mrr = Decimal(str(new_customer_rev + expansion_rev - churned_rev))
        revenue_data['net_new_mrr'] = net_new_mrr
        
        existing = self.db.query(RevenueMetrics).filter(
            and_(
                RevenueMetrics.period_start == period_start,
                RevenueMetrics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in revenue_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = RevenueMetrics(
            period_start=period_start,
            period_end=period_end,
            **revenue_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def _calculate_revenue_diversity(
        self,
        revenue_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate revenue diversity score (0-100).
        
        Higher score = more diversified revenue sources.
        Uses Herfindahl-Hirschman Index (HHI) inverse.
        """
        total_revenue = float(revenue_data.get('total_revenue', 0))
        
        if total_revenue == 0:
            return Decimal('0.00')
        
        # Get revenue by plan
        revenue_by_plan = revenue_data.get('revenue_by_plan', {})
        
        if not revenue_by_plan:
            return Decimal('50.00')  # Default moderate diversity
        
        # Calculate HHI
        hhi = 0.0
        for plan_revenue in revenue_by_plan.values():
            market_share = float(plan_revenue) / total_revenue
            hhi += market_share ** 2
        
        # Convert HHI to diversity score (inverse relationship)
        # HHI ranges from 1/n to 1 (where n is number of plans)
        # Perfect diversity (equal split) = 1/n, monopoly = 1
        
        num_plans = len(revenue_by_plan)
        if num_plans == 0:
            return Decimal('0.00')
        
        perfect_diversity_hhi = 1 / num_plans
        
        # Normalize to 0-100 scale
        if hhi <= perfect_diversity_hhi:
            diversity_score = 100.0
        else:
            # Linear scale from perfect to monopoly
            diversity_score = (1 - hhi) / (1 - perfect_diversity_hhi) * 100
        
        return Decimal(str(round(max(0, min(100, diversity_score)), 2)))

# --- File: C:\Hostel-Main\app\repositories\analytics\supervisor_analytics_repository.py ---
"""
Supervisor Analytics Repository for performance tracking.

Provides comprehensive supervisor analytics with:
- Individual supervisor KPIs
- Workload distribution analysis
- Performance rating tracking
- Team analytics aggregation
- Comparative benchmarking
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, desc
from sqlalchemy.orm import Session, joinedload
from uuid import UUID

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.models.analytics.supervisor_analytics import (
    SupervisorWorkload,
    SupervisorPerformanceRating,
    SupervisorKPI,
    SupervisorTrendPoint,
    SupervisorComparison,
    TeamAnalytics,
)


class SupervisorAnalyticsRepository(BaseRepository):
    """Repository for supervisor analytics operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
    
    # ==================== Supervisor KPI ====================
    
    def create_supervisor_kpi(
        self,
        supervisor_id: UUID,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        kpi_data: Dict[str, Any]
    ) -> SupervisorKPI:
        """Create or update supervisor KPI."""
        # Calculate derived metrics
        complaint_resolution_rate = self._calculate_resolution_rate(
            kpi_data.get('complaints_resolved', 0),
            kpi_data.get('complaints_assigned', 0)
        )
        kpi_data['complaint_resolution_rate'] = complaint_resolution_rate
        
        maintenance_completion_rate = self._calculate_resolution_rate(
            kpi_data.get('maintenance_requests_completed', 0),
            kpi_data.get('maintenance_requests_created', 0)
        )
        kpi_data['maintenance_completion_rate'] = maintenance_completion_rate
        
        reopen_rate = self._calculate_reopen_rate(
            kpi_data.get('reopened_complaints', 0),
            kpi_data.get('complaints_resolved', 0)
        )
        kpi_data['reopen_rate'] = reopen_rate
        
        # Determine performance status
        performance_status = self._determine_performance_status(
            kpi_data.get('overall_performance_score', 0)
        )
        kpi_data['performance_status'] = performance_status
        
        existing = self.db.query(SupervisorKPI).filter(
            and_(
                SupervisorKPI.supervisor_id == supervisor_id,
                SupervisorKPI.hostel_id == hostel_id if hostel_id else SupervisorKPI.hostel_id.is_(None),
                SupervisorKPI.period_start == period_start,
                SupervisorKPI.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in kpi_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        kpi = SupervisorKPI(
            supervisor_id=supervisor_id,
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **kpi_data
        )
        
        self.db.add(kpi)
        self.db.commit()
        self.db.refresh(kpi)
        
        return kpi
    
    def get_supervisor_kpi(
        self,
        supervisor_id: UUID,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> Optional[SupervisorKPI]:
        """Get supervisor KPI for period."""
        return self.db.query(SupervisorKPI).filter(
            and_(
                SupervisorKPI.supervisor_id == supervisor_id,
                SupervisorKPI.hostel_id == hostel_id if hostel_id else SupervisorKPI.hostel_id.is_(None),
                SupervisorKPI.period_start == period_start,
                SupervisorKPI.period_end == period_end
            )
        ).first()
    
    def get_all_supervisor_kpis(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> List[SupervisorKPI]:
        """Get all supervisor KPIs for a period."""
        query = QueryBuilder(SupervisorKPI, self.db)
        
        if hostel_id:
            query = query.where(SupervisorKPI.hostel_id == hostel_id)
        
        query = query.where(
            and_(
                SupervisorKPI.period_start == period_start,
                SupervisorKPI.period_end == period_end
            )
        )
        
        return query.all()
    
    def _calculate_resolution_rate(
        self,
        resolved: int,
        total: int
    ) -> Decimal:
        """Calculate resolution/completion rate."""
        if total == 0:
            return Decimal('0.00')
        
        rate = (resolved / total) * 100
        return Decimal(str(round(rate, 2)))
    
    def _calculate_reopen_rate(
        self,
        reopened: int,
        resolved: int
    ) -> Decimal:
        """Calculate complaint reopen rate."""
        if resolved == 0:
            return Decimal('0.00')
        
        rate = (reopened / resolved) * 100
        return Decimal(str(round(rate, 2)))
    
    def _determine_performance_status(
        self,
        performance_score: Decimal
    ) -> str:
        """Determine performance status category."""
        score = float(performance_score)
        
        if score >= 90:
            return 'excellent'
        elif score >= 80:
            return 'good'
        elif score >= 70:
            return 'satisfactory'
        elif score >= 60:
            return 'needs_improvement'
        else:
            return 'unsatisfactory'
    
    # ==================== Workload Management ====================
    
    def create_supervisor_workload(
        self,
        supervisor_kpi_id: UUID,
        workload_data: Dict[str, Any]
    ) -> SupervisorWorkload:
        """Create or update supervisor workload."""
        # Calculate available capacity
        max_capacity = workload_data.get('max_capacity', 0)
        pending_tasks = workload_data.get('pending_tasks', 0)
        
        available_capacity = max(0, max_capacity - pending_tasks)
        workload_data['available_capacity'] = available_capacity
        
        # Determine workload status
        current_utilization = float(workload_data.get('current_utilization', 0))
        
        if current_utilization >= 95:
            workload_status = 'overloaded'
        elif current_utilization >= 80:
            workload_status = 'high'
        elif current_utilization >= 50:
            workload_status = 'moderate'
        else:
            workload_status = 'low'
        
        workload_data['workload_status'] = workload_status
        
        existing = self.db.query(SupervisorWorkload).filter(
            SupervisorWorkload.supervisor_kpi_id == supervisor_kpi_id
        ).first()
        
        if existing:
            for key, value in workload_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        workload = SupervisorWorkload(
            supervisor_kpi_id=supervisor_kpi_id,
            **workload_data
        )
        
        self.db.add(workload)
        self.db.commit()
        self.db.refresh(workload)
        
        return workload
    
    # ==================== Performance Rating ====================
    
    def create_performance_rating(
        self,
        supervisor_kpi_id: UUID,
        rating_data: Dict[str, Any]
    ) -> SupervisorPerformanceRating:
        """Create or update performance rating."""
        # Calculate overall rating (weighted average)
        overall_rating = self._calculate_overall_rating(rating_data)
        rating_data['overall_rating'] = overall_rating
        
        # Assign performance grade
        performance_grade = self._assign_performance_grade(overall_rating)
        rating_data['performance_grade'] = performance_grade
        
        # Identify strengths and improvement areas
        strengths, improvements = self._analyze_performance_dimensions(rating_data)
        rating_data['strengths'] = strengths
        rating_data['improvement_areas'] = improvements
        
        existing = self.db.query(SupervisorPerformanceRating).filter(
            SupervisorPerformanceRating.supervisor_kpi_id == supervisor_kpi_id
        ).first()
        
        if existing:
            for key, value in rating_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        rating = SupervisorPerformanceRating(
            supervisor_kpi_id=supervisor_kpi_id,
            **rating_data
        )
        
        self.db.add(rating)
        self.db.commit()
        self.db.refresh(rating)
        
        return rating
    
    def _calculate_overall_rating(
        self,
        rating_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate overall performance rating (0-100).
        
        Weighted average:
        - Efficiency: 25%
        - Quality: 25%
        - Responsiveness: 20%
        - Student satisfaction: 20%
        - Reliability: 10%
        """
        weights = {
            'efficiency_score': 0.25,
            'quality_score': 0.25,
            'responsiveness_score': 0.20,
            'student_satisfaction_score': 0.20,
            'reliability_score': 0.10,
        }
        
        weighted_sum = sum(
            float(rating_data.get(key, 0)) * weight
            for key, weight in weights.items()
        )
        
        return Decimal(str(round(weighted_sum, 2)))
    
    def _assign_performance_grade(
        self,
        overall_rating: Decimal
    ) -> str:
        """Assign letter grade based on overall rating."""
        rating = float(overall_rating)
        
        if rating >= 95:
            return 'A+'
        elif rating >= 90:
            return 'A'
        elif rating >= 85:
            return 'A-'
        elif rating >= 80:
            return 'B+'
        elif rating >= 75:
            return 'B'
        elif rating >= 70:
            return 'B-'
        elif rating >= 65:
            return 'C+'
        elif rating >= 60:
            return 'C'
        else:
            return 'D'
    
    def _analyze_performance_dimensions(
        self,
        rating_data: Dict[str, Any]
    ) -> Tuple[List[str], List[str]]:
        """Identify performance strengths and areas for improvement."""
        dimensions = {
            'Efficiency': float(rating_data.get('efficiency_score', 0)),
            'Quality': float(rating_data.get('quality_score', 0)),
            'Responsiveness': float(rating_data.get('responsiveness_score', 0)),
            'Student Satisfaction': float(rating_data.get('student_satisfaction_score', 0)),
            'Reliability': float(rating_data.get('reliability_score', 0)),
        }
        
        # Strengths: scores >= 80
        strengths = [
            dim for dim, score in dimensions.items()
            if score >= 80
        ]
        
        # Improvement areas: scores < 70
        improvements = [
            dim for dim, score in dimensions.items()
            if score < 70
        ]
        
        return strengths, improvements
    
    # ==================== Trend Tracking ====================
    
    def add_supervisor_trend_points(
        self,
        supervisor_kpi_id: UUID,
        trend_points: List[Dict[str, Any]]
    ) -> List[SupervisorTrendPoint]:
        """Add supervisor performance trend points."""
        created_points = []
        
        for point_data in trend_points:
            # Calculate total tasks
            total_tasks = (
                point_data.get('complaints_resolved', 0) +
                point_data.get('maintenance_completed', 0)
            )
            point_data['total_tasks_completed'] = total_tasks
            
            existing = self.db.query(SupervisorTrendPoint).filter(
                and_(
                    SupervisorTrendPoint.supervisor_kpi_id == supervisor_kpi_id,
                    SupervisorTrendPoint.period_start == point_data['period_start'],
                    SupervisorTrendPoint.period_end == point_data['period_end']
                )
            ).first()
            
            if existing:
                for key, value in point_data.items():
                    setattr(existing, key, value)
                created_points.append(existing)
            else:
                point = SupervisorTrendPoint(
                    supervisor_kpi_id=supervisor_kpi_id,
                    **point_data
                )
                self.db.add(point)
                created_points.append(point)
        
        self.db.commit()
        for point in created_points:
            self.db.refresh(point)
        
        return created_points
    
    def get_supervisor_trend_points(
        self,
        supervisor_kpi_id: UUID
    ) -> List[SupervisorTrendPoint]:
        """Get all trend points for a supervisor KPI."""
        return self.db.query(SupervisorTrendPoint).filter(
            SupervisorTrendPoint.supervisor_kpi_id == supervisor_kpi_id
        ).order_by(SupervisorTrendPoint.period_start.asc()).all()
    
    # ==================== Comparative Analysis ====================
    
    def create_supervisor_comparison(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date,
        scope_type: str = 'hostel'
    ) -> SupervisorComparison:
        """Create supervisor performance comparison."""
        # Get all supervisor KPIs for the period
        kpis = self.get_all_supervisor_kpis(hostel_id, period_start, period_end)
        
        if not kpis:
            return None
        
        # Sort by various metrics
        ranked_by_performance = sorted(
            kpis,
            key=lambda k: k.overall_performance_score,
            reverse=True
        )
        
        ranked_by_resolution_speed = sorted(
            kpis,
            key=lambda k: k.avg_complaint_resolution_time_hours
        )
        
        ranked_by_feedback = sorted(
            kpis,
            key=lambda k: k.student_feedback_score or 0,
            reverse=True
        )
        
        ranked_by_sla = sorted(
            kpis,
            key=lambda k: k.complaint_sla_compliance_rate,
            reverse=True
        )
        
        # Create rankings (just IDs)
        rankings = {
            'ranked_by_performance': [str(k.supervisor_id) for k in ranked_by_performance],
            'ranked_by_resolution_speed': [str(k.supervisor_id) for k in ranked_by_resolution_speed],
            'ranked_by_feedback_score': [str(k.supervisor_id) for k in ranked_by_feedback],
            'ranked_by_sla_compliance': [str(k.supervisor_id) for k in ranked_by_sla],
        }
        
        # Calculate statistics
        avg_performance = sum(
            float(k.overall_performance_score) for k in kpis
        ) / len(kpis)
        
        avg_resolution_time = sum(
            float(k.avg_complaint_resolution_time_hours) for k in kpis
        ) / len(kpis)
        
        avg_sla = sum(
            float(k.complaint_sla_compliance_rate) for k in kpis
        ) / len(kpis)
        
        # Top performer
        top_performer = ranked_by_performance[0].supervisor_id
        
        # Performance variance
        performance_scores = [float(k.overall_performance_score) for k in kpis]
        if len(performance_scores) > 1:
            mean = sum(performance_scores) / len(performance_scores)
            variance = sum((x - mean) ** 2 for x in performance_scores) / len(performance_scores)
        else:
            variance = 0.0
        
        existing = self.db.query(SupervisorComparison).filter(
            and_(
                SupervisorComparison.hostel_id == hostel_id if hostel_id else SupervisorComparison.hostel_id.is_(None),
                SupervisorComparison.period_start == period_start,
                SupervisorComparison.period_end == period_end,
                SupervisorComparison.scope_type == scope_type
            )
        ).first()
        
        comparison_data = {
            **rankings,
            'avg_performance_score': Decimal(str(round(avg_performance, 2))),
            'avg_resolution_time_hours': Decimal(str(round(avg_resolution_time, 2))),
            'avg_sla_compliance': Decimal(str(round(avg_sla, 2))),
            'top_performer': top_performer,
            'performance_variance': Decimal(str(round(variance, 4))),
            'calculated_at': datetime.utcnow(),
        }
        
        if existing:
            for key, value in comparison_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        comparison = SupervisorComparison(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            scope_type=scope_type,
            **comparison_data
        )
        
        self.db.add(comparison)
        self.db.commit()
        self.db.refresh(comparison)
        
        return comparison
    
    # ==================== Team Analytics ====================
    
    def create_team_analytics(
        self,
        hostel_id: Optional[UUID],
        period_start: date,
        period_end: date
    ) -> TeamAnalytics:
        """Create team-level supervisor analytics."""
        # Get all supervisor KPIs
        kpis = self.get_all_supervisor_kpis(hostel_id, period_start, period_end)
        
        if not kpis:
            return None
        
        # Calculate aggregates
        total_supervisors = len(kpis)
        active_supervisors = len([k for k in kpis if k.complaints_assigned > 0])
        
        total_tasks_assigned = sum(
            k.complaints_assigned + k.maintenance_requests_created
            for k in kpis
        )
        
        total_tasks_completed = sum(
            k.complaints_resolved + k.maintenance_requests_completed
            for k in kpis
        )
        
        team_completion_rate = (
            Decimal(str((total_tasks_completed / total_tasks_assigned) * 100))
            if total_tasks_assigned > 0 else Decimal('0.00')
        )
        
        avg_performance = sum(
            float(k.overall_performance_score) for k in kpis
        ) / len(kpis)
        
        avg_sla = sum(
            float(k.complaint_sla_compliance_rate) for k in kpis
        ) / len(kpis)
        
        # Calculate workload balance
        workload_balance = self._calculate_workload_balance(kpis)
        
        # Identify top performers
        top_performers = sorted(
            kpis,
            key=lambda k: k.overall_performance_score,
            reverse=True
        )[:5]
        
        top_performer_ids = [str(k.supervisor_id) for k in top_performers]
        
        # Determine team efficiency
        if avg_performance >= 85:
            team_efficiency = 'high'
        elif avg_performance >= 70:
            team_efficiency = 'moderate'
        else:
            team_efficiency = 'low'
        
        existing = self.db.query(TeamAnalytics).filter(
            and_(
                TeamAnalytics.hostel_id == hostel_id if hostel_id else TeamAnalytics.hostel_id.is_(None),
                TeamAnalytics.period_start == period_start,
                TeamAnalytics.period_end == period_end
            )
        ).first()
        
        team_data = {
            'total_supervisors': total_supervisors,
            'active_supervisors': active_supervisors,
            'total_tasks_assigned': total_tasks_assigned,
            'total_tasks_completed': total_tasks_completed,
            'team_completion_rate': team_completion_rate,
            'avg_team_performance_score': Decimal(str(round(avg_performance, 2))),
            'avg_team_sla_compliance': Decimal(str(round(avg_sla, 2))),
            'workload_balance_score': workload_balance,
            'top_performers': top_performer_ids,
            'team_efficiency': team_efficiency,
            'calculated_at': datetime.utcnow(),
        }
        
        if existing:
            for key, value in team_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        analytics = TeamAnalytics(
            hostel_id=hostel_id,
            period_start=period_start,
            period_end=period_end,
            **team_data
        )
        
        self.db.add(analytics)
        self.db.commit()
        self.db.refresh(analytics)
        
        return analytics
    
    def _calculate_workload_balance(
        self,
        kpis: List[SupervisorKPI]
    ) -> Decimal:
        """
        Calculate workload balance score (0-100).
        
        100 = perfectly balanced workload
        Lower score = more imbalance
        """
        if not kpis:
            return Decimal('0.00')
        
        # Get task counts
        task_counts = [
            k.complaints_assigned + k.maintenance_requests_created
            for k in kpis
        ]
        
        if not task_counts or sum(task_counts) == 0:
            return Decimal('100.00')  # No tasks = balanced
        
        # Calculate coefficient of variation
        mean = sum(task_counts) / len(task_counts)
        
        if mean == 0:
            return Decimal('100.00')
        
        variance = sum((x - mean) ** 2 for x in task_counts) / len(task_counts)
        std_dev = variance ** 0.5
        cv = std_dev / mean
        
        # Convert to balance score (lower CV = higher balance)
        # CV of 0 = perfect balance (100), CV of 1 or more = poor balance (0)
        balance_score = max(0, min(100, (1 - cv) * 100))
        
        return Decimal(str(round(balance_score, 2)))

# --- File: C:\Hostel-Main\app\repositories\analytics\visitor_analytics_repository.py ---
"""
Visitor Analytics Repository for funnel and behavior tracking.

Provides comprehensive visitor analytics with:
- Acquisition funnel tracking
- Traffic source performance
- Search behavior analysis
- Engagement metrics
- Conversion path analysis
- Visitor behavior insights
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import date, datetime, timedelta
from decimal import Decimal
from sqlalchemy import and_, or_, func, select, case, desc
from sqlalchemy.orm import Session, joinedload
from uuid import UUID

from app.repositories.base.base_repository import BaseRepository
from app.repositories.base.query_builder import QueryBuilder
from app.models.analytics.visitor_analytics import (
    VisitorFunnel,
    TrafficSourceMetrics,
    SearchBehavior,
    EngagementMetrics,
    VisitorBehaviorAnalytics,
    ConversionPathAnalysis,
    TrafficSourceAnalytics,
)


class VisitorAnalyticsRepository(BaseRepository):
    """Repository for visitor analytics operations."""
    
    def __init__(self, db: Session):
        super().__init__(db)
    
    # ==================== Visitor Funnel ====================
    
    def create_visitor_funnel(
        self,
        period_start: date,
        period_end: date,
        funnel_data: Dict[str, Any]
    ) -> VisitorFunnel:
        """Create or update visitor acquisition funnel."""
        # Calculate conversion rates
        total_visits = funnel_data.get('total_visits', 0)
        
        if total_visits > 0:
            visit_to_search = (
                funnel_data.get('searches_performed', 0) / total_visits
            ) * 100
            
            search_to_view = (
                funnel_data.get('hostel_views', 0) / 
                max(funnel_data.get('searches_performed', 1), 1)
            ) * 100
            
            view_to_registration = (
                funnel_data.get('registrations', 0) / 
                max(funnel_data.get('hostel_views', 1), 1)
            ) * 100
            
            registration_to_booking = (
                funnel_data.get('bookings', 0) / 
                max(funnel_data.get('registrations', 1), 1)
            ) * 100
            
            booking_to_confirm = (
                funnel_data.get('confirmed_bookings', 0) / 
                max(funnel_data.get('bookings', 1), 1)
            ) * 100
            
            visit_to_booking = (
                funnel_data.get('confirmed_bookings', 0) / total_visits
            ) * 100
        else:
            visit_to_search = 0
            search_to_view = 0
            view_to_registration = 0
            registration_to_booking = 0
            booking_to_confirm = 0
            visit_to_booking = 0
        
        funnel_data.update({
            'visit_to_search_rate': Decimal(str(round(visit_to_search, 2))),
            'search_to_view_rate': Decimal(str(round(search_to_view, 2))),
            'view_to_registration_rate': Decimal(str(round(view_to_registration, 2))),
            'registration_to_booking_rate': Decimal(str(round(registration_to_booking, 2))),
            'booking_to_confirm_rate': Decimal(str(round(booking_to_confirm, 2))),
            'visit_to_booking_rate': Decimal(str(round(visit_to_booking, 2))),
        })
        
        # Calculate drop-offs
        dropped_after_search = max(
            0,
            funnel_data.get('searches_performed', 0) - 
            funnel_data.get('hostel_views', 0)
        )
        
        dropped_after_view = max(
            0,
            funnel_data.get('hostel_views', 0) - 
            funnel_data.get('registrations', 0)
        )
        
        dropped_after_booking_start = max(
            0,
            funnel_data.get('booking_starts', 0) - 
            funnel_data.get('bookings', 0)
        )
        
        funnel_data.update({
            'dropped_after_search': dropped_after_search,
            'dropped_after_hostel_view': dropped_after_view,
            'dropped_after_booking_start': dropped_after_booking_start,
        })
        
        # Calculate insights
        total_drop_offs = (
            dropped_after_search +
            dropped_after_view +
            dropped_after_booking_start
        )
        funnel_data['total_drop_offs'] = total_drop_offs
        
        # Identify largest drop-off stage
        drop_offs = {
            'search': dropped_after_search,
            'hostel_view': dropped_after_view,
            'booking_start': dropped_after_booking_start,
        }
        
        largest_drop_off_stage = max(drop_offs.items(), key=lambda x: x[1])[0]
        funnel_data['largest_drop_off_stage'] = largest_drop_off_stage
        
        # Calculate efficiency score
        efficiency = (visit_to_booking / 100) * 100  # Already percentage
        funnel_data['funnel_efficiency_score'] = Decimal(str(round(efficiency, 2)))
        
        existing = self.db.query(VisitorFunnel).filter(
            and_(
                VisitorFunnel.period_start == period_start,
                VisitorFunnel.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in funnel_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        funnel = VisitorFunnel(
            period_start=period_start,
            period_end=period_end,
            **funnel_data
        )
        
        self.db.add(funnel)
        self.db.commit()
        self.db.refresh(funnel)
        
        return funnel
    
    def get_visitor_funnel(
        self,
        period_start: date,
        period_end: date
    ) -> Optional[VisitorFunnel]:
        """Get visitor funnel for period."""
        return self.db.query(VisitorFunnel).filter(
            and_(
                VisitorFunnel.period_start == period_start,
                VisitorFunnel.period_end == period_end
            )
        ).first()
    
    # ==================== Traffic Source Metrics ====================
    
    def create_traffic_source_metrics(
        self,
        period_start: date,
        period_end: date,
        source: str,
        metrics_data: Dict[str, Any]
    ) -> TrafficSourceMetrics:
        """Create or update traffic source metrics."""
        # Calculate engagement score
        engagement_score = self._calculate_engagement_score(metrics_data)
        metrics_data['engagement_score'] = engagement_score
        
        # Calculate quality score
        quality_score = self._calculate_source_quality_score(metrics_data)
        metrics_data['quality_score'] = quality_score
        
        existing = self.db.query(TrafficSourceMetrics).filter(
            and_(
                TrafficSourceMetrics.period_start == period_start,
                TrafficSourceMetrics.period_end == period_end,
                TrafficSourceMetrics.source == source
            )
        ).first()
        
        if existing:
            for key, value in metrics_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = TrafficSourceMetrics(
            period_start=period_start,
            period_end=period_end,
            source=source,
            **metrics_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def get_traffic_source_metrics(
        self,
        period_start: date,
        period_end: date
    ) -> List[TrafficSourceMetrics]:
        """Get all traffic source metrics for period."""
        return self.db.query(TrafficSourceMetrics).filter(
            and_(
                TrafficSourceMetrics.period_start == period_start,
                TrafficSourceMetrics.period_end == period_end
            )
        ).order_by(TrafficSourceMetrics.visits.desc()).all()
    
    def _calculate_engagement_score(
        self,
        metrics_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate engagement score (0-100).
        
        Factors:
        - Session duration: 30%
        - Pages per session: 30%
        - Bounce rate (inverse): 40%
        """
        # Normalize session duration (assume 300s is excellent)
        avg_duration = float(metrics_data.get('avg_session_duration_seconds', 0))
        duration_score = min(avg_duration / 300, 1.0) * 30
        
        # Normalize pages per session (assume 5 is excellent)
        avg_pages = float(metrics_data.get('avg_pages_per_session', 0))
        pages_score = min(avg_pages / 5, 1.0) * 30
        
        # Bounce rate (inverse)
        bounce_rate = float(metrics_data.get('bounce_rate', 100))
        bounce_score = max(0, (100 - bounce_rate)) * 0.40
        
        total_score = duration_score + pages_score + bounce_score
        
        return Decimal(str(round(total_score, 2)))
    
    def _calculate_source_quality_score(
        self,
        metrics_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate source quality score (0-100).
        
        Factors:
        - Conversion rate: 40%
        - Engagement score: 30%
        - ROI: 30%
        """
        # Conversion rate (normalize to 0-1, assume 5% is excellent)
        conversion_rate = float(metrics_data.get('visit_to_booking_rate', 0))
        conversion_score = min(conversion_rate / 5, 1.0) * 40
        
        # Engagement
        engagement_score = float(metrics_data.get('engagement_score', 0)) * 0.30
        
        # ROI (normalize, assume 300% is excellent)
        roi = float(metrics_data.get('roi', 0)) if metrics_data.get('roi') else 0
        roi_score = min(max(roi, 0) / 300, 1.0) * 30
        
        total_score = conversion_score + engagement_score + roi_score
        
        return Decimal(str(round(total_score, 2)))
    
    # ==================== Search Behavior ====================
    
    def create_search_behavior(
        self,
        period_start: date,
        period_end: date,
        behavior_data: Dict[str, Any]
    ) -> SearchBehavior:
        """Create or update search behavior analytics."""
        # Calculate effectiveness score
        effectiveness = self._calculate_search_effectiveness(behavior_data)
        behavior_data['search_effectiveness_score'] = effectiveness
        
        existing = self.db.query(SearchBehavior).filter(
            and_(
                SearchBehavior.period_start == period_start,
                SearchBehavior.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in behavior_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        behavior = SearchBehavior(
            period_start=period_start,
            period_end=period_end,
            **behavior_data
        )
        
        self.db.add(behavior)
        self.db.commit()
        self.db.refresh(behavior)
        
        return behavior
    
    def _calculate_search_effectiveness(
        self,
        behavior_data: Dict[str, Any]
    ) -> Decimal:
        """
        Calculate search effectiveness score (0-100).
        
        Factors:
        - Zero result rate (inverse): 50%
        - Avg results per search: 30%
        - Filter usage: 20%
        """
        # Zero result rate (inverse)
        zero_result_rate = float(behavior_data.get('zero_result_rate', 0))
        zero_result_score = max(0, 100 - zero_result_rate) * 0.50
        
        # Avg results (normalize, assume 10 is ideal)
        avg_results = float(behavior_data.get('avg_results_per_search', 0))
        results_score = min(avg_results / 10, 1.0) * 30
        
        # Filter usage (normalize, assume 2 filters is good)
        avg_filters = float(behavior_data.get('avg_filters_used', 0))
        filter_score = min(avg_filters / 2, 1.0) * 20
        
        total_score = zero_result_score + results_score + filter_score
        
        return Decimal(str(round(total_score, 2)))
    
    # ==================== Engagement Metrics ====================
    
    def create_engagement_metrics(
        self,
        period_start: date,
        period_end: date,
        engagement_data: Dict[str, Any]
    ) -> EngagementMetrics:
        """Create or update engagement metrics."""
        # Determine engagement level
        engagement_level = self._determine_engagement_level(engagement_data)
        engagement_data['engagement_level'] = engagement_level
        
        existing = self.db.query(EngagementMetrics).filter(
            and_(
                EngagementMetrics.period_start == period_start,
                EngagementMetrics.period_end == period_end
            )
        ).first()
        
        if existing:
            for key, value in engagement_data.items():
                setattr(existing, key, value)
            
            existing.calculated_at = datetime.utcnow()
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        metrics = EngagementMetrics(
            period_start=period_start,
            period_end=period_end,
            **engagement_data
        )
        
        self.db.add(metrics)
        self.db.commit()
        self.db.refresh(metrics)
        
        return metrics
    
    def _determine_engagement_level(
        self,
        engagement_data: Dict[str, Any]
    ) -> str:
        """Determine overall engagement level."""
        # Calculate composite engagement score
        avg_hostels_viewed = float(engagement_data.get('avg_hostels_viewed_per_session', 0))
        avg_time_on_page = float(engagement_data.get('avg_time_on_hostel_page_seconds', 0))
        comparison_usage = float(engagement_data.get('comparison_tool_usage_rate', 0))
        
        # Simple scoring
        score = 0
        
        if avg_hostels_viewed >= 3:
            score += 33
        elif avg_hostels_viewed >= 2:
            score += 20
        
        if avg_time_on_page >= 120:
            score += 33
        elif avg_time_on_page >= 60:
            score += 20
        
        if comparison_usage >= 30:
            score += 34
        elif comparison_usage >= 15:
            score += 20
        
        if score >= 70:
            return 'high'
        elif score >= 40:
            return 'moderate'
        else:
            return 'low'
    
    # ==================== Comprehensive Analytics ====================
    
    def create_visitor_behavior_analytics(
        self,
        period_start: date,
        period_end: date,
        search_behavior_id: Optional[UUID],
        engagement_metrics_id: Optional[UUID],
        behavior_data: Dict[str, Any]
    ) -> VisitorBehaviorAnalytics:
        """Create comprehensive visitor behavior analytics."""
        # Calculate visitor quality score
        quality_score = self._calculate_visitor_quality_score(behavior_data)
        behavior_data['visitor_quality_score'] = quality_score
        
        # Generate optimization recommendations
        recommendations = self._generate_visitor_optimization_recommendations(
            behavior_data
        )
        behavior_data['optimization_recommendations'] = recommendations
        
        existing = self.db.query(VisitorBehaviorAnalytics).filter(
            and_(
                VisitorBehaviorAnalytics.period_start == period_start,
                VisitorBehaviorAnalytics.period_end == period_end
            )
        ).first()
        
        analytics_data = {
            'search_behavior_id': search_behavior_id,
            'engagement_metrics_id': engagement_metrics_id,
            **behavior_data,
            'calculated_at': datetime.utcnow(),
        }
        
        if existing:
            for key, value in analytics_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        analytics = VisitorBehaviorAnalytics(
            period_start=period_start,
            period_end=period_end,
            **analytics_data
        )
        
        self.db.add(analytics)
        self.db.commit()
        self.db.refresh(analytics)
        
        return analytics
    
    def _calculate_visitor_quality_score(
        self,
        behavior_data: Dict[str, Any]
    ) -> Decimal:
        """Calculate visitor quality score (0-100)."""
        # Based on engagement and conversion potential
        avg_session_duration = float(behavior_data.get('avg_session_duration_seconds', 0))
        return_visitor_rate = float(behavior_data.get('return_visitor_rate', 0))
        bounce_rate = float(behavior_data.get('bounce_rate', 100))
        
        # Session duration (normalize to 300s)
        duration_score = min(avg_session_duration / 300, 1.0) * 40
        
        # Return visitor rate
        return_score = return_visitor_rate * 0.30
        
        # Bounce rate (inverse)
        bounce_score = max(0, 100 - bounce_rate) * 0.30
        
        total_score = duration_score + return_score + bounce_score
        
        return Decimal(str(round(total_score, 2)))
    
    def _generate_visitor_optimization_recommendations(
        self,
        behavior_data: Dict[str, Any]
    ) -> List[str]:
        """Generate actionable optimization recommendations."""
        recommendations = []
        
        bounce_rate = float(behavior_data.get('bounce_rate', 0))
        if bounce_rate > 60:
            recommendations.append(
                'High bounce rate detected - improve landing page relevance and loading speed'
            )
        
        avg_session = float(behavior_data.get('avg_session_duration_seconds', 0))
        if avg_session < 60:
            recommendations.append(
                'Low session duration - enhance content engagement and value proposition'
            )
        
        return_rate = float(behavior_data.get('return_visitor_rate', 0))
        if return_rate < 20:
            recommendations.append(
                'Low return visitor rate - implement retargeting and email nurture campaigns'
            )
        
        return recommendations
    
    # ==================== Traffic Source Analytics ====================
    
    def create_traffic_source_analytics(
        self,
        period_start: date,
        period_end: date
    ) -> TrafficSourceAnalytics:
        """Create comprehensive traffic source analytics."""
        # Get all source metrics
        sources = self.get_traffic_source_metrics(period_start, period_end)
        
        if not sources:
            return None
        
        # Aggregate data
        total_visits = sum(s.visits for s in sources)
        
        visits_by_source = {s.source: s.visits for s in sources}
        registrations_by_source = {s.source: s.registrations for s in sources}
        bookings_by_source = {s.source: s.bookings for s in sources}
        
        conversion_rates = {
            s.source: float(s.visit_to_booking_rate)
            for s in sources
        }
        
        # Find best performers
        best_converting = max(sources, key=lambda s: s.visit_to_booking_rate)
        highest_volume = max(sources, key=lambda s: s.visits)
        
        # Best ROI (if available)
        sources_with_roi = [s for s in sources if s.roi is not None]
        best_roi = max(sources_with_roi, key=lambda s: s.roi) if sources_with_roi else None
        
        existing = self.db.query(TrafficSourceAnalytics).filter(
            and_(
                TrafficSourceAnalytics.period_start == period_start,
                TrafficSourceAnalytics.period_end == period_end
            )
        ).first()
        
        analytics_data = {
            'total_visits': total_visits,
            'visits_by_source': visits_by_source,
            'registrations_by_source': registrations_by_source,
            'bookings_by_source': bookings_by_source,
            'visit_to_booking_rate_by_source': conversion_rates,
            'best_converting_source': best_converting.source,
            'highest_volume_source': highest_volume.source,
            'best_roi_source': best_roi.source if best_roi else None,
            'calculated_at': datetime.utcnow(),
        }
        
        if existing:
            for key, value in analytics_data.items():
                setattr(existing, key, value)
            
            self.db.commit()
            self.db.refresh(existing)
            return existing
        
        analytics = TrafficSourceAnalytics(
            period_start=period_start,
            period_end=period_end,
            **analytics_data
        )
        
        self.db.add(analytics)
        self.db.commit()
        self.db.refresh(analytics)
        
        return analytics

# --- File: C:\Hostel-Main\app\repositories\analytics\__init__.py ---
"""
Analytics repositories package.

Provides data access layer for all analytics models with:
- Comprehensive CRUD operations
- Complex query building and optimization
- Aggregation and calculation logic
- Caching integration
- Performance tracking
"""

from app.repositories.analytics.analytics_aggregate_repository import (
    AnalyticsAggregateRepository
)
from app.repositories.analytics.booking_analytics_repository import (
    BookingAnalyticsRepository
)
from app.repositories.analytics.complaint_analytics_repository import (
    ComplaintAnalyticsRepository
)
from app.repositories.analytics.custom_reports_repository import (
    CustomReportsRepository
)
from app.repositories.analytics.dashboard_analytics_repository import (
    DashboardAnalyticsRepository
)
from app.repositories.analytics.financial_analytics_repository import (
    FinancialAnalyticsRepository
)
from app.repositories.analytics.occupancy_analytics_repository import (
    OccupancyAnalyticsRepository
)
from app.repositories.analytics.platform_analytics_repository import (
    PlatformAnalyticsRepository
)
from app.repositories.analytics.supervisor_analytics_repository import (
    SupervisorAnalyticsRepository
)
from app.repositories.analytics.visitor_analytics_repository import (
    VisitorAnalyticsRepository
)

__all__ = [
    'AnalyticsAggregateRepository',
    'BookingAnalyticsRepository',
    'ComplaintAnalyticsRepository',
    'CustomReportsRepository',
    'DashboardAnalyticsRepository',
    'FinancialAnalyticsRepository',
    'OccupancyAnalyticsRepository',
    'PlatformAnalyticsRepository',
    'SupervisorAnalyticsRepository',
    'VisitorAnalyticsRepository',
]
